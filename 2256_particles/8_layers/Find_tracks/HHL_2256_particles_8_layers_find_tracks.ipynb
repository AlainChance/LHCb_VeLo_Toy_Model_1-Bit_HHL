{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1-Bit HHL track simulation toy model 2256 particles 8 layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Jupyter notebook is compatible with Python 3.13, Qiskit v2.2, Qiskit Aer v0.17, Qiskit runtime version: 0.43 and Qiskit Runtime V2 primitives.\n",
    "|||\n",
    "|-|-|\n",
    "|**Author:** |Alain Chancé|\n",
    "|**Date:** |September 29, 2025|\n",
    "|**Version:** |**1.00**|\n",
    "# LHCb_VeLo_Toy_Model_1-Bit_HHL\n",
    "An efficient implementation of the 1-Bit HHL track simulation toy model at the LHCb at CERN derived from the following publications:\n",
    "- [Alain Chancé, A Toy Model For Reconstructing Particle Tracks at LHCb at CERN with Quantum Computing, 30 Oct. 2025, LHCb_VeLo_Toy_Model_1-Bit_HHL.pdf](https://github.com/AlainChance/LHCb_VeLo_Toy_Model_1-Bit_HHL/blob/main/LHCb_VeLo_Toy_Model_1-Bit_HHL.pdf).\n",
    "- [Xenofon Chiotopoulos, Davide Nicotra, George Scriven, Kurt Driessens, Marcel Merk, Jochen Schütz, Jacco de Vries, Mark H.M. Winands, TrackHHL: The 1-Bit Quantum Filter for particle trajectory reconstruction, 12 Jan 2026, arXiv:2601.07766](https://doi.org/10.48550/arXiv.2601.07766)\n",
    "- [Xenofon Chiotopoulos, TrackHHL: A Quantum Computing Algorithm for Track Reconstruction at the LHCb](https://indico.cern.ch/event/1338689/contributions/6010017/attachments/2951297/5188722/CHEP_ppt.pdf)\n",
    "- Xenofon Chiotopoulos, Miriam Lucio Martinez, Davide Nicotra, Jacco A. de Vries, Kurt Driessens, Marcel Merk, and Mark H.M. Winands, TrackHHL: A Quantum Computing Algorithm for Track Reconstruction at the LHCb, EPJ Web of Conferences 337, 01181 (2025), [https://doi.org/10.1051/epjconf/202533701181](https://doi.org/10.1051/epjconf/202533701181).\n",
    "- [D. Nicotra et al., arXiv:2308.00619v2, 7 Oct 2023, A quantum algorithm for track reconstruction in the LHCb vertex detector](https://arxiv.org/pdf/2308.00619)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qiskit version: 2.2.3\n",
      "Qiskit Aer version: 0.17.2\n",
      "Qiskit runtime version: 0.43.1\n"
     ]
    }
   ],
   "source": [
    "from One_Bit_HHL_Simulation import One_Bit_HHL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup configuration parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    #--------------------\n",
    "    # Simulation options\n",
    "    #--------------------\n",
    "    \"dz\": 20,                           # layer spacing (mm)\n",
    "    \"layers\": 8,                        # Number of layers\n",
    "    \"n_particles\": [256, 500, 500, 500, 500],    # Number of particles\n",
    "    \"p_vertices\": [(0,0,2), (0,0,4), (0,0,6), (0,0,8), (0,0,10)],  # Primary vertices\n",
    "    #------------------\n",
    "    # Noise parameters\n",
    "    #------------------\n",
    "    \"measurement_error\": 0.0,           # HIT RESOLUTION (sigma on measurement) (sigma)\n",
    "    \"collision_noise\": 1.0e-7,          # MULTIPLE SCATTERING (angular noise proxy)\n",
    "    \"ghost_rate\": 1e-2,                 # Ghost (fake) track rate\n",
    "    \"drop_rate\": 0.0,                   # Hit drop (inefficiency) rate\n",
    "    #-----------------\n",
    "    # Display options\n",
    "    #-----------------\n",
    "    \"display_particles\": False,         # Whether to display initial particle states\n",
    "    \"display_hits\": False,              # Whether to display hits\n",
    "    \"display_ghost_hits\": True,         # Whether to display ghost hits\n",
    "    \"display_tracks\": False,            # Whether to display events and ghost tracks\n",
    "    \"display_clusters\": False,          # Whether to display clusters found by find_tracks()\n",
    "    \"display_false_clusters\": True,     # Whether to display clusters rejected by find_tracks()\n",
    "    \"display_clone_splitting\": True,    # Whether to display clone splitting information\n",
    "    \"display_clustering\": True,         # Whether to display clustering information\n",
    "    \"do_plot_tracks\": False,            # Whether to plot events and ghost tracks \n",
    "    \"do_spectrum\": False,               # Whether to analyze the classical solution spectrum\n",
    "    \"do_print_counts\": False,           # Whether to print raw measurement counts\n",
    "    \"resolution\": 2000,                 # Resolution for plots of tracks - Increase for finer mesh\n",
    "    \"do_draw\": False,                   # Whether to draw the HHL circuit\n",
    "    #----------------------------------\n",
    "    # Classical find_tracks parameters\n",
    "    #----------------------------------\n",
    "    \"tol\": None,                        # Tolerance for floating point comparison\n",
    "    \"tol_clusters\": None,               # Tolerance for cluster_by_last_column()\n",
    "    \"tol_clone\": 1.0e-8,                # Tolerance for decloning tracks\n",
    "    \"tol_intersects\": None,             # Tolerance for segment_intersects_z_axis()\n",
    "    #---------------------------------------------------------------------------------------------------------\n",
    "    # A simulated primary vertex is defined as reconstructed if a primary vertex is found within 2 mm \n",
    "    # of its true position. See Primary Vertex Reconstruction Efficiency and Resolution in [ALGO-2]\n",
    "    # [Aaij, R., Adinolfi, M., Aiola, S. et al. A Comparison of CPU and GPU Implementations for the LHCb \n",
    "    # Experiment Run 3 Trigger. Comput Softw Big Sci 6, 1 (2022)](https://doi.org/10.1007/s41781-021-00070-2)\n",
    "    #---------------------------------------------------------------------------------------------------------\n",
    "    \"tol_vertices\": None,               # Tolerance for clustering primary vertices (mm)\n",
    "    #---------------------------------------\n",
    "    # Classical diagonalisation run options\n",
    "    #---------------------------------------\n",
    "    \"do_solve_scipy\": False,            # Whether to solve classically using scipy.sparse.linalg.cg\n",
    "    \"T_classical\": None,                # Threshold for discretizing classical solutions\n",
    "    #------------------------------------------\n",
    "    # Files containing token (API key) and CRN\n",
    "    #------------------------------------------\n",
    "    \"token_file\": \"Token.txt\",          # Token file\n",
    "    \"CRN_file\": \"CRN.txt\",              # CRN file\n",
    "    #-------------------------------\n",
    "    # Quantum computing run options\n",
    "    #-------------------------------\n",
    "    \"T_hhl\": None,                                      # Threshold for discretizing 1-Bit HHL solutions - None: to be computed\n",
    "    \"backend_name\": \"AerSimulator noiseless\",           # AerSimulator noiseless or Fake QPU or real IBM cloud backend name\n",
    "    \"job_id\": None,                                     # job_id of a previously run job\n",
    "    \"run_on_QPU\": False,                                # Whether to run the quantum circuit on the target hardware\n",
    "    \"nshots\": 2000000,                                  # Number of shots\n",
    "    'opt_level': 1,                                     # Optimization level\n",
    "    \"poll_interval\": 5,                                 # Poll interval in seconds for job monitor\n",
    "    \"timeout\": 600,                                     # Time out in seconds for job monitor\n",
    "    #-------------------------------------\n",
    "    # eco2AI Tracker options\n",
    "    # https://github.com/sb-ai-lab/Eco2AI\n",
    "    #-------------------------------------\n",
    "    \"do_eco2ai\": True,                                   # Whether to use the eco2AI Tracker\n",
    "    \"project_name\": \"One_Bit_HHL\",                       # Project name\n",
    "    \"experiment_description\": \"HHL_2256_p_8_l_find_tracks\", # Experiment description\n",
    "    \"eco2ai_file_name\": \"HHL_2256_p_8_l_find_tracks.csv\",   # eco2AI file name\n",
    "    #---------------------------------------------------------------------------------\n",
    "    # Ballpark figure (kW) for the power consumption of the IBM cloud backend\n",
    "    # \"The power consumption of a quantum computer is about 15-25kW\"\n",
    "    # https://www.capgemini.com/insights/expert-perspectives/green-quantum-computing/\n",
    "    #---------------------------------------------------------------------------------\n",
    "    \"power_QPU\": 25,                    # Ballpark figure (kW) for the power consumption of the IBM cloud backend\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an instance of the One_Bit_HHL class from the configuration dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------\n",
      " Simulation options\n",
      "--------------------\n",
      "layer spacing (mm), dz: 20\n",
      "layers: 8\n",
      "n_particles: [256, 500, 500, 500, 500], Total number: 2256\n",
      "primary_vertices: [(0, 0, 2), (0, 0, 4), (0, 0, 6), (0, 0, 8), (0, 0, 10)]\n",
      "\n",
      "-----------------\n",
      " Display options\n",
      "-----------------\n",
      "do_draw: False\n",
      "display_particles: False\n",
      "display_hits: False\n",
      "display_ghost_hits: True\n",
      "display_tracks: False\n",
      "display_clusters: False\n",
      "display_false_clusters: True\n",
      "display_clone_splitting: True\n",
      "display_clustering: True\n",
      "do_plot_tracks: False\n",
      "do_plot_heat_map: False\n",
      "do_spectrum: False\n",
      "do_print_counts: False\n",
      "do_print_outer_segs False\n",
      "resolution: 2000\n",
      "\n",
      "------------------\n",
      " Noise parameters\n",
      "------------------\n",
      "measurement hit resolution: 0.0\n",
      "ghost (fake) track rate: 0.01\n",
      "hit drop (inefficiency) rate: 0.0\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------------\n",
      " Anchoring clustering and clone splitting tolerances of the classical function find_tracks() to the parameter collision noise\n",
      "------------------------------------------------------------------------------------------------------------------------------\n",
      "Multiple scattering collision noise, collision_noise: 1.00e-07\n",
      "Tolerance for floating point comparison, tol: 1.00e-07\n",
      "Minimum value of the tolerance for clustering, cluster_by_last_column(), tol_clusters: 1.00e-06\n",
      "Minimum value of the decloning tolerance, tol_clone: 1.00e-08\n",
      "Tolerance for segment_intersects_z_axis(), tol_intersects: 1.00e-03\n",
      "Tolerance for clustering vertices, tol_vertices: 1.00e+00\n",
      "\n",
      "---------------------------------------\n",
      " Classical diagonalisation run options\n",
      "---------------------------------------\n",
      "do_solve_scipy: False\n",
      "T_classical: None\n",
      "\n",
      "-------------------------------\n",
      " Quantum computing run options\n",
      "-------------------------------\n",
      "T_hhl: None\n",
      "Backend name: AerSimulator noiseless\n",
      "Run on QPU: False\n",
      "Optimization level: 1\n",
      "\n",
      "------------------------\n",
      " eco2AI Tracker options\n",
      "------------------------\n",
      "project_name: One_Bit_HHL\n",
      "experiment_description: HHL_2256_p_8_l_find_tracks\n",
      "eco2ai_file_name: HHL_2256_p_8_l_find_tracks.csv\n",
      "\n",
      "Ballpark figure (kW) for QPU power consumption: 25\n",
      "\n",
      "Deleted: HHL_2256_p_8_l_find_tracks.csv\n",
      "eco2AI tracker started\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    My_HHL = One_Bit_HHL(**config)\n",
    "except Exception as e:\n",
    "   print(f\"Error creating 1_Bit_HHL instance: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------------------------------------------------------\n",
      " All 180 ghost hits created by the function make_noisy_event()\n",
      "---------------------------------------------------------------\n",
      "\n",
      "    Hit Index   Hit ID        x         y         z       Theta      Module ID\n",
      "       0           0         4.07     15.18     80.00     1.309          4\n",
      "       0           0       -16.15      8.73     80.00     2.646          4\n",
      "       0           0        -9.58     -4.11    120.00    -2.737          6\n",
      "       0           0         9.69      1.28     40.00     0.131          2\n",
      "       0           0        -9.15     -6.13     40.00    -2.551          2\n",
      "       0           0         9.57      5.87    120.00     0.550          6\n",
      "       0           0        10.45    -15.81     80.00    -0.986          4\n",
      "       0           0        -8.24      9.95     20.00     2.263          1\n",
      "       0           0       -12.56      0.41     40.00     3.109          2\n",
      "       0           0        -4.60      6.84    160.00     2.163          8\n",
      "       0           0        -5.28     -2.70    120.00    -2.669          6\n",
      "       0           0        -3.52      8.50     20.00     1.964          1\n",
      "       0           0        -4.28      2.57     80.00     2.600          4\n",
      "       0           0        -7.28     -8.07    100.00    -2.305          5\n",
      "       0           0         5.78     -6.33     60.00    -0.830          3\n",
      "       0           0       -12.57     12.80    160.00     2.347          8\n",
      "       0           0         5.88     -0.06    160.00    -0.011          8\n",
      "       0           0        -9.70    -14.23    160.00    -2.169          8\n",
      "       0           0       -15.46     15.30     60.00     2.361          3\n",
      "       0           0        -5.76     -1.42     80.00    -2.900          4\n",
      "       0           0         1.79      7.55     40.00     1.338          2\n",
      "       0           0        -6.91      1.44    140.00     2.936          7\n",
      "       0           0         2.71      3.84    140.00     0.956          7\n",
      "       0           0        -9.21     -5.01     80.00    -2.644          4\n",
      "       0           0        14.22    -12.50     80.00    -0.721          4\n",
      "       0           0        14.08      3.85    160.00     0.267          8\n",
      "       0           0        -4.51     -7.33    100.00    -2.122          5\n",
      "       0           0         4.94      8.17     60.00     1.027          3\n",
      "       0           0       -11.87     -6.49     80.00    -2.641          4\n",
      "       0           0       -10.93    -13.70     20.00    -2.244          1\n",
      "       0           0       -13.63     -3.25     20.00    -2.907          1\n",
      "       0           0        15.95     16.49     20.00     0.802          1\n",
      "       0           0         1.59      7.75    160.00     1.369          8\n",
      "       0           0        10.74      0.16     60.00     0.015          3\n",
      "       0           0         9.07      3.86    140.00     0.403          7\n",
      "       0           0         4.86      5.10    120.00     0.810          6\n",
      "       0           0        -1.65     -4.75     80.00    -1.905          4\n",
      "       0           0        -8.19      8.30    160.00     2.350          8\n",
      "       0           0        -6.19    -14.22    100.00    -1.981          5\n",
      "       0           0       -10.81     -7.52    140.00    -2.534          7\n",
      "       0           0        -0.60    -10.30     60.00    -1.629          3\n",
      "       0           0        -7.91     -4.04    160.00    -2.670          8\n",
      "       0           0        -5.26    -13.18    140.00    -1.950          7\n",
      "       0           0        15.13     12.86    140.00     0.705          7\n",
      "       0           0        -2.62     -1.85     40.00    -2.526          2\n",
      "       0           0         2.30      4.07     60.00     1.057          3\n",
      "       0           0        -2.61    -14.17    160.00    -1.753          8\n",
      "       0           0        -3.24     -3.12     20.00    -2.376          1\n",
      "       0           0       -11.78      9.30     20.00     2.473          1\n",
      "       0           0         2.88     12.33     20.00     1.341          1\n",
      "       0           0       -12.01     16.38    160.00     2.203          8\n",
      "       0           0         6.33     -6.62    120.00    -0.808          6\n",
      "       0           0         4.05     10.91    100.00     1.215          5\n",
      "       0           0         4.98    -11.22    160.00    -1.153          8\n",
      "       0           0        -7.31     -3.96     40.00    -2.645          2\n",
      "       0           0         1.35     13.17    100.00     1.469          5\n",
      "       0           0         3.21    -15.67     80.00    -1.369          4\n",
      "       0           0        -7.30      5.38     40.00     2.506          2\n",
      "       0           0        -6.12     -9.10    100.00    -2.163          5\n",
      "       0           0       -16.25      6.76    140.00     2.747          7\n",
      "       0           0        -9.94     12.36    160.00     2.248          8\n",
      "       0           0       -14.13     -6.59    120.00    -2.705          6\n",
      "       0           0       -11.97      5.35     80.00     2.721          4\n",
      "       0           0        -7.82     15.99     20.00     2.026          1\n",
      "       0           0         1.98     -9.47    120.00    -1.365          6\n",
      "       0           0       -11.34      6.59    100.00     2.615          5\n",
      "       0           0       -13.99     14.18    100.00     2.349          5\n",
      "       0           0        -4.75      2.32    100.00     2.688          5\n",
      "       0           0        -8.80      3.99    140.00     2.716          7\n",
      "       0           0         0.05      2.52    120.00     1.549          6\n",
      "       0           0        11.57     -8.90    140.00    -0.656          7\n",
      "       0           0         4.49     14.65    140.00     1.274          7\n",
      "       0           0         4.83      0.96     40.00     0.197          2\n",
      "       0           0         1.44     -2.06     40.00    -0.959          2\n",
      "       0           0         4.67     -2.98    140.00    -0.569          7\n",
      "       0           0        -9.31     -0.69     80.00    -3.067          4\n",
      "       0           0       -11.48      2.24     60.00     2.949          3\n",
      "       0           0         8.55     -5.89     80.00    -0.603          4\n",
      "       0           0        -7.47     16.25     80.00     2.002          4\n",
      "       0           0         7.34     -7.97     60.00    -0.826          3\n",
      "       0           0        16.40    -13.61     60.00    -0.693          3\n",
      "       0           0        13.29    -14.64     80.00    -0.834          4\n",
      "       0           0        15.70      0.82     80.00     0.052          4\n",
      "       0           0         1.22     -6.46    100.00    -1.384          5\n",
      "       0           0         0.91    -15.76    120.00    -1.513          6\n",
      "       0           0         8.54      0.89     20.00     0.104          1\n",
      "       0           0       -14.03    -16.02     60.00    -2.290          3\n",
      "       0           0        -2.95     -6.19    120.00    -2.015          6\n",
      "       0           0         4.63     -0.31     60.00    -0.067          3\n",
      "       0           0       -10.10      5.87    160.00     2.615          8\n",
      "       0           0        11.14    -15.28    120.00    -0.941          6\n",
      "       0           0         4.66      8.87     40.00     1.086          2\n",
      "       0           0        -1.08     -0.99     40.00    -2.396          2\n",
      "       0           0        11.42     -5.33     40.00    -0.437          2\n",
      "       0           0        -7.95      5.74     40.00     2.516          2\n",
      "       0           0        -4.93     -8.88    140.00    -2.078          7\n",
      "       0           0        -1.08     -1.94    160.00    -2.079          8\n",
      "       0           0        -7.66      8.76     40.00     2.289          2\n",
      "       0           0         7.15     -7.68     60.00    -0.821          3\n",
      "       0           0       -13.56      9.15     40.00     2.548          2\n",
      "       0           0         9.87     13.09    140.00     0.925          7\n",
      "       0           0        -0.17     -1.93    160.00    -1.661          8\n",
      "       0           0        -3.75     -2.13     80.00    -2.625          4\n",
      "       0           0        14.42    -11.15     40.00    -0.658          2\n",
      "       0           0       -13.54      1.78    100.00     3.011          5\n",
      "       0           0        14.35      2.07     60.00     0.143          3\n",
      "       0           0        11.38    -14.02     20.00    -0.889          1\n",
      "       0           0        -2.25      0.13     80.00     3.085          4\n",
      "       0           0        14.50      3.04    100.00     0.206          5\n",
      "       0           0        -0.50     12.84    120.00     1.610          6\n",
      "       0           0         3.08     -7.68     60.00    -1.189          3\n",
      "       0           0       -12.31      7.01     80.00     2.624          4\n",
      "       0           0        -3.52      6.09     80.00     2.095          4\n",
      "       0           0        13.97    -14.39     80.00    -0.800          4\n",
      "       0           0        -0.20     -1.58     60.00    -1.694          3\n",
      "       0           0        -1.71     11.13     80.00     1.723          4\n",
      "       0           0        13.89      9.81    140.00     0.615          7\n",
      "       0           0        -0.95    -14.30     80.00    -1.637          4\n",
      "       0           0        12.37    -10.10    140.00    -0.685          7\n",
      "       0           0        -0.11      5.80     40.00     1.591          2\n",
      "       0           0        -2.96     12.66     20.00     1.800          1\n",
      "       0           0         2.49    -10.78    140.00    -1.344          7\n",
      "       0           0         1.87      9.15     80.00     1.369          4\n",
      "       0           0         3.31     -5.13    100.00    -0.998          5\n",
      "       0           0        10.10     15.92    160.00     1.005          8\n",
      "       0           0         6.65    -12.24     40.00    -1.073          2\n",
      "       0           0        -0.53      2.01    100.00     1.828          5\n",
      "       0           0        14.38     11.62     60.00     0.679          3\n",
      "       0           0       -12.98     -0.63    140.00    -3.093          7\n",
      "       0           0         3.99     14.42    160.00     1.301          8\n",
      "       0           0        -3.35     12.78     60.00     1.827          3\n",
      "       0           0       -12.31     10.56    140.00     2.432          7\n",
      "       0           0         8.36     -6.04    140.00    -0.626          7\n",
      "       0           0        -8.85     -1.32    120.00    -2.994          6\n",
      "       0           0        12.26      8.55     20.00     0.609          1\n",
      "       0           0       -13.70     -2.07     60.00    -2.992          3\n",
      "       0           0         9.44     11.80    120.00     0.896          6\n",
      "       0           0        -5.23     14.43    120.00     1.919          6\n",
      "       0           0        -0.40      2.80    140.00     1.713          7\n",
      "       0           0         6.45     11.53     60.00     1.061          3\n",
      "       0           0        -2.49      0.95     80.00     2.777          4\n",
      "       0           0        -2.44     12.60     40.00     1.762          2\n",
      "       0           0         2.86     -3.93     60.00    -0.942          3\n",
      "       0           0         4.92     14.79    160.00     1.250          8\n",
      "       0           0        -8.72      7.68    140.00     2.420          7\n",
      "       0           0         3.96     -8.55    160.00    -1.137          8\n",
      "       0           0        -4.12      4.77    160.00     2.282          8\n",
      "       0           0         9.01      3.41     60.00     0.362          3\n",
      "       0           0        14.44     -1.46    140.00    -0.101          7\n",
      "       0           0        15.05      2.02    160.00     0.133          8\n",
      "       0           0        -2.55      3.15    160.00     2.252          8\n",
      "       0           0        -9.91     -7.43     80.00    -2.498          4\n",
      "       0           0        -5.68     -0.64    120.00    -3.029          6\n",
      "       0           0       -15.66      3.98    160.00     2.893          8\n",
      "       0           0        11.73     13.81     40.00     0.867          2\n",
      "       0           0        -3.04    -15.21     20.00    -1.768          1\n",
      "       0           0        10.41      0.45     60.00     0.043          3\n",
      "       0           0        -6.96     -5.29     20.00    -2.491          1\n",
      "       0           0       -16.41      9.61    100.00     2.612          5\n",
      "       0           0        -2.48     -0.39     60.00    -2.984          3\n",
      "       0           0         1.95     16.21    160.00     1.451          8\n",
      "       0           0        -8.54    -14.22    140.00    -2.112          7\n",
      "       0           0         3.55     -2.82    160.00    -0.671          8\n",
      "       0           0        12.19     -4.30    140.00    -0.339          7\n",
      "       0           0        -5.08     -3.16    100.00    -2.585          5\n",
      "       0           0        -3.00      0.48     20.00     2.982          1\n",
      "       0           0        -7.92     -3.36    140.00    -2.741          7\n",
      "       0           0        -5.88     -4.62     60.00    -2.476          3\n",
      "       0           0        15.76      0.89    120.00     0.056          6\n",
      "       0           0        -7.90     -3.05    160.00    -2.774          8\n",
      "       0           0       -13.82     -4.59    160.00    -2.821          8\n",
      "       0           0       -14.03     12.75     40.00     2.404          2\n",
      "       0           0        15.18     -5.49     20.00    -0.347          1\n",
      "       0           0        -4.08      5.32    160.00     2.225          8\n",
      "       0           0        -5.77      3.95    160.00     2.541          8\n",
      "       0           0        12.89     -1.68    140.00    -0.129          7\n",
      "       0           0        -2.27    -16.20     40.00    -1.710          2\n",
      "       0           0        -5.55    -12.79    160.00    -1.981          8\n",
      "       0           0        -1.61      6.77    160.00     1.804          8\n",
      "       0           0        -2.30     -5.75    160.00    -1.952          8\n",
      "\n",
      "-------------------------------------------------------\n",
      " ✅ Function setup_events() completed in 16.36 seconds \n",
      "-------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "My_HHL.setup_events()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run classical and 1-Bit HHL simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------------------------------------------------------------------------------------\n",
      " find_tracks() - Refined tol_clusters_est = 1.0000e-06 (mean intra-cluster std=2.9819e-07)\n",
      "-------------------------------------------------------------------------------------------\n",
      "\n",
      "-----------------------\n",
      " Clone-track splitting\n",
      "-----------------------\n",
      "\n",
      "   Hit Index   Hit ID      x         y         z       Theta    Module ID\n",
      "    1392       1392      -0.66     -3.58     20.00    -1.753       1\n",
      "    1393       1393      -1.39     -7.55     40.00    -1.753       2\n",
      "    1394       1394      -2.13    -11.53     60.00    -1.753       3\n",
      "    1395       1395      -2.86    -15.50     80.00    -1.753       4\n",
      "    1396       1396      -3.59    -19.48    100.00    -1.753       5\n",
      "    1397       1397      -4.33    -23.45    120.00    -1.753       6\n",
      "    1398       1398      -5.06    -27.43    140.00    -1.753       7\n",
      "   18094          0      -2.61    -14.17    160.00    -1.753       8\n",
      "    1399       1399      -5.79    -31.40    160.00    -1.753       8\n",
      "\n",
      "--------------------------------------------------------------------\n",
      " Estimated tol_clone (segment-based) = 1.6490e+00  (std=1.0993e+00)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Clusters found by the function split_clone_by_direction()\n",
      "\n",
      "    Hit Index     Hit ID          x         y         z       Theta      Module ID\n",
      "      1392          1392        -0.66     -3.58     20.00    -1.753          1\n",
      "      1393          1393        -1.39     -7.55     40.00    -1.753          2\n",
      "      1394          1394        -2.13    -11.53     60.00    -1.753          3\n",
      "      1395          1395        -2.86    -15.50     80.00    -1.753          4\n",
      "      1396          1396        -3.59    -19.48    100.00    -1.753          5\n",
      "      1397          1397        -4.33    -23.45    120.00    -1.753          6\n",
      "      1398          1398        -5.06    -27.43    140.00    -1.753          7\n",
      "     18094             0        -2.61    -14.17    160.00    -1.753          8\n",
      "\n",
      "--------------------------------------------\n",
      " ✅ find_tracks() completed in 0.18 seconds \n",
      "--------------------------------------------\n",
      "\n",
      "----------------------------------------\n",
      " find_tracks() found 5 primary vertices\n",
      "----------------------------------------\n",
      "(0.000, 0.000, 2.000)\n",
      "(0.000, 0.000, 4.000)\n",
      "(0.000, 0.000, 6.000)\n",
      "(0.000, 0.000, 8.000)\n",
      "(0.000, 0.000, 10.000)\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      " find_tracks() found 2215 tracks and 420 ghost hits and 99 false clusters\n",
      "--------------------------------------------------------------------------\n",
      "\n",
      "-----------------------------------------------------------\n",
      " All 99 false clusters found by the function find_tracks()\n",
      "-----------------------------------------------------------\n",
      "\n",
      "   Hit Index   Hit ID      x         y         z       Theta    Module ID\n",
      "     144        144      -0.51      0.73     20.00     2.184       1\n",
      "     145        145      -1.08      1.54     40.00     2.184       2\n",
      "     146        146      -1.65      2.35     60.00     2.184       3\n",
      "     147        147      -2.22      3.16     80.00     2.184       4\n",
      "     148        148      -2.79      3.97    100.00     2.184       5\n",
      "     149        149      -3.36      4.78    120.00     2.184       6\n",
      "     150        150      -3.93      5.59    140.00     2.184       7\n",
      "     151        151      -4.50      6.40    160.00     2.184       8\n",
      "     288        288       0.72      1.04     20.00     0.963       1\n",
      "     289        289       1.52      2.19     40.00     0.963       2\n",
      "     290        290       2.32      3.34     60.00     0.963       3\n",
      "     334        334       4.90     -3.39    140.00    -0.606       7\n",
      "     335        335       5.61     -3.88    160.00    -0.606       8\n",
      "    1177       1177       0.26     -0.20     40.00    -0.658       2\n",
      "    1178       1178       0.39     -0.30     60.00    -0.658       3\n",
      "    1181       1181       0.80     -0.62    120.00    -0.658       6\n",
      "    1182       1182       0.94     -0.72    140.00    -0.658       7\n",
      "    1280       1280      -0.78      0.87     20.00     2.307       1\n",
      "    1281       1281      -1.66      1.83     40.00     2.307       2\n",
      "    1282       1282      -2.53      2.79     60.00     2.307       3\n",
      "    1284       1284      -4.27      4.72    100.00     2.307       5\n",
      "    1285       1285      -5.14      5.68    120.00     2.307       6\n",
      "    1286       1286      -6.01      6.64    140.00     2.307       7\n",
      "    1287       1287      -6.89      7.61    160.00     2.307       8\n",
      "    1465       1465      -3.98      0.01     40.00     3.140       2\n",
      "    1466       1466      -6.08      0.01     60.00     3.140       3\n",
      "    1467       1467      -8.18      0.01     80.00     3.140       4\n",
      "    1468       1468     -10.27      0.02    100.00     3.140       5\n",
      "    1469       1469     -12.37      0.02    120.00     3.140       6\n",
      "    1470       1470     -14.47      0.02    140.00     3.140       7\n",
      "    1471       1471     -16.56      0.03    160.00     3.140       8\n",
      "    1600       1600      -0.97      0.12     20.00     3.019       1\n",
      "    1601       1601      -2.04      0.25     40.00     3.019       2\n",
      "    2469       2469      -2.47      1.30    120.00     2.659       6\n",
      "    2470       2470      -2.90      1.52    140.00     2.659       7\n",
      "    2471       2471      -3.33      1.74    160.00     2.659       8\n",
      "    2760       2760      -0.39     -0.14     20.00    -2.798       1\n",
      "    2762       2762      -1.35     -0.48     60.00    -2.798       3\n",
      "    2763       2763      -1.83     -0.66     80.00    -2.798       4\n",
      "    2764       2764      -2.31     -0.83    100.00    -2.798       5\n",
      "    2765       2765      -2.80     -1.00    120.00    -2.798       6\n",
      "    2766       2766      -3.28     -1.17    140.00    -2.798       7\n",
      "    2767       2767      -3.76     -1.35    160.00    -2.798       8\n",
      "    2981       2981       2.41      3.79    120.00     1.005       6\n",
      "    2982       2982       2.82      4.44    140.00     1.005       7\n",
      "    2983       2983       3.24      5.09    160.00     1.005       8\n",
      "    3013       3013       2.45     -5.95    120.00    -1.181       6\n",
      "    3014       3014       2.87     -6.98    140.00    -1.181       7\n",
      "    3089       3089       0.85      1.69     40.00     1.103       2\n",
      "    3090       3090       1.33      2.63     60.00     1.103       3\n",
      "    3490       3490       0.01     -1.96     60.00    -1.568       3\n",
      "    3491       3491       0.01     -2.66     80.00    -1.568       4\n",
      "    3492       3492       0.01     -3.35    100.00    -1.568       5\n",
      "    3493       3493       0.01     -4.05    120.00    -1.568       6\n",
      "    3494       3494       0.01     -4.75    140.00    -1.568       7\n",
      "    3495       3495       0.01     -5.45    160.00    -1.568       8\n",
      "    3523       3523      -0.99      0.03     80.00     3.111       4\n",
      "    3524       3524      -1.25      0.04    100.00     3.111       5\n",
      "    3525       3525      -1.51      0.05    120.00     3.111       6\n",
      "    3526       3526      -1.77      0.05    140.00     3.111       7\n",
      "    3768       3768      -0.45      0.12     20.00     2.888       1\n",
      "    3769       3769      -1.01      0.26     40.00     2.888       2\n",
      "    3990       3990       7.70     -2.45    140.00    -0.308       7\n",
      "    3991       3991       8.83     -2.81    160.00    -0.308       8\n",
      "    4313       4313      -0.41      0.95     40.00     1.975       2\n",
      "    4317       4317      -1.31      3.06    120.00     1.975       6\n",
      "    4318       4318      -1.53      3.59    140.00     1.975       7\n",
      "    4319       4319      -1.76      4.12    160.00     1.975       8\n",
      "    4314       4314      -0.63      1.48     60.00     1.975       3\n",
      "    4315       4315      -0.86      2.01     80.00     1.975       4\n",
      "    4316       4316      -1.08      2.53    100.00     1.975       5\n",
      "    4792       4792       0.34     -0.30     20.00    -0.721       1\n",
      "    4794       4794       1.18     -1.03     60.00    -0.721       3\n",
      "    4796       4796       2.02     -1.77    100.00    -0.721       5\n",
      "    4797       4797       2.44     -2.14    120.00    -0.721       6\n",
      "    4976       4976      -0.44      0.75     20.00     2.101       1\n",
      "    4977       4977      -0.99      1.69     40.00     2.101       2\n",
      "    4978       4978      -1.54      2.63     60.00     2.101       3\n",
      "    5005       5005       2.64     -1.83    120.00    -0.606       6\n",
      "    5006       5006       3.09     -2.14    140.00    -0.606       7\n",
      "    5007       5007       3.55     -2.46    160.00    -0.606       8\n",
      "    5214       5214      -2.31      5.57    140.00     1.964       7\n",
      "    5215       5215      -2.65      6.39    160.00     1.964       8\n",
      "    5472       5472      -0.33     -0.78     20.00    -1.974       1\n",
      "    5473       5473      -0.75     -1.76     40.00    -1.974       2\n",
      "    5474       5474      -1.17     -2.74     60.00    -1.974       3\n",
      "    5760       5760      -0.92     -0.39     20.00    -2.737       1\n",
      "    5761       5761      -2.08     -0.89     40.00    -2.737       2\n",
      "    5764       5764      -5.54     -2.37    100.00    -2.737       5\n",
      "    5765       5765      -6.70     -2.86    120.00    -2.737       6\n",
      "    5766       5766      -7.85     -3.36    140.00    -2.737       7\n",
      "    5767       5767      -9.00     -3.85    160.00    -2.737       8\n",
      "    5872       5872      -0.32      0.82     20.00     1.942       1\n",
      "    5877       5877      -2.31      5.95    120.00     1.942       6\n",
      "    5878       5878      -2.71      6.97    140.00     1.942       7\n",
      "    5879       5879      -3.11      8.00    160.00     1.942       8\n",
      "    5873       5873      -0.72      1.85     40.00     1.942       2\n",
      "    5874       5874      -1.12      2.87     60.00     1.942       3\n",
      "    5875       5875      -1.52      3.90     80.00     1.942       4\n",
      "    5876       5876      -1.92      4.92    100.00     1.942       5\n",
      "    6016       6016      -0.24      0.17     20.00     2.530       1\n",
      "    6021       6021      -1.76      1.24    120.00     2.530       6\n",
      "    6022       6022      -2.07      1.45    140.00     2.530       7\n",
      "    6023       6023      -2.37      1.66    160.00     2.530       8\n",
      "    6017       6017      -0.55      0.38     40.00     2.530       2\n",
      "    6018       6018      -0.85      0.60     60.00     2.530       3\n",
      "    6019       6019      -1.16      0.81     80.00     2.530       4\n",
      "    6020       6020      -1.46      1.02    100.00     2.530       5\n",
      "    6080       6080       0.09      0.28     20.00     1.260       1\n",
      "    6085       6085       0.73      2.28    120.00     1.260       6\n",
      "    6086       6086       0.86      2.68    140.00     1.260       7\n",
      "    6087       6087       0.99      3.07    160.00     1.260       8\n",
      "    6081       6081       0.22      0.68     40.00     1.260       2\n",
      "    6084       6084       0.60      1.88    100.00     1.260       5\n",
      "    6248       6248       0.58      0.10     20.00     0.174       1\n",
      "    6249       6249       1.40      0.25     40.00     0.174       2\n",
      "    6288       6288      -0.62      0.08     20.00     3.019       1\n",
      "    6289       6289      -1.50      0.18     40.00     3.019       2\n",
      "    6290       6290      -2.38      0.29     60.00     3.019       3\n",
      "    6291       6291      -3.26      0.40     80.00     3.019       4\n",
      "    6483       6483      -1.85      0.63     80.00     2.815       4\n",
      "    6484       6484      -2.35      0.80    100.00     2.815       5\n",
      "    6485       6485      -2.85      0.97    120.00     2.815       6\n",
      "    6486       6486      -3.35      1.14    140.00     2.815       7\n",
      "    6609       6609       0.81     -0.69     40.00    -0.706       2\n",
      "    6610       6610       1.29     -1.10     60.00    -0.706       3\n",
      "    6611       6611       1.77     -1.51     80.00    -0.706       4\n",
      "    6612       6612       2.25     -1.91    100.00    -0.706       5\n",
      "    6614       6614       3.20     -2.73    140.00    -0.706       7\n",
      "    6615       6615       3.68     -3.13    160.00    -0.706       8\n",
      "    6916       6916       2.03     -2.18    100.00    -0.821       5\n",
      "    6917       6917       2.47     -2.65    120.00    -0.821       6\n",
      "    6918       6918       2.90     -3.11    140.00    -0.821       7\n",
      "    6919       6919       3.33     -3.58    160.00    -0.821       8\n",
      "    7065       7065       1.01     -0.09     40.00    -0.088       2\n",
      "    7066       7066       1.60     -0.14     60.00    -0.088       3\n",
      "    7068       7068       2.78     -0.24    100.00    -0.088       5\n",
      "    7069       7069       3.37     -0.30    120.00    -0.088       6\n",
      "    7070       7070       3.96     -0.35    140.00    -0.088       7\n",
      "    7071       7071       4.55     -0.40    160.00    -0.088       8\n",
      "    7594       7594      -0.93     -1.83     60.00    -2.041       3\n",
      "    7595       7595      -1.28     -2.51     80.00    -2.041       4\n",
      "    7596       7596      -1.62     -3.19    100.00    -2.041       5\n",
      "    7625       7625       2.43     -0.09     40.00    -0.036       2\n",
      "    7626       7626       3.86     -0.14     60.00    -0.036       3\n",
      "    8104       8104       0.87     -0.62     20.00    -0.619       1\n",
      "    8105       8105       2.11     -1.51     40.00    -0.619       2\n",
      "    8784       8784       0.31     -0.42     20.00    -0.932       1\n",
      "    8785       8785       0.75     -1.01     40.00    -0.932       2\n",
      "    9072       9072      -0.05      0.18     20.00     1.853       1\n",
      "    9077       9077      -0.42      1.44    120.00     1.853       6\n",
      "    9078       9078      -0.49      1.69    140.00     1.853       7\n",
      "    9079       9079      -0.56      1.94    160.00     1.853       8\n",
      "    9073       9073      -0.12      0.43     40.00     1.853       2\n",
      "    9074       9074      -0.20      0.68     60.00     1.853       3\n",
      "    9075       9075      -0.27      0.93     80.00     1.853       4\n",
      "    9076       9076      -0.34      1.18    100.00     1.853       5\n",
      "    9145       9145       0.79      0.02     40.00     0.031       2\n",
      "    9146       9146       1.25      0.04     60.00     0.031       3\n",
      "    9280       9280      -0.89      0.10     20.00     3.030       1\n",
      "    9281       9281      -2.17      0.24     40.00     3.030       2\n",
      "    9465       9465      -0.72     -1.89     40.00    -1.932       2\n",
      "    9466       9466      -1.14     -3.01     60.00    -1.932       3\n",
      "    9628       9628      -2.58     -0.13    100.00    -3.089       5\n",
      "    9629       9629      -3.13     -0.16    120.00    -3.089       6\n",
      "    9630       9630      -3.68     -0.19    140.00    -3.089       7\n",
      "    9631       9631      -4.23     -0.22    160.00    -3.089       8\n",
      "    9742       9742      -6.95      4.04    140.00     2.614       7\n",
      "    9743       9743      -7.98      4.65    160.00     2.614       8\n",
      "    9904       9904      -0.18      0.73     20.00     1.821       1\n",
      "    9905       9905      -0.45      1.76     40.00     1.821       2\n",
      "   10040      10040       0.32     -0.27     20.00    -0.686       1\n",
      "   10047      10047       3.57     -2.92    160.00    -0.686       8\n",
      "   10705      10705       0.81     -0.91     40.00    -0.843       2\n",
      "   10706      10706       1.32     -1.49     60.00    -0.843       3\n",
      "   10707      10707       1.83     -2.06     80.00    -0.843       4\n",
      "   10708      10708       2.34     -2.63    100.00    -0.843       5\n",
      "   10709      10709       2.85     -3.20    120.00    -0.843       6\n",
      "   10710      10710       3.36     -3.77    140.00    -0.843       7\n",
      "   10711      10711       3.87     -4.34    160.00    -0.843       8\n",
      "   10888      10888      -0.23     -0.18     20.00    -2.482       1\n",
      "   10889      10889      -0.62     -0.48     40.00    -2.482       2\n",
      "   10890      10890      -1.00     -0.78     60.00    -2.482       3\n",
      "   10891      10891      -1.39     -1.08     80.00    -2.482       4\n",
      "   11670      11670      -4.69     -3.36    140.00    -2.521       7\n",
      "   11671      11671      -5.40     -3.86    160.00    -2.521       8\n",
      "   11696      11696       0.23     -0.63     20.00    -1.220       1\n",
      "   11697      11697       0.61     -1.67     40.00    -1.220       2\n",
      "   11832      11832      -0.27     -0.01     20.00    -3.088       1\n",
      "   11834      11834      -1.18     -0.06     60.00    -3.088       3\n",
      "   11835      11835      -1.63     -0.09     80.00    -3.088       4\n",
      "   11836      11836      -2.08     -0.11    100.00    -3.088       5\n",
      "   12168      12168      -0.43      0.83     20.00     2.054       1\n",
      "   12169      12169      -1.16      2.20     40.00     2.054       2\n",
      "   12304      12304      -0.61     -0.45     20.00    -2.506       1\n",
      "   12305      12305      -1.63     -1.20     40.00    -2.506       2\n",
      "   12616      12616      -0.12      0.23     20.00     2.050       1\n",
      "   12617      12617      -0.32      0.62     40.00     2.050       2\n",
      "   12618      12618      -0.52      1.00     60.00     2.050       3\n",
      "   12623      12623      -1.52      2.93    160.00     2.050       8\n",
      "   12619      12619      -0.72      1.39     80.00     2.050       4\n",
      "   12622      12622      -1.32      2.54    140.00     2.050       7\n",
      "   12620      12620      -0.92      1.77    100.00     2.050       5\n",
      "   12621      12621      -1.12      2.16    120.00     2.050       6\n",
      "   12984      12984       0.22     -1.08     20.00    -1.369       1\n",
      "   12985      12985       0.59     -2.87     40.00    -1.369       2\n",
      "   13032      13032       0.35     -0.18     20.00    -0.477       1\n",
      "   13033      13033       0.93     -0.48     40.00    -0.477       2\n",
      "   13034      13034       1.51     -0.78     60.00    -0.477       3\n",
      "   13035      13035       2.09     -1.08     80.00    -0.477       4\n",
      "   13036      13036       2.67     -1.38    100.00    -0.477       5\n",
      "   13037      13037       3.25     -1.68    120.00    -0.477       6\n",
      "   13038      13038       3.83     -1.98    140.00    -0.477       7\n",
      "   13039      13039       4.42     -2.28    160.00    -0.477       8\n",
      "   13136      13136       1.05     -0.38     20.00    -0.348       1\n",
      "   13137      13137       2.81     -1.02     40.00    -0.348       2\n",
      "   13138      13138       4.56     -1.65     60.00    -0.348       3\n",
      "   13808      13808      -0.40      0.06     20.00     2.996       1\n",
      "   13809      13809      -1.06      0.16     40.00     2.996       2\n",
      "   13812      13812      -3.06      0.45    100.00     2.996       5\n",
      "   13813      13813      -3.72      0.55    120.00     2.996       6\n",
      "   13984      13984       0.70     -0.09     20.00    -0.133       1\n",
      "   13985      13985       1.88     -0.25     40.00    -0.133       2\n",
      "   14016      14016      -0.02     -0.03     20.00    -2.157       1\n",
      "   14017      14017      -0.06     -0.08     40.00    -2.157       2\n",
      "   14400      14400      -0.51      0.06     20.00     3.019       1\n",
      "   14401      14401      -1.52      0.19     40.00     3.019       2\n",
      "   15214      15214      -6.16      0.71    140.00     3.027       7\n",
      "   15215      15215      -7.10      0.81    160.00     3.027       8\n",
      "   15504      15504      -0.14      0.05     20.00     2.828       1\n",
      "   15506      15506      -0.70      0.23     60.00     2.828       3\n",
      "   15508      15508      -1.26      0.41    100.00     2.828       5\n",
      "   15509      15509      -1.54      0.50    120.00     2.828       6\n",
      "   15888      15888      -0.59      0.08     20.00     3.005       1\n",
      "   15889      15889      -1.77      0.24     40.00     3.005       2\n",
      "   15913      15913      -0.55     -1.05     40.00    -2.052       2\n",
      "   15914      15914      -0.92     -1.76     60.00    -2.052       3\n",
      "   15915      15915      -1.28     -2.46     80.00    -2.052       4\n",
      "   15916      15916      -1.65     -3.16    100.00    -2.052       5\n",
      "   15918      15918      -2.38     -4.57    140.00    -2.052       7\n",
      "   15919      15919      -2.75     -5.27    160.00    -2.052       8\n",
      "   16648      16648      -0.11      0.04     20.00     2.824       1\n",
      "   16649      16649      -0.34      0.11     40.00     2.824       2\n",
      "   16650      16650      -0.57      0.19     60.00     2.824       3\n",
      "   16664      16664       0.24      0.13     20.00     0.485       1\n",
      "   16669      16669       2.62      1.38    120.00     0.485       6\n",
      "   16670      16670       3.10      1.63    140.00     0.485       7\n",
      "   16671      16671       3.57      1.88    160.00     0.485       8\n",
      "   16665      16665       0.71      0.38     40.00     0.485       2\n",
      "   16666      16666       1.19      0.63     60.00     0.485       3\n",
      "   16667      16667       1.67      0.88     80.00     0.485       4\n",
      "   16668      16668       2.14      1.13    100.00     0.485       5\n",
      "   16689      16689       0.47     -0.45     40.00    -0.756       2\n",
      "   16690      16690       0.79     -0.75     60.00    -0.756       3\n",
      "   16772      16772      -0.77     -2.44    100.00    -1.878       5\n",
      "   16773      16773      -0.95     -2.98    120.00    -1.878       6\n",
      "   16774      16774      -1.12     -3.52    140.00    -1.878       7\n",
      "   16775      16775      -1.29     -4.06    160.00    -1.878       8\n",
      "   16889      16889       0.35      0.87     40.00     1.189       2\n",
      "   16890      16890       0.58      1.44     60.00     1.189       3\n",
      "   16891      16891       0.81      2.02     80.00     1.189       4\n",
      "   16892      16892       1.04      2.60    100.00     1.189       5\n",
      "   16893      16893       1.28      3.18    120.00     1.189       6\n",
      "   16894      16894       1.51      3.76    140.00     1.189       7\n",
      "   16895      16895       1.74      4.33    160.00     1.189       8\n",
      "   17008      17008       0.60      0.37     20.00     0.546       1\n",
      "   17009      17009       1.80      1.10     40.00     0.546       2\n",
      "   17200      17200       1.28     -0.06     20.00    -0.049       1\n",
      "   17201      17201       3.84     -0.19     40.00    -0.049       2\n",
      "   17233      17233      -0.63     -0.74     40.00    -2.271       2\n",
      "   17234      17234      -1.04     -1.24     60.00    -2.271       3\n",
      "   17235      17235      -1.46     -1.73     80.00    -2.271       4\n",
      "   17236      17236      -1.88     -2.23    100.00    -2.271       5\n",
      "   17237      17237      -2.29     -2.72    120.00    -2.271       6\n",
      "   17537      17537      -1.32     -1.42     40.00    -2.317       2\n",
      "   17538      17538      -2.19     -2.37     60.00    -2.317       3\n",
      "   17539      17539      -3.07     -3.32     80.00    -2.317       4\n",
      "   17540      17540      -3.95     -4.27    100.00    -2.317       5\n",
      "   17541      17541      -4.83     -5.22    120.00    -2.317       6\n",
      "   17542      17542      -5.71     -6.17    140.00    -2.317       7\n",
      "   17543      17543      -6.58     -7.12    160.00    -2.317       8\n",
      "   17786      17786      -0.72     -2.45     60.00    -1.857       3\n",
      "   17787      17787      -1.01     -3.43     80.00    -1.857       4\n",
      "   17788      17788      -1.30     -4.41    100.00    -1.857       5\n",
      "\n",
      "--------------------------------------------------------\n",
      " All 420 ghost hits found by the function find_tracks()\n",
      "--------------------------------------------------------\n",
      "\n",
      "   Hit Index   Hit ID      x         y         z       Theta    Module ID\n",
      "      80         80       1.75      1.38     20.00     0.669       1\n",
      "     136        136      -0.69      0.57     20.00     2.446       1\n",
      "     200        200       0.69     -0.99     20.00    -0.963       1\n",
      "     256        256       0.45     -0.32     20.00    -0.615       1\n",
      "     656        656       0.23      0.46     20.00     1.113       1\n",
      "     657        657       0.48      0.97     40.00     1.113       2\n",
      "     856        856       0.22     -1.12     20.00    -1.376       1\n",
      "     880        880      -1.44     -0.68     20.00    -2.699       1\n",
      "     928        928       1.12      1.10     20.00     0.774       1\n",
      "    1176       1176       0.12     -0.09     20.00    -0.658       1\n",
      "    1179       1179       0.53     -0.41     80.00    -0.658       4\n",
      "    1180       1180       0.66     -0.51    100.00    -0.658       5\n",
      "    1183       1183       1.07     -0.83    160.00    -0.658       8\n",
      "    1283       1283      -3.40      3.75     80.00     2.307       4\n",
      "    1384       1384      -1.46      0.74     20.00     2.676       1\n",
      "    1464       1464      -1.89      0.00     20.00     3.140       1\n",
      "    1568       1568      -0.05     -1.12     20.00    -1.612       1\n",
      "    1664       1664      -0.40     -1.31     20.00    -1.866       1\n",
      "    2464       2464      -0.34      0.18     20.00     2.659       1\n",
      "    2465       2465      -0.77      0.40     40.00     2.659       2\n",
      "    2466       2466      -1.19      0.63     60.00     2.659       3\n",
      "    2467       2467      -1.62      0.85     80.00     2.659       4\n",
      "    2468       2468      -2.05      1.07    100.00     2.659       5\n",
      "    2544       2544       0.53      0.65     20.00     0.879       1\n",
      "    2656       2656      -0.91      0.48     20.00     2.658       1\n",
      "    2761       2761      -0.87     -0.31     40.00    -2.798       2\n",
      "    2856       2856       0.83      0.60     20.00     0.621       1\n",
      "    2936       2936       0.15     -0.12     20.00    -0.698       1\n",
      "    2937       2937       0.33     -0.28     40.00    -0.698       2\n",
      "    3008       3008       0.34     -0.82     20.00    -1.181       1\n",
      "    3009       3009       0.76     -1.85     40.00    -1.181       2\n",
      "    3010       3010       1.18     -2.87     60.00    -1.181       3\n",
      "    3011       3011       1.60     -3.90     80.00    -1.181       4\n",
      "    3012       3012       2.03     -4.93    100.00    -1.181       5\n",
      "    3015       3015       3.29     -8.01    160.00    -1.181       8\n",
      "    3088       3088       0.38      0.75     20.00     1.103       1\n",
      "    3304       3304      -0.71     -0.67     20.00    -2.387       1\n",
      "    3305       3305      -1.61     -1.51     40.00    -2.387       2\n",
      "    3336       3336       0.71     -0.84     20.00    -0.868       1\n",
      "    3488       3488       0.00     -0.56     20.00    -1.568       1\n",
      "    3489       3489       0.00     -1.26     40.00    -1.568       2\n",
      "    3496       3496      -0.23      0.78     20.00     1.858       1\n",
      "    3520       3520      -0.21      0.01     20.00     3.111       1\n",
      "    3521       3521      -0.47      0.01     40.00     3.111       2\n",
      "    3522       3522      -0.73      0.02     60.00     3.111       3\n",
      "    3527       3527      -2.03      0.06    160.00     3.111       8\n",
      "    3560       3560       0.51     -0.80     20.00    -1.007       1\n",
      "    3584       3584       0.41     -0.54     20.00    -0.915       1\n",
      "    3656       3656      -1.37      0.46     20.00     2.817       1\n",
      "    3657       3657      -3.09      1.04     40.00     2.817       2\n",
      "    3744       3744      -0.33      0.16     20.00     2.698       1\n",
      "    3750       3750      -2.81      1.34    140.00     2.698       7\n",
      "    3751       3751      -3.23      1.53    160.00     2.698       8\n",
      "    3770       3770      -1.58      0.41     60.00     2.888       3\n",
      "    3822       3822       4.91      1.13    140.00     0.226       7\n",
      "    3823       3823       5.64      1.29    160.00     0.226       8\n",
      "    3872       3872       1.04      0.33     20.00     0.312       1\n",
      "    4312       4312      -0.18      0.42     20.00     1.975       1\n",
      "    4456       4456       1.65     -1.06     20.00    -0.572       1\n",
      "    4793       4793       0.76     -0.66     40.00    -0.721       2\n",
      "    4795       4795       1.60     -1.40     80.00    -0.721       4\n",
      "    4798       4798       2.86     -2.51    140.00    -0.721       7\n",
      "    4799       4799       3.28     -2.88    160.00    -0.721       8\n",
      "    4896       4896       0.01     -0.51     20.00    -1.552       1\n",
      "    5000       5000       0.36     -0.25     20.00    -0.606       1\n",
      "    5001       5001       0.82     -0.57     40.00    -0.606       2\n",
      "    5002       5002       1.27     -0.88     60.00    -0.606       3\n",
      "    5003       5003       1.73     -1.20     80.00    -0.606       4\n",
      "    5004       5004       2.18     -1.51    100.00    -0.606       5\n",
      "    5213       5213      -1.97      4.75    120.00     1.964       6\n",
      "    5328       5328       0.07     -0.90     20.00    -1.492       1\n",
      "    5744       5744       0.07     -0.74     20.00    -1.474       1\n",
      "    5762       5762      -3.23     -1.38     60.00    -2.737       3\n",
      "    5763       5763      -4.39     -1.88     80.00    -2.737       4\n",
      "    5784       5784      -0.46      0.03     20.00     3.068       1\n",
      "    5785       5785      -1.03      0.08     40.00     3.068       2\n",
      "    5952       5952      -0.51     -2.16     20.00    -1.805       1\n",
      "    6082       6082       0.35      1.08     60.00     1.260       3\n",
      "    6083       6083       0.47      1.48     80.00     1.260       4\n",
      "    6292       6292      -4.14      0.51    100.00     3.019       5\n",
      "    6293       6293      -5.02      0.62    120.00     3.019       6\n",
      "    6294       6294      -5.90      0.73    140.00     3.019       7\n",
      "    6295       6295      -6.78      0.84    160.00     3.019       8\n",
      "    6480       6480      -0.35      0.12     20.00     2.815       1\n",
      "    6481       6481      -0.85      0.29     40.00     2.815       2\n",
      "    6482       6482      -1.35      0.46     60.00     2.815       3\n",
      "    6487       6487      -3.85      1.30    160.00     2.815       8\n",
      "    6504       6504       0.82     -1.14     20.00    -0.949       1\n",
      "    6608       6608       0.33     -0.28     20.00    -0.706       1\n",
      "    6613       6613       2.72     -2.32    120.00    -0.706       6\n",
      "    6632       6632       0.26     -1.47     20.00    -1.399       1\n",
      "    6912       6912       0.30     -0.33     20.00    -0.821       1\n",
      "    6913       6913       0.74     -0.79     40.00    -0.821       2\n",
      "    6914       6914       1.17     -1.25     60.00    -0.821       3\n",
      "    6915       6915       1.60     -1.72     80.00    -0.821       4\n",
      "    7016       7016       0.76      0.16     20.00     0.204       1\n",
      "    7064       7064       0.41     -0.04     20.00    -0.088       1\n",
      "    7067       7067       2.19     -0.19     80.00    -0.088       4\n",
      "    7104       7104       0.17      0.81     20.00     1.363       1\n",
      "    7256       7256       0.36      0.65     20.00     1.068       1\n",
      "    7257       7257       0.87      1.59     40.00     1.068       2\n",
      "    7258       7258       1.38      2.52     60.00     1.068       3\n",
      "    7360       7360       1.05     -0.13     20.00    -0.121       1\n",
      "    7384       7384       0.62      0.34     20.00     0.501       1\n",
      "    7560       7560      -0.89      0.03     20.00     3.110       1\n",
      "    7624       7624       1.00     -0.04     20.00    -0.036       1\n",
      "    7912       7912      -0.61     -1.10     20.00    -2.078       1\n",
      "    8106       8106       3.36     -2.39     60.00    -0.619       3\n",
      "    8632       8632      -0.61     -0.01     20.00    -3.118       1\n",
      "    9136       9136      -0.14     -0.08     20.00    -2.630       1\n",
      "    9143       9143      -1.53     -0.86    160.00    -2.630       8\n",
      "    9144       9144       0.32      0.01     20.00     0.031       1\n",
      "    9147       9147       1.72      0.05     80.00     0.031       4\n",
      "    9148       9148       2.18      0.07    100.00     0.031       5\n",
      "    9149       9149       2.64      0.08    120.00     0.031       6\n",
      "    9150       9150       3.11      0.10    140.00     0.031       7\n",
      "    9151       9151       3.57      0.11    160.00     0.031       8\n",
      "    9464       9464      -0.29     -0.78     20.00    -1.932       1\n",
      "    9552       9552       0.21     -0.52     20.00    -1.188       1\n",
      "    9553       9553       0.51     -1.27     40.00    -1.188       2\n",
      "    9560       9560       0.41      0.32     20.00     0.663       1\n",
      "    9576       9576      -0.50      0.86     20.00     2.101       1\n",
      "    9624       9624      -0.38     -0.02     20.00    -3.089       1\n",
      "    9625       9625      -0.93     -0.05     40.00    -3.089       2\n",
      "    9626       9626      -1.48     -0.08     60.00    -3.089       3\n",
      "    9627       9627      -2.03     -0.11     80.00    -3.089       4\n",
      "    9664       9664       1.38     -0.48     20.00    -0.334       1\n",
      "    9688       9688      -0.56      0.02     20.00     3.113       1\n",
      "   10024      10024       0.37     -0.16     20.00    -0.401       1\n",
      "   10167      10167      -3.30     -4.04    160.00    -2.255       8\n",
      "   10368      10368       0.84     -0.36     20.00    -0.407       1\n",
      "   10416      10416       0.76     -0.38     20.00    -0.464       1\n",
      "   10504      10504       0.09     -0.86     20.00    -1.467       1\n",
      "   10664      10664       1.64      0.86     20.00     0.482       1\n",
      "   10704      10704       0.31     -0.34     20.00    -0.843       1\n",
      "   10892      10892      -1.78     -1.38    100.00    -2.482       5\n",
      "   10893      10893      -2.16     -1.68    120.00    -2.482       6\n",
      "   10894      10894      -2.55     -1.98    140.00    -2.482       7\n",
      "   10895      10895      -2.93     -2.27    160.00    -2.482       8\n",
      "   10992      10992       0.29      2.36     20.00     1.449       1\n",
      "   11008      11008       0.71     -0.26     20.00    -0.355       1\n",
      "   11032      11032      -0.03      0.49     20.00     1.624       1\n",
      "   11128      11128      -1.29     -0.21     20.00    -2.982       1\n",
      "   11168      11168      -0.73     -0.59     20.00    -2.459       1\n",
      "   11617      11617       0.50      0.54     40.00     0.820       2\n",
      "   11816      11816       0.36      0.43     20.00     0.879       1\n",
      "   11817      11817       0.95      1.15     40.00     0.879       2\n",
      "   11833      11833      -0.72     -0.04     40.00    -3.088       2\n",
      "   11837      11837      -2.54     -0.14    120.00    -3.088       6\n",
      "   11838      11838      -2.99     -0.16    140.00    -3.088       7\n",
      "   11839      11839      -3.44     -0.19    160.00    -3.088       8\n",
      "   12072      12072      -0.68      0.18     20.00     2.877       1\n",
      "   12073      12073      -1.81      0.49     40.00     2.877       2\n",
      "   12080      12080       1.13     -0.35     20.00    -0.298       1\n",
      "   12264      12264       0.61      0.52     20.00     0.708       1\n",
      "   12306      12306      -2.65     -1.95     60.00    -2.506       3\n",
      "   12432      12432      -0.02      0.33     20.00     1.621       1\n",
      "   12472      12472       0.63      0.75     20.00     0.868       1\n",
      "   12976      12976       0.05     -0.77     20.00    -1.501       1\n",
      "   12977      12977       0.14     -2.06     40.00    -1.501       2\n",
      "   13144      13144      -0.44     -2.06     20.00    -1.781       1\n",
      "   13272      13272      -0.20     -0.65     20.00    -1.863       1\n",
      "   13432      13432       0.86      0.22     20.00     0.252       1\n",
      "   13680      13680      -0.95      1.30     20.00     2.204       1\n",
      "   13810      13810      -1.73      0.25     60.00     2.996       3\n",
      "   13811      13811      -2.39      0.35     80.00     2.996       4\n",
      "   13814      13814      -4.39      0.64    140.00     2.996       7\n",
      "   13815      13815      -5.05      0.74    160.00     2.996       8\n",
      "   14018      14018      -0.09     -0.13     60.00    -2.157       3\n",
      "   14019      14019      -0.12     -0.19     80.00    -2.157       4\n",
      "   14020      14020      -0.16     -0.24    100.00    -2.157       5\n",
      "   14021      14021      -0.19     -0.29    120.00    -2.157       6\n",
      "   14022      14022      -0.23     -0.34    140.00    -2.157       7\n",
      "   14023      14023      -0.26     -0.39    160.00    -2.157       8\n",
      "   14280      14280       0.58      0.70     20.00     0.882       1\n",
      "   14416      14416      -0.83     -0.68     20.00    -2.451       1\n",
      "   14600      14600      -0.47     -0.18     20.00    -2.781       1\n",
      "   14744      14744      -0.17      0.44     20.00     1.941       1\n",
      "   14745      14745      -0.51      1.31     40.00     1.941       2\n",
      "   14920      14920      -0.66     -0.20     20.00    -2.847       1\n",
      "   14944      14944      -0.84     -0.14     20.00    -2.979       1\n",
      "   15056      15056       0.05     -0.18     20.00    -1.291       1\n",
      "   15057      15057       0.15     -0.54     40.00    -1.291       2\n",
      "   15060      15060       0.46     -1.61    100.00    -1.291       5\n",
      "   15104      15104       0.67      0.79     20.00     0.872       1\n",
      "   15152      15152       0.28      0.37     20.00     0.927       1\n",
      "   15153      15153       0.83      1.10     40.00     0.927       2\n",
      "   15169      15169       0.45     -1.94     40.00    -1.340       2\n",
      "   15184      15184       0.08     -0.35     20.00    -1.340       1\n",
      "   15216      15216      -0.22     -0.05     20.00    -2.916       1\n",
      "   15408      15408      -0.98      0.31     20.00     2.836       1\n",
      "   15480      15480      -0.19      0.15     20.00     2.492       1\n",
      "   15481      15481      -0.58      0.44     40.00     2.492       2\n",
      "   15505      15505      -0.42      0.14     40.00     2.828       2\n",
      "   15507      15507      -0.98      0.32     80.00     2.828       4\n",
      "   15510      15510      -1.83      0.59    140.00     2.828       7\n",
      "   15511      15511      -2.11      0.68    160.00     2.828       8\n",
      "   15840      15840      -0.20      0.08     20.00     2.748       1\n",
      "   15841      15841      -0.60      0.25     40.00     2.748       2\n",
      "   15912      15912      -0.18     -0.35     20.00    -2.052       1\n",
      "   15917      15917      -2.02     -3.87    120.00    -2.052       6\n",
      "   15944      15944       0.37     -0.03     20.00    -0.076       1\n",
      "   16055      16055      -4.73      0.91    160.00     2.952       8\n",
      "   16272      16272      -1.33      0.46     20.00     2.810       1\n",
      "   16480      16480       0.45     -0.59     20.00    -0.917       1\n",
      "   16632      16632      -0.78     -0.53     20.00    -2.545       1\n",
      "   16651      16651      -0.80      0.26     80.00     2.824       4\n",
      "   16652      16652      -1.03      0.34    100.00     2.824       5\n",
      "   16653      16653      -1.25      0.41    120.00     2.824       6\n",
      "   16654      16654      -1.48      0.49    140.00     2.824       7\n",
      "   16655      16655      -1.71      0.56    160.00     2.824       8\n",
      "   16691      16691       1.11     -1.04     80.00    -0.756       4\n",
      "   16768      16768      -0.09     -0.27     20.00    -1.878       1\n",
      "   16769      16769      -0.26     -0.81     40.00    -1.878       2\n",
      "   16770      16770      -0.43     -1.35     60.00    -1.878       3\n",
      "   16771      16771      -0.60     -1.90     80.00    -1.878       4\n",
      "   16800      16800       0.28      0.03     20.00     0.096       1\n",
      "   16801      16801       0.83      0.08     40.00     0.096       2\n",
      "   16802      16802       1.38      0.13     60.00     0.096       3\n",
      "   16803      16803       1.93      0.19     80.00     0.096       4\n",
      "   16804      16804       2.48      0.24    100.00     0.096       5\n",
      "   16805      16805       3.04      0.29    120.00     0.096       6\n",
      "   16806      16806       3.59      0.35    140.00     0.096       7\n",
      "   16807      16807       4.14      0.40    160.00     0.096       8\n",
      "   16888      16888       0.12      0.29     20.00     1.189       1\n",
      "   16976      16976       0.86      0.42     20.00     0.458       1\n",
      "   17080      17080      -0.71      0.76     20.00     2.324       1\n",
      "   17232      17232      -0.21     -0.25     20.00    -2.271       1\n",
      "   17238      17238      -2.71     -3.22    140.00    -2.271       7\n",
      "   17239      17239      -3.13     -3.71    160.00    -2.271       8\n",
      "   17392      17392      -0.42     -1.18     20.00    -1.910       1\n",
      "   17408      17408       0.13      0.35     20.00     1.207       1\n",
      "   17536      17536      -0.44     -0.47     20.00    -2.317       1\n",
      "   17784      17784      -0.14     -0.49     20.00    -1.857       1\n",
      "   17785      17785      -0.43     -1.47     40.00    -1.857       2\n",
      "   17789      17789      -1.59     -5.39    120.00    -1.857       6\n",
      "   17790      17790      -1.88     -6.37    140.00    -1.857       7\n",
      "   17791      17791      -2.17     -7.35    160.00    -1.857       8\n",
      "   17848      17848      -0.30      0.24     20.00     2.473       1\n",
      "   17944      17944      -0.68      0.79     20.00     2.285       1\n",
      "   18008      18008       0.51      0.35     20.00     0.603       1\n",
      "   18048          0       4.07     15.18     80.00     1.309       4\n",
      "   18049          0     -16.15      8.73     80.00     2.646       4\n",
      "   18050          0      -9.58     -4.11    120.00    -2.737       6\n",
      "   18051          0       9.69      1.28     40.00     0.131       2\n",
      "   18052          0      -9.15     -6.13     40.00    -2.551       2\n",
      "   18053          0       9.57      5.87    120.00     0.550       6\n",
      "   18054          0      10.45    -15.81     80.00    -0.986       4\n",
      "   18055          0      -8.24      9.95     20.00     2.263       1\n",
      "   18056          0     -12.56      0.41     40.00     3.109       2\n",
      "   18057          0      -4.60      6.84    160.00     2.163       8\n",
      "   18058          0      -5.28     -2.70    120.00    -2.669       6\n",
      "   18059          0      -3.52      8.50     20.00     1.964       1\n",
      "   18060          0      -4.28      2.57     80.00     2.600       4\n",
      "   18061          0      -7.28     -8.07    100.00    -2.305       5\n",
      "   18062          0       5.78     -6.33     60.00    -0.830       3\n",
      "   18063          0     -12.57     12.80    160.00     2.347       8\n",
      "   18064          0       5.88     -0.06    160.00    -0.011       8\n",
      "   18065          0      -9.70    -14.23    160.00    -2.169       8\n",
      "   18066          0     -15.46     15.30     60.00     2.361       3\n",
      "   18067          0      -5.76     -1.42     80.00    -2.900       4\n",
      "   18068          0       1.79      7.55     40.00     1.338       2\n",
      "   18069          0      -6.91      1.44    140.00     2.936       7\n",
      "   18070          0       2.71      3.84    140.00     0.956       7\n",
      "   18071          0      -9.21     -5.01     80.00    -2.644       4\n",
      "   18072          0      14.22    -12.50     80.00    -0.721       4\n",
      "   18073          0      14.08      3.85    160.00     0.267       8\n",
      "   18074          0      -4.51     -7.33    100.00    -2.122       5\n",
      "   18075          0       4.94      8.17     60.00     1.027       3\n",
      "   18076          0     -11.87     -6.49     80.00    -2.641       4\n",
      "   18077          0     -10.93    -13.70     20.00    -2.244       1\n",
      "   18078          0     -13.63     -3.25     20.00    -2.907       1\n",
      "   18079          0      15.95     16.49     20.00     0.802       1\n",
      "   18080          0       1.59      7.75    160.00     1.369       8\n",
      "   18081          0      10.74      0.16     60.00     0.015       3\n",
      "   18082          0       9.07      3.86    140.00     0.403       7\n",
      "   18083          0       4.86      5.10    120.00     0.810       6\n",
      "   18084          0      -1.65     -4.75     80.00    -1.905       4\n",
      "   18085          0      -8.19      8.30    160.00     2.350       8\n",
      "   18086          0      -6.19    -14.22    100.00    -1.981       5\n",
      "   18087          0     -10.81     -7.52    140.00    -2.534       7\n",
      "   18088          0      -0.60    -10.30     60.00    -1.629       3\n",
      "   18089          0      -7.91     -4.04    160.00    -2.670       8\n",
      "   18090          0      -5.26    -13.18    140.00    -1.950       7\n",
      "   18091          0      15.13     12.86    140.00     0.705       7\n",
      "   18092          0      -2.62     -1.85     40.00    -2.526       2\n",
      "   18093          0       2.30      4.07     60.00     1.057       3\n",
      "   18095          0      -3.24     -3.12     20.00    -2.376       1\n",
      "   18096          0     -11.78      9.30     20.00     2.473       1\n",
      "   18097          0       2.88     12.33     20.00     1.341       1\n",
      "   18098          0     -12.01     16.38    160.00     2.203       8\n",
      "   18099          0       6.33     -6.62    120.00    -0.808       6\n",
      "   18100          0       4.05     10.91    100.00     1.215       5\n",
      "   18101          0       4.98    -11.22    160.00    -1.153       8\n",
      "   18102          0      -7.31     -3.96     40.00    -2.645       2\n",
      "   18103          0       1.35     13.17    100.00     1.469       5\n",
      "   18104          0       3.21    -15.67     80.00    -1.369       4\n",
      "   18105          0      -7.30      5.38     40.00     2.506       2\n",
      "   18106          0      -6.12     -9.10    100.00    -2.163       5\n",
      "   18107          0     -16.25      6.76    140.00     2.747       7\n",
      "   18108          0      -9.94     12.36    160.00     2.248       8\n",
      "   18109          0     -14.13     -6.59    120.00    -2.705       6\n",
      "   18110          0     -11.97      5.35     80.00     2.721       4\n",
      "   18111          0      -7.82     15.99     20.00     2.026       1\n",
      "   18112          0       1.98     -9.47    120.00    -1.365       6\n",
      "   18113          0     -11.34      6.59    100.00     2.615       5\n",
      "   18114          0     -13.99     14.18    100.00     2.349       5\n",
      "   18115          0      -4.75      2.32    100.00     2.688       5\n",
      "   18116          0      -8.80      3.99    140.00     2.716       7\n",
      "   18117          0       0.05      2.52    120.00     1.549       6\n",
      "   18118          0      11.57     -8.90    140.00    -0.656       7\n",
      "   18119          0       4.49     14.65    140.00     1.274       7\n",
      "   18120          0       4.83      0.96     40.00     0.197       2\n",
      "   18121          0       1.44     -2.06     40.00    -0.959       2\n",
      "   18122          0       4.67     -2.98    140.00    -0.569       7\n",
      "   18123          0      -9.31     -0.69     80.00    -3.067       4\n",
      "   18124          0     -11.48      2.24     60.00     2.949       3\n",
      "   18125          0       8.55     -5.89     80.00    -0.603       4\n",
      "   18126          0      -7.47     16.25     80.00     2.002       4\n",
      "   18127          0       7.34     -7.97     60.00    -0.826       3\n",
      "   18128          0      16.40    -13.61     60.00    -0.693       3\n",
      "   18129          0      13.29    -14.64     80.00    -0.834       4\n",
      "   18130          0      15.70      0.82     80.00     0.052       4\n",
      "   18131          0       1.22     -6.46    100.00    -1.384       5\n",
      "   18132          0       0.91    -15.76    120.00    -1.513       6\n",
      "   18133          0       8.54      0.89     20.00     0.104       1\n",
      "   18134          0     -14.03    -16.02     60.00    -2.290       3\n",
      "   18135          0      -2.95     -6.19    120.00    -2.015       6\n",
      "   18136          0       4.63     -0.31     60.00    -0.067       3\n",
      "   18137          0     -10.10      5.87    160.00     2.615       8\n",
      "   18138          0      11.14    -15.28    120.00    -0.941       6\n",
      "   18139          0       4.66      8.87     40.00     1.086       2\n",
      "   18140          0      -1.08     -0.99     40.00    -2.396       2\n",
      "   18141          0      11.42     -5.33     40.00    -0.437       2\n",
      "   18142          0      -7.95      5.74     40.00     2.516       2\n",
      "   18143          0      -4.93     -8.88    140.00    -2.078       7\n",
      "   18144          0      -1.08     -1.94    160.00    -2.079       8\n",
      "   18145          0      -7.66      8.76     40.00     2.289       2\n",
      "   18146          0       7.15     -7.68     60.00    -0.821       3\n",
      "   18147          0     -13.56      9.15     40.00     2.548       2\n",
      "   18148          0       9.87     13.09    140.00     0.925       7\n",
      "   18149          0      -0.17     -1.93    160.00    -1.661       8\n",
      "   18150          0      -3.75     -2.13     80.00    -2.625       4\n",
      "   18151          0      14.42    -11.15     40.00    -0.658       2\n",
      "   18152          0     -13.54      1.78    100.00     3.011       5\n",
      "   18153          0      14.35      2.07     60.00     0.143       3\n",
      "   18154          0      11.38    -14.02     20.00    -0.889       1\n",
      "   18155          0      -2.25      0.13     80.00     3.085       4\n",
      "   18156          0      14.50      3.04    100.00     0.206       5\n",
      "   18157          0      -0.50     12.84    120.00     1.610       6\n",
      "   18158          0       3.08     -7.68     60.00    -1.189       3\n",
      "   18159          0     -12.31      7.01     80.00     2.624       4\n",
      "   18160          0      -3.52      6.09     80.00     2.095       4\n",
      "   18161          0      13.97    -14.39     80.00    -0.800       4\n",
      "   18162          0      -0.20     -1.58     60.00    -1.694       3\n",
      "   18163          0      -1.71     11.13     80.00     1.723       4\n",
      "   18164          0      13.89      9.81    140.00     0.615       7\n",
      "   18165          0      -0.95    -14.30     80.00    -1.637       4\n",
      "   18166          0      12.37    -10.10    140.00    -0.685       7\n",
      "   18167          0      -0.11      5.80     40.00     1.591       2\n",
      "   18168          0      -2.96     12.66     20.00     1.800       1\n",
      "   18169          0       2.49    -10.78    140.00    -1.344       7\n",
      "   18170          0       1.87      9.15     80.00     1.369       4\n",
      "   18171          0       3.31     -5.13    100.00    -0.998       5\n",
      "   18172          0      10.10     15.92    160.00     1.005       8\n",
      "   18173          0       6.65    -12.24     40.00    -1.073       2\n",
      "   18174          0      -0.53      2.01    100.00     1.828       5\n",
      "   18175          0      14.38     11.62     60.00     0.679       3\n",
      "   18176          0     -12.98     -0.63    140.00    -3.093       7\n",
      "   18177          0       3.99     14.42    160.00     1.301       8\n",
      "   18178          0      -3.35     12.78     60.00     1.827       3\n",
      "   18179          0     -12.31     10.56    140.00     2.432       7\n",
      "   18180          0       8.36     -6.04    140.00    -0.626       7\n",
      "   18181          0      -8.85     -1.32    120.00    -2.994       6\n",
      "   18182          0      12.26      8.55     20.00     0.609       1\n",
      "   18183          0     -13.70     -2.07     60.00    -2.992       3\n",
      "   18184          0       9.44     11.80    120.00     0.896       6\n",
      "   18185          0      -5.23     14.43    120.00     1.919       6\n",
      "   18186          0      -0.40      2.80    140.00     1.713       7\n",
      "   18187          0       6.45     11.53     60.00     1.061       3\n",
      "   18188          0      -2.49      0.95     80.00     2.777       4\n",
      "   18189          0      -2.44     12.60     40.00     1.762       2\n",
      "   18190          0       2.86     -3.93     60.00    -0.942       3\n",
      "   18191          0       4.92     14.79    160.00     1.250       8\n",
      "   18192          0      -8.72      7.68    140.00     2.420       7\n",
      "   18193          0       3.96     -8.55    160.00    -1.137       8\n",
      "   18194          0      -4.12      4.77    160.00     2.282       8\n",
      "   18195          0       9.01      3.41     60.00     0.362       3\n",
      "   18196          0      14.44     -1.46    140.00    -0.101       7\n",
      "   18197          0      15.05      2.02    160.00     0.133       8\n",
      "   18198          0      -2.55      3.15    160.00     2.252       8\n",
      "   18199          0      -9.91     -7.43     80.00    -2.498       4\n",
      "   18200          0      -5.68     -0.64    120.00    -3.029       6\n",
      "   18201          0     -15.66      3.98    160.00     2.893       8\n",
      "   18202          0      11.73     13.81     40.00     0.867       2\n",
      "   18203          0      -3.04    -15.21     20.00    -1.768       1\n",
      "   18204          0      10.41      0.45     60.00     0.043       3\n",
      "   18205          0      -6.96     -5.29     20.00    -2.491       1\n",
      "   18206          0     -16.41      9.61    100.00     2.612       5\n",
      "   18207          0      -2.48     -0.39     60.00    -2.984       3\n",
      "   18208          0       1.95     16.21    160.00     1.451       8\n",
      "   18209          0      -8.54    -14.22    140.00    -2.112       7\n",
      "   18210          0       3.55     -2.82    160.00    -0.671       8\n",
      "   18211          0      12.19     -4.30    140.00    -0.339       7\n",
      "   18212          0      -5.08     -3.16    100.00    -2.585       5\n",
      "   18213          0      -3.00      0.48     20.00     2.982       1\n",
      "   18214          0      -7.92     -3.36    140.00    -2.741       7\n",
      "   18215          0      -5.88     -4.62     60.00    -2.476       3\n",
      "   18216          0      15.76      0.89    120.00     0.056       6\n",
      "   18217          0      -7.90     -3.05    160.00    -2.774       8\n",
      "   18218          0     -13.82     -4.59    160.00    -2.821       8\n",
      "   18219          0     -14.03     12.75     40.00     2.404       2\n",
      "   18220          0      15.18     -5.49     20.00    -0.347       1\n",
      "   18221          0      -4.08      5.32    160.00     2.225       8\n",
      "   18222          0      -5.77      3.95    160.00     2.541       8\n",
      "   18223          0      12.89     -1.68    140.00    -0.129       7\n",
      "   18224          0      -2.27    -16.20     40.00    -1.710       2\n",
      "   18225          0      -5.55    -12.79    160.00    -1.981       8\n",
      "   18226          0      -1.61      6.77    160.00     1.804       8\n",
      "   18227          0      -2.30     -5.75    160.00    -1.952       8\n",
      "\n",
      "Classical processing - Duration (h): 0.0047 - Power consumption (kWh): 0.0000\n"
     ]
    }
   ],
   "source": [
    "My_HHL.run_simulation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# LHCb_VeLo_Toy_Model_1-Bit_HHL\n",
       "Fast particle track reconstruction in the LHCb VELO using classical angle sorting and Ising-like optimization.\n",
       "\n",
       "# The Large Hadron Collider beauty (LHCb) experiment at CERN\n",
       "The LHCb experiment at CERN is a general-purpose detector at the Large Hadron Collider (LHC) that specializes in investigating the subtle differences between matter and antimatter by studying a type of particle called the *beauty quark*, or *b quark*.\n",
       "\n",
       "It uses a series of subdetectors to detect mainly forward particles—those produced in one forward direction by the collision. The first subdetector is mounted close to the collision point, with the others following sequentially over a length of 20 meters.\n",
       "\n",
       "The 5600-tonne LHCb detector consists of a forward spectrometer and planar detectors. It is 21 meters long, 10 meters high, and 13 meters wide, and is located 100 meters underground near the town of Ferney-Voltaire, France.\n",
       "\n",
       "As of 2024, the collaboration includes more than 1600 members from 98 institutes in 22 countries, including around 1100 authors.\n",
       "\n",
       "Source: [https://home.cern/science/experiments/lhcb](https://home.cern/science/experiments/lhcb)\n",
       "\n",
       "### LHCb Taking a closer look at LHC\n",
       "[LHC-1] [The Large Hadron Collider beauty (LHCb) experiment](https://home.cern/science/experiments/lhcb)\n",
       "\n",
       "[LHC-2] [LHCb Taking a closer look at LHC](https://www.lhc-closer.es/taking_a_closer_look_at_lhc/0.lhcb)\n",
       "\n",
       "---\n",
       "\n",
       "# Particle track reconstruction in the LHCb Vertex Locator (VELO)\n",
       "In the High-Luminosity phase of the Large Hadron Collider (HL-LHC), thousands of particles are produced simultaneously. These particles leave energy hits in detector layers, which are reconstructed into particle tracks. Tracks reveal primary vertices (collision points).\n",
       "\n",
       "Tracks in the LHCb Vertex Locator (VELO) can be modeled as straight lines intersecting the *z*-axis, since the VELO is the subdetector closest to the LHCb collision point and experiences a negligible magnetic field.\n",
       "\n",
       "---\n",
       "\n",
       "## Classical sort-by-angle (θ) particle track reconstruction\n",
       "In the *XY* projection, these straight lines pass through the origin. As a result, energy hits are expected to have a nearly constant phase in polar coordinates when projected onto the *XY* plane (see Section 3, *Search by triplet — Sort by φ*, in [ALGO-4](https://arxiv.org/pdf/2207.03936)).\n",
       "\n",
       "We have developed the following functions:\n",
       "\n",
       "* `plot_hits_polar()`, which displays a polar plot (in radians) of hits projected onto the *XY* plane.\n",
       "  Example:\n",
       "  [Polar_Plot_8_p_6_l_noiseless.png](https://github.com/AlainChance/LHCb_VeLo_Toy_Model_1-Bit_HHL/blob/main/8_particles/6_layers/Noiseless/Polar_Plot_8_p_6_l_noiseless.png)\n",
       "* `cluster_by_last_column()`, which clusters hits by the polar angle `theta` in the last column of a hit array.\n",
       "* `create_tracks()`, which builds a single track from a cluster of hits (no clone splitting here).\n",
       "* `segment_intersects_z_axis()`, which checks whether a line intersects the *z*-axis and computes the corresponding primary vertex.\n",
       "* `find_tracks()`, which reconstructs tracks from these clusters and identifies all primary vertices.\n",
       "\n",
       "## Split clone tracks by direction\n",
       "We have developed the function `split_clone_by_direction()` which splits a θ-cluster into physically distinct clone tracks by clustering the 3D direction vectors of consecutive hit segments. A θ-cluster groups hits with similar azimuthal angle φ. When multiple particles share nearly identical φ (common in dense VELO-like geometries), they may be merged into a single cluster. These \"clone clusters\" must be separated into individual tracks. The most stable discriminator between clone tracks is the *direction* of their local segments. For a true straight track, the direction vector between consecutive modules is nearly constant. Clone tracks, even if close in φ, exhibit distinct 3D directions.\n",
       "\n",
       "### Efficient implementation\n",
       "The function `find_tracks()` successfully reconstructs toy events with several thousand particles in well under a second, as demonstrated in the following Jupyter notebooks:\n",
       "\n",
       "* [1024_particles/7_layers/Find_tracks](https://github.com/AlainChance/LHCb_VeLo_Toy_Model_1-Bit_HHL/blob/main/1024_particles/7_layers/Find_tracks/HHL_1024_particles_7_layers_find_tracks.ipynb)\n",
       "* [2256_particles/8_layers/Find_tracks](https://github.com/AlainChance/LHCb_VeLo_Toy_Model_1-Bit_HHL/blob/main/2256_particles/8_layers/Find_tracks/HHL_2256_particles_8_layers_find_tracks.ipynb)\n",
       "* [5000_particles/7_layers/Find_tracks](https://github.com/AlainChance/LHCb_VeLo_Toy_Model_1-Bit_HHL/blob/main/5000_particles/7_layers/Find_tracks/HHL_5000_particles_7_layers_find_tracks.ipynb)\n",
       "\n",
       "### Note on computational complexity\n",
       "The computational bottleneck in the function `cluster_by_last_column()` is the comparison-based sorting step, for which both classical and bounded-error quantum query complexities are $O(n. \\log n)$; quantum algorithms do not reduce the asymptotic number of comparisons required.\n",
       "\n",
       "Høyer, P.; Neerbek, J.; Shi, Y. (2001). *Quantum complexities of ordered searching, sorting, and element distinctness*.\n",
       "28th International Colloquium on Automata, Languages, and Programming. Lecture Notes in Computer Science, Vol. 2076, pp. 62–73.\n",
       "[arXiv:quant-ph/0102078](https://arxiv.org/abs/quant-ph/0102078)\n",
       "\n",
       "### Efficient algorithms for track reconstruction\n",
       "[ALGO-1] [Alain Chancé, A Toy Model For Reconstructing Particle Tracks at LHCb at CERN with Quantum Computing, 30 Oct. 2025, LHCb_VeLo_Toy_Model_1-Bit_HHL.pdf](https://github.com/AlainChance/LHCb_VeLo_Toy_Model_1-Bit_HHL/blob/main/LHCb_VeLo_Toy_Model_1-Bit_HHL.pdf)\n",
       "\n",
       "[ALGO-2] [Aaij, R., Adinolfi, M., Aiola, S. et al. A Comparison of CPU and GPU Implementations for the LHCb Experiment Run 3 Trigger. Comput Softw Big Sci 6, 1 (2022)](https://doi.org/10.1007/s41781-021-00070-2)\n",
       "\n",
       "[ALGO-3] [Daniel Campora, Track reconstruction made easy, 2021](https://github.com/dcampora/velopix_tracking)\n",
       "\n",
       "[ALGO-4] [Cámpora Pérez, D. H., Neufeld, N. & Riscos Núñez, A. Search by triplet: An efficient local track reconstruction algorithm\n",
       "for parallel architectures. J. Comput. Sci. 54, 101422, DOI: 10.1016/j.jocs.2021.101422 (2021)](https://arxiv.org/pdf/2207.03936)\n",
       "\n",
       "[ALGO-5] [Aaij, R., Albrecht, J., Belous, M. et al. Allen: A High-Level Trigger on GPUs for LHCb. Comput Softw Big Sci 4, 7 (2020). https://doi.org/10.1007/s41781-020-00039-7](https://doi.org/10.1007/s41781-020-00039-7)\n",
       "\n",
       "[ALGO-6] [The CMS Collaboration, Description and performance of track and primary-vertex reconstruction with the CMS tracker, arXiv:1405.6569v2, physics.ins-det, 28 Oct 2014](https://doi.org/10.48550/arXiv.1405.6569)\n",
       "\n",
       "[ALGO-7] [Primary Vertex Reconstruction at LHCb, LHCb-PUB-2014-044, October 21, 2014](https://cds.cern.ch/record/1756296/files/LHCb-PUB-2014-044.pdf)\n",
       "\n",
       "---\n",
       "\n",
       "## Ising-like optimization using matrix inversion\n",
       "The Hamiltonian $𝐻(𝑆)$ is parametrized in terms of doublets $𝑆$, these doublets are possible connections between two hits in subsequent detector layers and take a binary value to indicate if they actively contribute to a track, $S_i \\in${0, 1}. It includes three terms:\n",
       "\n",
       "- The angular term $𝐻_{𝑎𝑛𝑔}$ is the most important as it determines if a set of doublets $𝑆_𝑖$ and $𝑆_𝑗$ are aligned within $\\varepsilon$.\n",
       "- $𝐻_{spec}(𝑆)$ makes the spectrum of $A$ positive.\n",
       "- $𝐻_{gap}(𝑆)$ ensures gap in the solution spectrum.\n",
       "\n",
       "$$𝐻(𝑆) = 𝐻_{𝑎𝑛𝑔}(𝑆,\\varepsilon)+\\gamma𝐻_{spec}(𝑆)+\\delta𝐻_{gap}(𝑆)$$\n",
       "\n",
       "$$H_{\\text{ang}}(S,\\varepsilon) = -\\frac{1}{2} \\left[ \\sum_{abc} f(\\theta_{abc}, \\varepsilon) S_{ab} S_{bc} \\right]$$\n",
       "\n",
       "$$𝐻_{spec}(𝑆)=\\sum_{𝑎𝑏} 𝑆_{𝑎𝑏}^2$$\n",
       "\n",
       "$$𝐻_{gap}(𝑆)=\\sum_{𝑎𝑏} (1−2S_{𝑎𝑏})^2)$$\n",
       "\n",
       "$$\n",
       "f(\\theta_{abc}, \\varepsilon) =\n",
       "\\begin{cases}\n",
       "1 & \\text{if } \\cos(\\theta_{abc}) \\geq 1 - \\varepsilon \\\\\n",
       "0 & \\text{otherwise}\n",
       "\\end{cases}\n",
       "$$\n",
       "\n",
       "$$𝐻(𝑆)=−\\frac{1}{2} \\left[\\sum_{abc} f(\\theta_{abc}, \\varepsilon) S_{ab} S_{bc} + \\gamma\\sum_{𝑎𝑏} 𝑆_{𝑎𝑏}^2 + \\delta\\sum_{𝑎𝑏} (1−2S_{𝑎𝑏} )^2\\right]$$ \n",
       "\n",
       "By relaxing $𝑆_𝑖\\inℝ$, we find its minimum by taking the derivative of the quadratic $𝐻$, obtaining a system of linear equations:\n",
       "\n",
       "$$∇_𝑆 H=−AS+b=0,  AS=b$$\n",
       "\n",
       "Matrix inversion yields the solution of reconstructed tracks. The resulting vector $𝑆$ of real values is subsequently discretized to obtain an \"on\"/\"off\" status by setting a threshold $𝑇$.\n",
       "\n",
       "---\n",
       "\n",
       "## Solving the system of linear equations classically\n",
       "The function `classical_simulation()` of the class `One_Bit_HHL` in the module `One_Bit_HHL_Simulation.py` uses only the first three layers of the toy event created by the function `setup_events()` in the same module.\n",
       "\n",
       "The system of linear equations $𝐴𝑆=𝑏$ is solved using [scipy.sparse.linalg.cg](https://docs.scipy.org/doc/scipy-1.12.0/reference/generated/scipy.sparse.linalg.cg.html):\n",
       "\n",
       "```python\n",
       "sol, _ = sci.sparse.linalg.cg(A, vector_b, atol=0)\n",
       "```\n",
       "The discretized solution is obtained by setting a threshold `T_classical` in the list of configuration parameters `param`:\n",
       "```python\n",
       "T_classical = param[\"T_classical\"]\n",
       "disc_sol = (sol > T_classical).astype(int)\n",
       "```\n",
       "\n",
       "---\n",
       "\n",
       "## Solving the system of linear equations with the 1-Bit HHL algorithm\n",
       "The Harrow–Hassidim–Lloyd (HHL) algorithm promises a complexity improvement over the best classical alternatives for solving sparse systems of linear equations. However, its practical implementation faces considerable challenges. The Quantum Phase Estimation (QPE) step results in prohibitively deep circuits, making the algorithm unfeasible on currently available hardware short of fault-tolerant quantum computing.\n",
       "\n",
       "The 1-Bit HHL algorithm, presented in the paper [TrackHHL: A Quantum Computing Algorithm for Track Reconstruction at the LHCb](https://doi.org/10.1051/epjconf/202533701181), applies a first-order Suzuki–Trotter decomposition to approximate the time-evolution operator. By restricting the QPE accuracy to a single bit, the algorithm can efficiently determine whether a phase is close to zero or significantly different.\n",
       "\n",
       "The function `HHL_simulation()` of the class `One_Bit_HHL` in the module `One_Bit_HHL_Simulation.py` uses only the first three layers of the toy event created by the function `setup_events()` in the same module.\n",
       "\n",
       "The discretized solution is obtained by setting a threshold `T_hhl` in the list of configuration parameters `param`:\n",
       "```python\n",
       "T_hhl = param[\"T_hhl\"]\n",
       "disc_x_hhl = (x_hhl > T_hhl).astype(int)\n",
       "```\n",
       "\n",
       "---\n",
       "\n",
       "### TrackHHL: A Quantum Computing Algorithm for Track Reconstruction at the LHCb\n",
       "[TRHHL-1] [Xenofon Chiotopoulos, Davide Nicotra, George Scriven, Kurt Driessens, Marcel Merk, Jochen Schütz, Jacco de Vries, Mark H.M. Winands, TrackHHL: The 1-Bit Quantum Filter for particle trajectory reconstruction, 12 Jan 2026, arXiv:2601.07766](https://doi.org/10.48550/arXiv.2601.07766)\n",
       "\n",
       "[TRHHL-2] [Xenofon Chiotopoulos, TrackHHL: A Quantum Computing Algorithm for Track Reconstruction at the LHCb](https://cds.cern.ch/record/2950969/files/document.pdf)\n",
       "\n",
       "[TRHHL-3] [Xenofon Chiotopoulos, Miriam Lucio Martinez, Davide Nicotra, Jacco A. de Vries, Kurt Driessens, Marcel Merk, and Mark H.M. Winands, TrackHHL: A Quantum Computing Algorithm for Track Reconstruction at the LHCb, EPJ Web of Conferences 337, 01181 (2025)](https://doi.org/10.1051/epjconf/202533701181)\n",
       "\n",
       "[TRHHL-4] [Okawa, Hideki, Quantum Algorithms for Track Reconstruction at High Energy Colliders, Workshop of Tracking in Particle Physics Experiments, May 17-19, 2024](https://indico.ihep.ac.cn/event/21775/contributions/155907/attachments/78247/97329/okawa_QTrack_20240517.pdf)\n",
       "\n",
       "[TRHHL-5] [D. Nicotra et al., arXiv:2308.00619v2, 7 Oct 2023, A quantum algorithm for track reconstruction in the LHCb vertex detector](https://arxiv.org/pdf/2308.00619)\n",
       "\n",
       "---\n",
       "\n",
       "## Efficient implementation of the Ising-like optimization\n",
       "\n",
       "### Fast construction of the Hamiltonian $H(S)$\n",
       "The function `construct_segments()` of the class `SimpleHamiltonian` in the module [toy_model/simple_hamiltonian.py](https://github.com/AlainChance/LHCb_VeLo_Toy_Model_1-Bit_HHL/blob/main/toy_model/simple_hamiltonian.py) is enhanced to identify segments with matching values of `theta` during their creation and to append them to the list `segment_in_indices`, along with their corresponding segment IDs in the list `segment_indices`. The function `construct_hamiltonian()` then considers only doublets $S_i$ and $S_j$ of segments in `segment_in_indices`. This modification significantly improves the performance of the preprocessing step.\n",
       "\n",
       "---\n",
       "\n",
       "### Smart error detection and recovery\n",
       "In his talk [*Dynamic Circuit and Error Detection* (QDC 2025)](https://www.youtube.com/watch?v=GO7fiYEKIVw), Alireza Seif pointed out that the sampling overhead of quantum error mitigation (QEM) scales exponentially with circuit size, while quantum error correction (QEC) requires a large number of qubits (see the slide titled *“Quantum Error Mitigation – Quantum Error Correction”*, around 0:30 in the talk).\n",
       "\n",
       "Quantum error detection (QED) uses additional qubits to reduce sampling costs and operates in a single-shot manner, similar to QEC. Alireza also explained that one way to achieve QEC is by measuring conserved quantities of a physical system.\n",
       "\n",
       "We apply a quantum error detection approach as a post-processing step consistent with the IBM Qiskit pattern methodology (*Post-process results*):\n",
       "\n",
       "*“This can involve a range of classical data-processing steps, such as … or post-selection based on inherent properties of the problem …”*\n",
       "\n",
       "(see [Introduction to Qiskit patterns](https://quantum.cloud.ibm.com/docs/en/guides/intro-to-patterns)).\n",
       "\n",
       "The function `get_tracks_smart()` of the class `One_Bit_HHL` in\n",
       "[One_Bit_HHL_Simulation.py](https://github.com/AlainChance/LHCb_VeLo_Toy_Model_1-Bit_HHL/blob/main/One_Bit_HHL_Simulation.py)\n",
       "performs the following steps:\n",
       "\n",
       "* Identifies active segments in the first three layers from both the classical solution and the 1-bit HHL quantum solution\n",
       "* Reconstructs tracks using only segments that intersect the z-axis\n",
       "* Adds missed segments intersecting the z-axis and extends active segments to all outer layers\n",
       "\n",
       "The function `segment_intersects_z_axis()` computes segment–axis intersections. The intersection points define the reconstructed primary vertices.\n",
       "\n",
       "The function `analyze_p_vertices()` clusters and summarizes primary-vertex candidates identified by `segment_intersects_z_axis()`. It groups vertices by z-value and returns averaged primary-vertex (PV) positions.\n",
       "\n",
       "A simulated primary vertex is considered reconstructed if a vertex is found within 2 mm of its true position. See *Primary Vertex Reconstruction Efficiency and Resolution* in [ALGO-2]:\n",
       "[Aaij, R., Adinolfi, M., Aiola, S. et al. *A Comparison of CPU and GPU Implementations for the LHCb Experiment Run 3 Trigger*. Comput Softw Big Sci 6, 1 (2022)](https://doi.org/10.1007/s41781-021-00070-2).\n",
       "\n",
       "---\n",
       "\n",
       "### Quantum error mitigation, detection, and correction\n",
       "\n",
       "[ERR-1] [Ian Hincks — *Samplomatic and Its Use Cases* (QDC 2025)](https://www.youtube.com/watch?v=mZB3SxQMsiI)\n",
       "\n",
       "[ERR-2] [Andrew Eddins — *Error Mitigation Landscape* (QDC 2025)](https://www.youtube.com/watch?v=ix52wx4_zek)\n",
       "\n",
       "[ERR-3] [Alireza Seif — *Dynamic Circuit and Error Detection* (QDC 2025)](https://www.youtube.com/watch?v=GO7fiYEKIVw)\n",
       "\n",
       "[ERR-4] [Maika Takita — *Dynamic Circuit and Error Detection* (QDC 2025)](https://www.youtube.com/watch?v=rs3nlhRK7So)\n",
       "\n",
       "[ERR-5] [van den Berg, E., Minev, Z. K., Kandala, A. et al.\n",
       "*Probabilistic error cancellation with sparse Pauli–Lindblad models on noisy quantum processors.*\n",
       "Nat. Phys. 19, 1116–1121 (2023). https://doi.org/10.1038/s41567-023-02042-2](https://doi.org/10.1038/s41567-023-02042-2)\n",
       "\n",
       "---\n",
       "\n",
       "# Installation\n",
       "\n",
       "## Requirements\n",
       "Be sure you have the following installed:\n",
       "\n",
       "* Qiskit SDK v2.1 or later, with visualization support (`pip install 'qiskit[visualization]'`)\n",
       "* 'qiskit-aer' library (`pip install qiskit-aer`)\n",
       "* Qiskit runtime 0.40 or later (`pip install qiskit-ibm-runtime`)\n",
       "* [eco2AI](https://github.com/sb-ai-lab/Eco2AI) is optional (`pip install eco2ai`)\n",
       "\n",
       "## Clone the repository LHCb_VeLo_Toy_Model_1-Bit_HHL\n",
       "`git clone https://github.com/AlainChance/LHCb_VeLo_Toy_Model_1-Bit_HHL`\n",
       "\n",
       "---\n",
       "\n",
       "# Set-up your own 1-Bit HHL track simulation toy model simulation\n",
       "Duplicate the Jupyter notebook [HHL_1024_particles_7_layers_find_tracks.ipynb](https://github.com/AlainChance/LHCb_VeLo_Toy_Model_1-Bit_HHL/blob/main/1024_particles/7_layers/Find_tracks/HHL_1024_particles_7_layers_find_tracks.ipynb), rename it and customize the configuration parameters:\n",
       "```python\n",
       "config = {\n",
       "    #--------------------\n",
       "    # Simulation options\n",
       "    #--------------------\n",
       "    \"dz\": 20,                           # layer spacing (mm)\n",
       "    \"layers\": 7,                        # Number of layers\n",
       "    \"n_particles\": [256, 256, 256, 256],    # Number of particles\n",
       "    \"p_vertices\": [(0,0,4), (0,0,6), (0,0,8), (0,0,10)],  # Primary vertices\n",
       "    #------------------\n",
       "    # Noise parameters\n",
       "    #------------------\n",
       "    \"measurement_error\": 0.0,           # HIT RESOLUTION (sigma on measurement) (sigma)\n",
       "    \"collision_noise\": 1.0e-7,          # MULTIPLE SCATTERING (angular noise proxy)\n",
       "    \"ghost_rate\": 1e-2,                 # Ghost (fake) track rate\n",
       "    \"drop_rate\": 0.0,                   # Hit drop (inefficiency) rate\n",
       "    #-----------------\n",
       "    # Display options\n",
       "    #-----------------\n",
       "    \"display_particles\": False,         # Whether to display initial particle states\n",
       "    \"display_hits\": False,              # Whether to display hits\n",
       "    \"display_ghost_hits\": True,         # Whether to display ghost hits\n",
       "    \"display_tracks\": False,            # Whether to display events and ghost tracks\n",
       "    \"display_clusters\": False,          # Whether to display clusters found by find_tracks()\n",
       "    \"display_false_clusters\": True,     # Whether to display clusters rejected by find_tracks()\n",
       "    \"display_clone_splitting\": True,    # Whether to display clone splitting information\n",
       "    \"display_clustering\": True,         # Whether to display clustering information\n",
       "    \"do_plot_tracks\": False,            # Whether to plot events and ghost tracks \n",
       "    \"do_spectrum\": False,               # Whether to analyze the classical solution spectrum\n",
       "    \"do_print_counts\": False,           # Whether to print raw measurement counts\n",
       "    \"resolution\": 2000,                 # Resolution for plots of tracks - Increase for finer mesh\n",
       "    \"do_draw\": False,                   # Whether to draw the HHL circuit\n",
       "    #----------------------------------\n",
       "    # Classical find_tracks parameters\n",
       "    #----------------------------------\n",
       "    \"tol\": None,                        # Tolerance for floating point comparison\n",
       "    \"tol_clusters\": None,               # Tolerance for cluster_by_last_column()\n",
       "    \"tol_clone\": None,                  # Tolerance for decloning tracks\n",
       "    \"tol_intersects\": None,             # Tolerance for segment_intersects_z_axis()\n",
       "    #---------------------------------------------------------------------------------------------------------\n",
       "    # A simulated primary vertex is defined as reconstructed if a primary vertex is found within 2 mm \n",
       "    # of its true position. See Primary Vertex Reconstruction Efficiency and Resolution in [ALGO-2]\n",
       "    # [Aaij, R., Adinolfi, M., Aiola, S. et al. A Comparison of CPU and GPU Implementations for the LHCb \n",
       "    # Experiment Run 3 Trigger. Comput Softw Big Sci 6, 1 (2022)](https://doi.org/10.1007/s41781-021-00070-2)\n",
       "    #---------------------------------------------------------------------------------------------------------\n",
       "    \"tol_vertices\": None,               # Tolerance for clustering primary vertices (mm)\n",
       "    #---------------------------------------\n",
       "    # Classical diagonalisation run options\n",
       "    #---------------------------------------\n",
       "    \"do_solve_scipy\": False,            # Whether to solve classically using scipy.sparse.linalg.cg\n",
       "    \"T_classical\": None,                # Threshold for discretizing classical solutions\n",
       "    #------------------------------------------\n",
       "    # Files containing token (API key) and CRN\n",
       "    #------------------------------------------\n",
       "    \"token_file\": \"Token.txt\",          # Token file\n",
       "    \"CRN_file\": \"CRN.txt\",              # CRN file\n",
       "    #-------------------------------\n",
       "    # Quantum computing run options\n",
       "    #-------------------------------\n",
       "    \"T_hhl\": None,                                      # Threshold for discretizing 1-Bit HHL solutions - None: to be computed\n",
       "    \"backend_name\": \"AerSimulator noiseless\",           # AerSimulator noiseless or Fake QPU or real IBM cloud backend name\n",
       "    \"job_id\": None,                                     # job_id of a previously run job\n",
       "    \"run_on_QPU\": False,                                # Whether to run the quantum circuit on the target hardware\n",
       "    \"nshots\": 2000000,                                  # Number of shots\n",
       "    'opt_level': 1,                                     # Optimization level\n",
       "    \"poll_interval\": 5,                                 # Poll interval in seconds for job monitor\n",
       "    \"timeout\": 600,                                     # Time out in seconds for job monitor\n",
       "    #-------------------------------------\n",
       "    # eco2AI Tracker options\n",
       "    # https://github.com/sb-ai-lab/Eco2AI\n",
       "    #-------------------------------------\n",
       "    \"do_eco2ai\": True,                                   # Whether to use the eco2AI Tracker\n",
       "    \"project_name\": \"One_Bit_HHL\",                       # Project name\n",
       "    \"experiment_description\": \"HHL_1024_p_7_l_find_tracks\", # Experiment description\n",
       "    \"eco2ai_file_name\": \"HHL_1024_p_7_l_find_tracks.csv\",   # eco2AI file name\n",
       "    #---------------------------------------------------------------------------------\n",
       "    # Ballpark figure (kW) for the power consumption of the IBM cloud backend\n",
       "    # \"The power consumption of a quantum computer is about 15-25kW\"\n",
       "    # https://www.capgemini.com/insights/expert-perspectives/green-quantum-computing/\n",
       "    #---------------------------------------------------------------------------------\n",
       "    \"power_QPU\": 25,                    # Ballpark figure (kW) for the power consumption of the IBM cloud backend\n",
       "}\n",
       "```\n",
       "\n",
       "---\n",
       "\n",
       "# Credits\n",
       "The Jupyter notebooks in this repository [LHCb_VeLo_Toy_Model_1-Bit_HHL](https://github.com/AlainChance/LHCb_VeLo_Toy_Model_1-Bit_HHL) and the Python file [One_Bit_HHL_Simulation.py](https://github.com/AlainChance/LHCb_VeLo_Toy_Model_1-Bit_HHL/blob/main/One_Bit_HHL_Simulation.py) are derived from the following sources:\n",
       "\n",
       "* GitHub repository [OneBQF](https://github.com/Xenofon-Chiotopoulos/OneBQF/tree/main) owned by Xenofon Chiotopoulos and more specifically:\n",
       "   - Module [OneBQF.py](https://github.com/Xenofon-Chiotopoulos/OneBQF/blob/main/quantum_algorithms/OneBQF.py)\n",
       "   - Jupyter notebook [example.ipynb](https://github.com/Xenofon-Chiotopoulos/OneBQF/blob/main/example.ipynb).\n",
       "\n",
       "* GitHub repository [LHCb VELO Toy Model](https://github.com/GeorgeWilliam1999/LHCb_VeLo_Toy_Model/tree/main#lhcb-velo-toy-model) owned by George William Scriven, [GeorgeWilliam1999](https://orcid.org/0009-0004-9997-1647).\n",
       "\n",
       "* Relevant documentation can be found in the Jupyter notebook [Tracking Toy Model Demo](https://github.com/Xenofon-Chiotopoulos/Tracking_Toy_model/blob/main/example_notebook.ipynb) in the public repository [Tracking_Toy_model](https://github.com/Xenofon-Chiotopoulos/Tracking_Toy_model/tree/main) owned by Xenofon Chiotopoulos.\n",
       "\n",
       "---\n",
       "\n",
       "# Additions by Alain Chancé\n",
       "\n",
       "## Energetics Analysis\n",
       "* **Assumption:**\n",
       "  A ballpark estimate for a typical modern IBM-class superconducting quantum computer (including cryogenics and supporting infrastructure, while idle or lightly used) is approximately **15–25 kW**.\n",
       "  Source: [*Green Quantum Computing*, Capgemini, 8 May 2023](https://www.capgemini.com/insights/expert-perspectives/green-quantum-computing/).\n",
       "\n",
       "* The `One_Bit_HHL` class integrates the [eco2AI](https://github.com/sb-ai-lab/Eco2AI) tracking feature, a python library which accumulates statistics about power consumption and CO2 emission during running code. The Eco2AI is licensed under a [Apache licence 2.0](https://www.apache.org/licenses/LICENSE-2.0).\n",
       "\n",
       "## Quantum computing energetics\n",
       "[EN-1] [informatique quantique état de l’art, perspective et défis, Olivier Ezratty, SFGP, Paris, 5 novembre 2025](https://www.oezratty.net/Files/Conferences/Olivier%20Ezratty%20Informatique%20Quantique%20SFGP%20Nov2025.pdf) \n",
       "\n",
       "[EN-2] [Q2B25 Paris | Olivier Ezratty, Academic, Co Founder, Free Electron, EPITA, Quantum Energy Initiative, \n",
       "QC Ware, September 24-25 2025](https://www.youtube.com/watch?v=JVtm3pbesnA)\n",
       "\n",
       "---\n",
       "\n",
       "## Class ToleranceEstimator\n",
       "The class ToleranceEstimator provides unified statistical estimators for:\n",
       "  - φ-clustering tolerance (tol_clusters_est)\n",
       "  - clone-track splitting tolerance (tol_clone_est)\n",
       "\n",
       "```python\n",
       "class ToleranceEstimator:\n",
       "    \"\"\"\n",
       "    Unified statistical estimators for:\n",
       "      - φ-clustering tolerance (tol_clusters_est)\n",
       "      - clone-track splitting tolerance (tol_clone_est)\n",
       "    \"\"\"\n",
       "```\n",
       "### Function estimate_intra_cluster_theta_std\n",
       "```python\n",
       "    @staticmethod\n",
       "    def estimate_intra_cluster_theta_std(clusters, layers, \n",
       "                                         n_sample_clusters=5,\n",
       "                                         alpha=1.0,\n",
       "                                         tol_min=1e-4,\n",
       "                                         tol_max=1e-2):\n",
       "        \"\"\"\n",
       "        Estimate tol_clusters_est from intra-cluster θ spread.\n",
       "        \"\"\"\n",
       "        if len(clusters) == 0:\n",
       "            return None\n",
       "\n",
       "        sample_indices = np.random.choice(\n",
       "            len(clusters),\n",
       "            size=min(n_sample_clusters, len(clusters)),\n",
       "            replace=False\n",
       "        )\n",
       "\n",
       "        intra_stds = []\n",
       "\n",
       "        for ci in sample_indices:\n",
       "            c = clusters[ci]\n",
       "            if len(c) < 2:\n",
       "                continue\n",
       "\n",
       "            theta_vals = c[:, 6]\n",
       "\n",
       "            if len(theta_vals) > layers:\n",
       "                theta_vals = theta_vals[:layers]\n",
       "\n",
       "            intra_stds.append(np.std(theta_vals))\n",
       "\n",
       "        if not intra_stds:\n",
       "            return None\n",
       "\n",
       "        mean_std = np.mean(intra_stds)\n",
       "        tol = max(alpha * mean_std, tol_min)\n",
       "        tol = min(tol, tol_max)\n",
       "\n",
       "        return tol, mean_std\n",
       "```\n",
       "\n",
       "### Function estimate_clone_tolerance\n",
       "The scale factor alpha determines how many sigmas define a decloning boundary.\n",
       "```python\n",
       "    @staticmethod\n",
       "    def estimate_clone_tolerance(track_hits,\n",
       "                                 alpha=1.0,\n",
       "                                 tol_min=1e-6,\n",
       "                                 tol_max=1e-2,\n",
       "                                 alpha_dyn=True):\n",
       "\n",
       "        if len(track_hits) < 2:\n",
       "            return tol_min, 0.0\n",
       "\n",
       "        temp_segments = []\n",
       "        for i in range(len(track_hits) - 1):\n",
       "            # Only build a segment if module_id increases\n",
       "            if track_hits[i+1].module_id > track_hits[i].module_id:\n",
       "                s = Segment(\n",
       "                    hits=[track_hits[i], track_hits[i+1]],\n",
       "                    segment_id=i\n",
       "                )\n",
       "                temp_segments.append(s)\n",
       "\n",
       "        if not temp_segments:\n",
       "            return tol_min, 0.0\n",
       "\n",
       "        theta_seg_values = np.array([s.theta for s in temp_segments], dtype=float)\n",
       "        theta_seg_std = np.std(theta_seg_values)\n",
       "\n",
       "        #-------------------------------------------------------------------------------\n",
       "        # The scale factor alpha determines how many sigmas define a decloning boundary\n",
       "        # Adapt alpha dynamically\n",
       "        #-------------------------------------------------------------------------------\n",
       "        if alpha_dyn:\n",
       "            if theta_seg_std < 1.0e-6:\n",
       "                alpha = 1.0\n",
       "            elif theta_seg_std > 1.0e-3:\n",
       "                alpha = 1.5\n",
       "            else:\n",
       "                alpha = 1.2\n",
       "\n",
       "        tol_clone_est = max(alpha * theta_seg_std, tol_min)\n",
       "        tol_clone_est = min(tol_clone_est, tol_max)\n",
       "\n",
       "        return tol_clone_est, theta_seg_std\n",
       "```\n",
       "\n",
       "---\n",
       "\n",
       "## Module One_Bit_HHL_Simulation.py\n",
       "The module [One_Bit_HHL_Simulation.py](https://github.com/AlainChance/LHCb_VeLo_Toy_Model_1-Bit_HHL/blob/main/One_Bit_HHL_Simulation.py) defines a new class `One_Bit_HHL`.\n",
       "\n",
       "### New data structures of the class One_Bit_HHL\n",
       "The function `find_tracks()` of the class `One_Bit_HHL` in the module [One_Bit_HHL_Simulation.py](https://github.com/AlainChance/LHCb_VeLo_Toy_Model_1-Bit_HHL/blob/main/One_Bit_HHL_Simulation.py) creates the following data structures and stores them in the parameter list `self.param`:\n",
       "\n",
       "  - `hit_by_index`: dictionary keyed by the index of the `hit`. Indices are always unique, even when `hit_id` is not.\n",
       "  - `array_hits`: NumPy array of hits with `theta` as last column.\n",
       "\n",
       "```python\n",
       "hit_by_index = {i: hit for i, hit in enumerate(list_hits)}\n",
       "param[\"hit_by_index\"] = hit_by_index\n",
       "```\n",
       "\n",
       "```python\n",
       "array_hits = np.array([ [i, hit.hit_id, hit.x, hit.y, hit.z, hit.module_id, hit.theta] for i, hit in enumerate(list_hits) ], dtype=float)\n",
       "param[\"array_hits\"] = array_hits\n",
       "```\n",
       "\n",
       "The function `setup_Hamiltonian()` of the class `One_Bit_HHL` stores in the parameter list the following lists returned by the function `construct segments()` in the module `simple_hamiltonian.py`:\n",
       "\n",
       "```python\n",
       "    ham.construct_segments(event=event_tracks)\n",
       "\n",
       "    param[\"segment_indices\"] = ham.segment_indices\n",
       "    param[\"segment_in_indices\"] = ham.segment_in_indices\n",
       "```\n",
       "\n",
       "### New properties of the class SimpleHamiltonian\n",
       "The module [AlainChance/LHCb_VeLo_Toy_Model_1-Bit_HHL/toy_model/simple_hamiltonian.py](https://github.com/AlainChance/LHCb_VeLo_Toy_Model_1-Bit_HHL/blob/main/toy_model/simple_hamiltonian.py) is derived from the module [Xenofon-Chiotopoulos/OneBQF/toy_model/simple_hamiltonian.py](https://github.com/Xenofon-Chiotopoulos/OneBQF/blob/main/toy_model/simple_hamiltonian.py).\n",
       "\n",
       "The following properties have been added:\n",
       "  - `segment_in_indices`: list of segments with matching values of `theta`\n",
       "  - `segment_indices`: list of corresponding segment ID's\n",
       "\n",
       "```python\n",
       "    self.segment_indices = [segment.segment_id for segment in self.segment_in_indices]\n",
       "```\n",
       "\n",
       "### Updated data classes in the module state_event_model.py\n",
       "The module [AlainChance/LHCb_VeLo_Toy_Model_1-Bit_HHL/toy_model\n",
       "/state_event_model.py](https://github.com/AlainChance/LHCb_VeLo_Toy_Model_1-Bit_HHL/blob/main/toy_model/state_event_model.py) is derived from the module [Xenofon-Chiotopoulos/OneBQF/toy_model/state_event_model.py](https://github.com/Xenofon-Chiotopoulos/OneBQF/blob/main/toy_model/state_event_model.py).\n",
       "\n",
       "The following import statements have been added or updated:\n",
       "```python\n",
       "from dataclasses import dataclass, field\n",
       "import math\n",
       "```\n",
       "\n",
       "In the data class `Hit`, the following two fields have been added:\n",
       "  - `theta` stores the phase of a hit in polar coordinates when projected onto the XY plane\n",
       "  - `index`: stores the index of the hit in an array of hits\n",
       "\n",
       "```python\n",
       "theta: float = field(init=False)  # Phase in polar coordinates when projected onto the XY plane\n",
       "index: int = field(init=False)    # Index of the hit in an array of hits\n",
       "\n",
       "def __post_init__(self): \n",
       "    self.theta = math.atan2(self.y, self.x)\n",
       "    self.index = 0\n",
       "```\n",
       "\n",
       "In the data class `Segment`, new fields `module_id`, `track_id` and `theta` have been added:\n",
       "```python\n",
       "module_id: int = field(init=False)  # Module id of the hit in the outer module\n",
       "track_id: int = field(init=False)   # Track id of the hit in the outer module\n",
       "theta: float = field(init=False)    # Phase in polar coordinates when projected onto the XY plane\n",
       "\n",
       "def __post_init__(self):\n",
       "    self.module_id = self.hits[1].module_id\n",
       "    self.track_id = self.hits[1].track_id\n",
       "    self.theta = math.atan2(self.hits[1].y - self.hits[0].y, self.hits[1].x - self.hits[0].x)\n",
       "\n",
       "def p0(self):\n",
       "    return [self.hits[0].x, self.hits[0].y, self.hits[0].z]\n",
       "\n",
       "def p1(self):\n",
       "    return [self.hits[1].x, self.hits[1].y, self.hits[1].z]\n",
       "```\n",
       "\n",
       "In the data class `Event`, a new field `ghost_hits` has been added: \n",
       "```python\n",
       "ghost_hits: []\n",
       "```\n",
       "\n",
       "---\n",
       "\n",
       "## Anchoring clustering and clone splitting tolerances to the parameter collision noise\n",
       "The parameter `collision_noise` sets the angular noise scale in `theta` (or `phi`) according to the following rules:\n",
       "  - θ-clustering (φ-clustering): `tol_clusters` = `10 * collision_noise`\n",
       "  - clone tracks splitting: `tol_clone` = `3 * collision_noise`\n",
       "  - Tolerance for `segment_intersects_z_axis()`: `tol_intersects` = `1.0e4 * collision_noise`\n",
       "\n",
       "The `_init_` function of the of the class `One_Bit_HHL` in the module [One_Bit_HHL_Simulation.py](https://github.com/AlainChance/LHCb_VeLo_Toy_Model_1-Bit_HHL/blob/main/One_Bit_HHL_Simulation.py) sets the default parameters as follows:\n",
       "\n",
       "```python\n",
       "        if collision_noise is None:\n",
       "            collision_noise = 0.0\n",
       "            \n",
       "        if tol is None:\n",
       "            tol = 1.0e-7\n",
       "\n",
       "        if tol_clusters is None:\n",
       "            tol_clusters = max(10.0 * collision_noise, tol)\n",
       "\n",
       "        if tol_clone is None:\n",
       "            tol_clone = max(3.0 * collision_noise, tol)\n",
       "            \n",
       "        if tol_intersects is None:\n",
       "            tol_intersects = min(max(1.0e4 * collision_noise, tol), 2.0)\n",
       "\n",
       "        text = f\" Anchoring clustering and clone splitting tolerances of the classical function find_tracks() to the parameter collision noise\"\n",
       "        line = \"-\" * (len(text) + 1)\n",
       "        print(f\"\\n{line}\\n{text}\\n{line}\")\n",
       "        \n",
       "        print(f\"Multiple scattering collision noise, collision_noise: {collision_noise:.2e}\")\n",
       "        print(f\"Tolerance for floating point comparison, tol: {tol:.2e}\")\n",
       "        print(f\"Minimum value of the tolerance for clustering, cluster_by_last_column(), tol_clusters: {tol_clusters:.2e}\")\n",
       "        print(f\"Minimum value of the decloning tolerance, tol_clone: {tol_clone:.2e}\")\n",
       "        print(f\"Tolerance for segment_intersects_z_axis(), tol_intersects: {tol_intersects:.2e}\")\n",
       "```\n",
       "\n",
       "## Setting up the tolerance for clustering vertices\n",
       "The tolerance for clustering vertices is set to 1 mm with the aim of finding every primary vertex within 2 mm of its true position.\n",
       "  - Tolerance for clustering vertices: `tol_vertices` = `1.0`\n",
       "\n",
       "```python\n",
       "        if tol_vertices is None:\n",
       "            tol_vertices = 1.0    # 1 mm\n",
       "\n",
       "        print(f\"Tolerance for clustering vertices, tol_vertices: {tol_vertices:.2e}\")\n",
       "```\n",
       "\n",
       "---\n",
       "\n",
       "## New functions of the class One_Bit_HHL in the module One_Bit_HHL_Simulation.py\n",
       "The following functions are copied from the class SQD in [SQD_Alain.py](https://github.com/AlainChance/SQD_Alain/blob/main/SQD_Alain.py):\n",
       "  - setup_backend()\n",
       "  - check_size()\n",
       "  - get_QPU_usage()\n",
       "  - get_classical_power_usage()\n",
       "\n",
       "The following function is derived from the module [OneBQF/toy_model/simple_hamiltonian.py](https://github.com/Xenofon-Chiotopoulos/OneBQF/blob/main/toy_model/simple_hamiltonian.py):\n",
       "- find_segments() derived from function find_segments()\n",
       "\n",
       "New functions:\n",
       "  - analyze_p_vertices()\n",
       "  - check_intersection()\n",
       "  - classical_simulation()\n",
       "  - cluster_by_last_column()\n",
       "  - create_tracks()\n",
       "  - display_all_clusters()\n",
       "  - display_all_hits()\n",
       "  - display_all_tracks()\n",
       "  - display_p_vertices()\n",
       "  - find_tracks()\n",
       "  - gen_indices()\n",
       "  - get_tracks_smart()\n",
       "  - HHL_simulation()\n",
       "  - intersects_origin()\n",
       "  - intersects_z_axis()\n",
       "  - plot_event()\n",
       "  - plot_hits_polar()\n",
       "  - setup_Hamiltonian()\n",
       "  - run_qc()\n",
       "  - run_simulation()\n",
       "  - segment_intersects_z_axis()\n",
       "\n",
       "---\n",
       "\n",
       "### Function analyze_p_vertices\n",
       "This function clusters and summarizes primary-vertex candidates found by the function `segment_intersects_z_axis()` which performs segment–axis intersections. It groups vertices by z-value and returns averaged primary vertex (PV) positions. \n",
       "\n",
       "A simulated primary vertex is defined as reconstructed if a primary vertex is found within 2 mm of its true position. See *Primary Vertex Reconstruction Efficiency and Resolution*, in [ALGO-2]\n",
       "[Aaij, R., Adinolfi, M., Aiola, S. et al. A Comparison of CPU and GPU Implementations for the LHCb Experiment Run 3 Trigger. Comput Softw Big Sci 6, 1 (2022)](https://doi.org/10.1007/s41781-021-00070-2).\n",
       "\n",
       "```python\n",
       "    def analyze_p_vertices(self, found_p_vertices, tol_vertices):\n",
       "        \"\"\"\n",
       "        Cluster and summarize primary-vertex candidates found by segment–axis intersections.\n",
       "        Groups vertices by z-value and returns averaged PV positions.\n",
       "        \"\"\"\n",
       "\n",
       "        if not found_p_vertices:\n",
       "            return []\n",
       "\n",
       "        # Extract z-values\n",
       "        z_values = np.array([xyz[2] for xyz in found_p_vertices])\n",
       "\n",
       "        # Build array for 1-D clustering\n",
       "        array_z = np.array([[i, z] for i, z in enumerate(z_values)], dtype=float)\n",
       "\n",
       "        # Cluster by z using existing machinery\n",
       "        clusters = self.cluster_by_last_column(array_z, tol=tol_vertices)\n",
       "\n",
       "        primary_vertices = []\n",
       "        for cluster in clusters:\n",
       "            idxs = cluster[:,0].astype(int)\n",
       "            z_cluster = z_values[idxs]\n",
       "            z_mean = np.mean(z_cluster)\n",
       "\n",
       "            # x,y are zero in the toy-model, but we compute them anyway for future realism\n",
       "            x_mean = np.mean([found_p_vertices[i][0] for i in idxs])\n",
       "            y_mean = np.mean([found_p_vertices[i][1] for i in idxs])\n",
       "\n",
       "            primary_vertices.append((x_mean, y_mean, z_mean))\n",
       "\n",
       "        return primary_vertices\n",
       "```\n",
       "---\n",
       "\n",
       "### Function cluster_by_last_column\n",
       "This function clusters rows of a NumPy array whose last column values differ by less than `tol`. It uses NumPy plus sorting.\n",
       "\n",
       "**Input parameters**\n",
       "  - `arr`: NumPy array of floats\n",
       "  - `tol`: tolerance\n",
       "\n",
       "**Returns**\n",
       "  - `clusters`: list of rows clustered around the values of the last column.\n",
       "\n",
       "### Note on θ‑based clustering and why ordering is not required here\n",
       "1. Tracks in the LHCb Vertex Locator (VELO) can be modeled as straight lines intersecting the `z-axis` because it is the sub-detector closest to the LHCb collision point and it contains a negligible magnetic field. In the XY projection, these straight lines pass through the origin. As a result, energy hits are likely to have a constant phase in polar coordinates when projected onto the XY plane (see Section 3, *Search by triplet — Sort by φ*, in # [ALGO-10](https://arxiv.org/pdf/2207.03936)). Grouping by the phase θ naturally isolates hits belonging to the same azimuthal “slice” of the detector.\n",
       "\n",
       "2. The VELO geometry ensures that hits from different layers (`module_id`) but belonging to the same physical track will still share nearly identical θ values. This makes θ a robust and discriminating clustering variable even in the presence of noise, missing layers, or imperfect hit patterns.\n",
       "\n",
       "3. The purpose of sorting by θ inside this function is purely to identify contiguous groups within a tolerance. It does not impose any physical ordering on the hits themselves. The physical structure (layer ordering, radial separation, and full 3D coordinates) is carried by the hits, not by their position in the array.\n",
       "\n",
       "4. Downstream logic (track construction and `z-axis` intersection tests) relies on the geometry of the hits and segments, not on the order in which hits appear inside a cluster. As long as hits share a consistent θ, any pair of hits from the cluster forms a segment with the correct XY direction for physics-based validation.\n",
       "\n",
       "Because of these properties, θ‑based clustering is both efficient and physically grounded, and does not require preserving any particular hit order beyond grouping hits with similar θ values.\n",
       "\n",
       "```python\n",
       "    def cluster_by_last_column(self, arr, tol=1e-6):\n",
       "        arr = np.asarray(arr)\n",
       "        \n",
       "        # Sort by last column\n",
       "        idx = np.argsort(arr[:, -1])\n",
       "        arr_sorted = arr[idx]\n",
       "    \n",
       "        clusters = []\n",
       "        current_cluster = [arr_sorted[0]]\n",
       "    \n",
       "        for row in arr_sorted[1:]:\n",
       "            if abs(row[-1] - current_cluster[-1][-1]) <= tol:\n",
       "                current_cluster.append(row) \n",
       "            else: \n",
       "                clusters.append(np.array(current_cluster)) \n",
       "                current_cluster = [row] \n",
       "            \n",
       "        clusters.append(np.array(current_cluster))\n",
       "    \n",
       "        return clusters\n",
       "```\n",
       "\n",
       "---\n",
       "\n",
       "### Function create_tracks\n",
       "This function builds a single track from a cluster of hits (no clone splitting here). It mutates all lists in place and returns updated k.\n",
       "\n",
       "**Input parameters**\n",
       "  - cluster\n",
       "  - hit_by_index\n",
       "  - tol_intersects\n",
       "  - k\n",
       "  - found_segments\n",
       "  - found_tracks\n",
       "  - found_clusters\n",
       "  - found_p_vertices\n",
       "  - false_tracks\n",
       "  - false_clusters\n",
       "\n",
       "**Mutates**\n",
       "  - k\n",
       "  - found_segments\n",
       "  - found_tracks\n",
       "  - found_clusters\n",
       "  - found_p_vertices\n",
       "  - false_tracks\n",
       "  - false_clusters\n",
       "\n",
       "**Returns**\n",
       "  - k\n",
       "\n",
       "```python\n",
       "    def create_tracks(\n",
       "        self,\n",
       "        cluster,\n",
       "        hit_by_index,\n",
       "        tol_intersects,\n",
       "        k,\n",
       "        found_segments,\n",
       "        found_tracks,\n",
       "        found_clusters,\n",
       "        found_p_vertices,\n",
       "        false_tracks,\n",
       "        false_clusters\n",
       "    ):\n",
       "        \"\"\"\n",
       "        Build a single track from a cluster of hits (no clone splitting here).\n",
       "        Mutates all lists in place and returns updated k.\n",
       "        \"\"\"\n",
       "\n",
       "        # Extract hit indices (order preserved)\n",
       "        cluster_hit_indices = {int(x[0]) for x in cluster}\n",
       "\n",
       "        # Convert indices → Hit objects\n",
       "        track_hits = [hit_by_index[idx] for idx in cluster_hit_indices]\n",
       "\n",
       "        # Sort hits by module_id (inner → outer)\n",
       "        track_hits = sorted(track_hits, key=lambda h: h.module_id)\n",
       "\n",
       "        # If only one hit → nothing to build\n",
       "        if len(track_hits) == 1:\n",
       "            return k\n",
       "\n",
       "        # Build segments\n",
       "        track_segs = []\n",
       "        for idx in range(len(track_hits) - 1):\n",
       "            s = Segment(\n",
       "                hits=[track_hits[idx], track_hits[idx + 1]],\n",
       "                segment_id=idx\n",
       "            )\n",
       "            track_segs.append(s)\n",
       "            found_segments.append(s)\n",
       "\n",
       "        # Build Track object\n",
       "        track = Track(\n",
       "            track_id=k,\n",
       "            hits=track_hits,\n",
       "            segments=track_segs\n",
       "        )\n",
       "\n",
       "        # z-axis intersection test\n",
       "        intersects = self.segment_intersects_z_axis(\n",
       "            track.segments[0],\n",
       "            found_p_vertices,\n",
       "            tol=tol_intersects\n",
       "        )\n",
       "\n",
       "        if intersects:\n",
       "            found_tracks.append(track)\n",
       "            found_clusters.append(cluster)\n",
       "            k += 1\n",
       "        else:\n",
       "            false_tracks.append(track)\n",
       "            false_clusters.append(cluster)\n",
       "\n",
       "        return k\n",
       "```\n",
       "---\n",
       "\n",
       "### Function display_all_clusters\n",
       "This function displays all clusters given as input.\n",
       "\n",
       "**Input parameters**\n",
       "  - clusters: list of clusters\n",
       "  - text: header text or None\n",
       "\n",
       "**Displays**\n",
       "  - List of all clusters\n",
       "\n",
       "```python\n",
       "    def display_all_clusters(self, clusters, text=None):\n",
       "\n",
       "        if clusters:\n",
       "            s = f\" All {len(clusters)} \"\n",
       "\n",
       "            text = s + text if text else s\n",
       "            \n",
       "            line = \"-\" * (len(text) + 1)\n",
       "            print(f\"\\n{line}\\n{text}\\n{line}\")\n",
       "\n",
       "            k = 0\n",
       "            print(f\"\\n   Hit Index   Hit ID      x         y         z       Theta    Module ID\")\n",
       "            for cluster in clusters:\n",
       "                for x in cluster:\n",
       "                    print(f\"  {x[0]:6.0f}     {x[1]:6.0f}     {x[2]:6.2f}    {x[3]:6.2f}    {x[4]:6.2f}    {x[6]:6.3f}       {x[5]:.0f}\")\n",
       "                k += 1\n",
       "\n",
       "```\n",
       "\n",
       "---\n",
       "\n",
       "### Function display_all_hits\n",
       "This function displays all hits given as input.\n",
       "\n",
       "**Input parameters**\n",
       "  - hits: list of hits\n",
       "  - text: header text or None\n",
       "\n",
       "**Displays**\n",
       "  - List of all hits\n",
       "\n",
       "\n",
       "```python\n",
       "def display_all_hits(self, hits, text=None):\n",
       "\n",
       "        if text: \n",
       "            line = \"-\" * (len(text) + 1) \n",
       "            print(f\"\\n{line}\\n{text}\\n{line}\")\n",
       "\n",
       "        print(f\"\\n    Hit Index   Hit ID        x         y         z       Theta      Module ID\")\n",
       "\n",
       "        for hit in hits:\n",
       "            print(f\"    {hit.index:4d}        {hit.hit_id:4d}       {hit.x:6.2f}    {hit.y:6.2f}    {hit.z:6.2f}    {hit.theta:6.3f}       {hit.module_id:4d}\")\n",
       "\n",
       "        return\n",
       "```\n",
       "\n",
       "---\n",
       "\n",
       "### Function display_p_vertices\n",
       "This function displays a primary vertex or a list of primary vertices.\n",
       "\n",
       "Input parameters:\n",
       "  - list_p_vertices: list of primary vertices\n",
       "  - text: Header text or None\n",
       "\n",
       "Displays:\n",
       "  - List of primary vertices\n",
       "\n",
       "```python\n",
       "    def display_p_vertices(self, list_p_vertices, text=None):\n",
       "        if list_p_vertices:\n",
       "\n",
       "            k = len(list_p_vertices)\n",
       "\n",
       "            if k == 1:\n",
       "                s = f\" a primary vertex\"\n",
       "            else:\n",
       "                s = f\" {k} primary vertices\"\n",
       "\n",
       "            if text:\n",
       "                text = text + \" found\" + s\n",
       "            else:\n",
       "                text = \" Found\" + s \n",
       "\n",
       "            line = \"-\" * (len(text) + 1)\n",
       "            print(f\"\\n{line}\\n{text}\\n{line}\")\n",
       "            \n",
       "            for p in list_p_vertices:\n",
       "                print(f\"({p[0]:5.3f}, {p[1]:5.3f}, {p[2]:5.3f})\")\n",
       "        return\n",
       "```\n",
       "\n",
       "---\n",
       "\n",
       "### Function find_tracks\n",
       "This function finds tracks using the function `cluster_by_last_column()`, which find tracks from clusters rows of an array of hits around the polar coordinate $\\theta$.\n",
       "\n",
       "**Input parameter**\n",
       "  - List of hits.\n",
       "\n",
       "**Input from the parameter list**\n",
       "  - `layers`: number of layers\n",
       "  - `tol_clusters`: tolerance for `cluster_by_last_column()`\n",
       "  - `tol_intersects`: tolerance for `segment_intersects_z_axis()`\n",
       "  - `do_plot_tracks`\n",
       "  - `resolution`\n",
       "  - `display_tracks`\n",
       "  - `display_ghost_hits`\n",
       "  - `display_clusters`\n",
       "  - `display_false_clusters`\n",
       "  - `display_clone_splitting`\n",
       "\n",
       "**Returns in the parameter list found data**\n",
       "  - `hit_by_index`: dictionary keyed by the index of the hit\n",
       "  - `array_hits`: NumPy array of hits with `theta` as last column\n",
       "  - `ghost_clusters`: list of ghost clusters\n",
       "  - `false_clusters`: list of false clusters\n",
       "  - `found_tracks`: list of tracks\n",
       "  - `found_segments`: list of found segments\n",
       "  - `found ghost_hits`: list of ghost hits\n",
       "  - `false_tracks`: list of tracks that do not intersect the z-axis\n",
       "  - `found_p_vertices`: list of primary vertices\n",
       "  - `found_event`: reconstructed event of the class `Event` defined in `state_event_model.py`\n",
       "\n",
       "**Displays found data**\n",
       "  - Number of found tracks, ghost hits and false clusters\n",
       "  - List of ghost hits\n",
       "  - List of clusters\n",
       "  - List of false clusters\n",
       "  - list of tracks\n",
       "  - List of primary vertices\n",
       "  - Plot of tracks found with ghost hits marked with a green 'x'\n",
       "\n",
       "**Calls**\n",
       "  - `time.time()`\n",
       "  - `cluster_by_last_column()`\n",
       "  - `create_tracks()`\n",
       "  - `split_clone_by_direction()`\n",
       "  - `display_all_clusters()`\n",
       "  - `display_all_tracks()`\n",
       "  - `analyze_p_vertices()`\n",
       "  - `display_p_vertices()`\n",
       "  - `plot_event()`\n",
       "\n",
       "### Note on sorting clusters by module_id\n",
       "After θ‑based clustering, each cluster contains hits that lie within the same azimuthal slice of the detector. To impose a physically meaningful internal structure, we sort each cluster by `hit.module_id` (column 5 of `array_hits`). This ordering is justified because:\n",
       "\n",
       "1. In the VELO geometry, `module_id` increases monotonically with radius or `|z|`. Sorting by module_id therefore arranges hits from inner to outer detector layers, reflecting the natural geometric progression of a particle traversing the VELO.\n",
       "\n",
       "2. This internal ordering is not required for the θ‑based clustering itself, but it provides a consistent and interpretable sequence for downstream operations such as segment construction, diagnostics, or visualization.\n",
       "\n",
       "3. The physical meaning of the ordering is guaranteed by the detector layout, not by the original order of hits in `array_hits`. Sorting by `module_id` ensures that each cluster is internally structured in a way that corresponds to the actual detector layers.\n",
       "\n",
       "Because of these properties, sorting each cluster by `module_id` yields clusters that are both geometrically coherent and aligned with the physical traversal of tracks through the VELO.\n",
       "\n",
       "### Note on using a set for cluster_hit_indices\n",
       "A Python set created from an ordered list preserves insertion order as long as no elements are added or removed afterward. Although sets are unordered, this does NOT break the physics of the algorithm for the following reasons:\n",
       "\n",
       "1. Clustering is performed on the polar angle `θ = atan2(y, x)`. Hits in the same cluster have nearly identical azimuthal direction in the XY plane, so any pair of hits from the cluster is already geometrically aligned.\n",
       "\n",
       "2. Each hit carries a `module_id` (detector layer). Even without explicit sorting, hits from different layers naturally form outward‑pointing segments because the detector geometry enforces radial or `|z|` separation between layers.\n",
       "\n",
       "3. Track acceptance depends only on whether a segment intersects the `z‑axis`. Since all hits in a θ‑cluster share the same azimuthal direction, any segment formed from any two hits in the cluster has essentially the same XY direction and therefore yields a consistent intersection test.\n",
       "\n",
       "4. The Segment class recomputes its own θ and `module_id` from the actual hit coordinates, so segment geometry remains physically meaningful even when the hit order is arbitrary. \n",
       "\n",
       "Because of these properties, using a set provides `O(1)` membership tests and automatic deduplication without compromising the physics. Segment order is irrelevant for this algorithm, and the resulting tracks remain stable, reproducible, and physically valid.\n",
       "\n",
       "```python\n",
       "      def find_tracks(self, list_hits):\n",
       "\n",
       "        if self.param is None:\n",
       "            print(\"find_tracks: missing parameter param\")\n",
       "            return None\n",
       "        param = self.param\n",
       "\n",
       "        layers = param[\"layers\"]\n",
       "        do_plot_tracks = param[\"do_plot_tracks\"]\n",
       "        resolution = param[\"resolution\"]\n",
       "        display_tracks = param[\"display_tracks\"]\n",
       "        display_ghost_hits = param[\"display_ghost_hits\"]\n",
       "        display_clusters = param[\"display_clusters\"]\n",
       "        display_false_clusters = param[\"display_false_clusters\"]\n",
       "        display_clone_splitting = param[\"display_clone_splitting\"]\n",
       "        display_clustering = param[\"display_clustering\"]\n",
       "\n",
       "        tol_clusters = param[\"tol_clusters\"]          # Tolerance for first pass coarse clustering for cluster_by_last_column()\n",
       "        tol_clone = param[\"tol_clone\"]                # Minimum value of the decloning tolerance for track_clusters()\n",
       "        tol_intersects = param[\"tol_intersects\"]      # Tolerance for segment_intersects_z_axis()\n",
       "        tol_vertices = param[\"tol_vertices\"]          # Tolerance for clustering primary vertices\n",
       "\n",
       "        if list_hits is None or list_hits == []:\n",
       "            print(\"find_tracks: input list of hits is None or empty - Exiting with no found track\")\n",
       "            return None\n",
       "\n",
       "        if layers <= 1:\n",
       "            print(\"find_tracks: more than one layer is required to find tracks - Exiting with no found track\")\n",
       "            return None\n",
       "\n",
       "        # Start timing\n",
       "        t0 = time.time()  # ⏱️ Start timing\n",
       "      \n",
       "        #--------------------------------------------------\n",
       "        # Build a dictionary keyed by the index of the hit\n",
       "        #--------------------------------------------------\n",
       "        hit_by_index = {i: hit for i, hit in enumerate(list_hits)}\n",
       "        param[\"hit_by_index\"] = hit_by_index\n",
       "\n",
       "        # Assign index to each Hit object\n",
       "        for i, hit in enumerate(list_hits):\n",
       "            hit.index = i\n",
       "\n",
       "        #--------------------------------------------------------\n",
       "        # Create a NumPy array of hits with theta as last column\n",
       "        #--------------------------------------------------------\n",
       "        array_hits = np.array([\n",
       "            [i, hit.hit_id, hit.x, hit.y, hit.z, hit.module_id, hit.theta]\n",
       "            for i, hit in enumerate(list_hits)\n",
       "        ], dtype=float)\n",
       "        param[\"array_hits\"] = array_hits\n",
       "        \n",
       "        #--------------------------------------------------------\n",
       "        # First pass: coarse clustering with config tol_clusters\n",
       "        #--------------------------------------------------------\n",
       "        clusters = self.cluster_by_last_column(array_hits, tol=tol_clusters)\n",
       "\n",
       "        #-----------------------------------------------------------------\n",
       "        # Unified estimator for tol_clusters_est (φ-clustering tolerance)\n",
       "        #-----------------------------------------------------------------\n",
       "        result = ToleranceEstimator.estimate_intra_cluster_theta_std(\n",
       "            clusters=clusters,\n",
       "            layers=layers,\n",
       "            n_sample_clusters=5,\n",
       "            alpha=1.5,\n",
       "            tol_min=tol_clusters,\n",
       "            tol_max=1e-2\n",
       "        )\n",
       "\n",
       "        if result is not None:\n",
       "            tol_clusters_est, mean_std = result\n",
       "\n",
       "            if display_clustering:\n",
       "                text = f\" find_tracks() - Refined tol_clusters_est = {tol_clusters_est:.4e} (mean intra-cluster std={mean_std:.4e})\"\n",
       "                line = \"-\" * (len(text) + 1)\n",
       "                print(f\"\\n{line}\\n{text}\\n{line}\")\n",
       "\n",
       "            #-------------------------------------------------------\n",
       "            # Second pass: refined clustering with tol_clusters_est\n",
       "            #-------------------------------------------------------\n",
       "            clusters = self.cluster_by_last_column(array_hits, tol=tol_clusters_est)\n",
       "\n",
       "        else:\n",
       "            tol_clusters_est = tol_clusters\n",
       "\n",
       "            if display_clustering:\n",
       "                text = \" find_tracks() - Refined tol_clusters_est: no usable clusters, keeping original tol_clusters\"\n",
       "                line = \"-\" * (len(text) + 1)\n",
       "                print(f\"\\n{line}\\n{text}\\n{line}\")\n",
       "\n",
       "        #------------------------------------------------------------------\n",
       "        # Sort each cluster internally in ascending order of hit.module_id\n",
       "        #------------------------------------------------------------------\n",
       "        clusters = [c[np.argsort(c[:, 5])] for c in clusters]\n",
       "\n",
       "        #----------------------------------------------------------------\n",
       "        # Sort the list of clusters by the first column of the first row\n",
       "        #----------------------------------------------------------------\n",
       "        clusters = sorted(clusters, key=lambda c: c[0, 0])\n",
       "\n",
       "        #------------------\n",
       "        # Initialize lists\n",
       "        #------------------\n",
       "        found_clusters = []\n",
       "        found_tracks = []\n",
       "        found_segments = []\n",
       "        found_p_vertices = []\n",
       "        ghost_clusters = []\n",
       "        false_tracks = []\n",
       "        false_clusters = []\n",
       "\n",
       "        threshold = int(layers / 2)\n",
       "        k = 0\n",
       "\n",
       "        #===========================\n",
       "        # Main reconstruction loop\n",
       "        #===========================\n",
       "        for cluster in clusters:\n",
       "\n",
       "            if len(cluster) > threshold:\n",
       "\n",
       "                #-------------------------------------------\n",
       "                # Compute track_hits ONCE for both branches\n",
       "                #-------------------------------------------\n",
       "                cluster_hit_indices = {int(x[0]) for x in cluster}\n",
       "                track_hits = [hit_by_index[idx] for idx in cluster_hit_indices]\n",
       "                track_hits = sorted(track_hits, key=lambda h: h.module_id)\n",
       "\n",
       "                #------------------------------------\n",
       "                # Case 1 — No clone splitting needed\n",
       "                #------------------------------------\n",
       "                if len(cluster) <= layers:\n",
       "\n",
       "                    k = self.create_tracks(\n",
       "                        cluster,\n",
       "                        hit_by_index,\n",
       "                        tol_intersects,\n",
       "                        k,\n",
       "                        found_segments,\n",
       "                        found_tracks,\n",
       "                        found_clusters,\n",
       "                        found_p_vertices,\n",
       "                        false_tracks,\n",
       "                        false_clusters\n",
       "                    )\n",
       "\n",
       "                #--------------------------------\n",
       "                # Case 2 — Clone-track splitting\n",
       "                #--------------------------------\n",
       "                else:\n",
       "                    if display_clone_splitting:\n",
       "                        text = f\" Clone-track splitting\"\n",
       "                        line = \"-\" * (len(text) + 1)\n",
       "                        print(f\"\\n{line}\\n{text}\\n{line}\")\n",
       "\n",
       "                        print(\"\\n   Hit Index   Hit ID      x         y         z       Theta    Module ID\")\n",
       "                        for x in cluster:\n",
       "                            print(f\"  {x[0]:6.0f}     {x[1]:6.0f}     {x[2]:6.2f}    {x[3]:6.2f}    {x[4]:6.2f}    {x[6]:6.3f}       {x[5]:.0f}\")\n",
       "\n",
       "                    #----------------------------------------------------\n",
       "                    # Unified estimator for tol_clone_est, theta_seg_std\n",
       "                    #----------------------------------------------------\n",
       "                    tol_clone_est, theta_seg_std = ToleranceEstimator.estimate_clone_tolerance(\n",
       "                        track_hits,\n",
       "                        alpha=1.0,\n",
       "                        tol_min=tol_clone,\n",
       "                        tol_max=2.0\n",
       "                    )\n",
       "\n",
       "                    if display_clone_splitting:\n",
       "                        text = f\" Estimated tol_clone (segment-based) = {tol_clone_est:.4e}  (std={theta_seg_std:.4e})\"\n",
       "                        line = \"-\" * (len(text) + 1)\n",
       "                        print(f\"\\n{line}\\n{text}\\n{line}\")\n",
       "\n",
       "                    #-------------------------------------------------\n",
       "                    # Split clone tracks by segment direction vectors\n",
       "                    #-------------------------------------------------\n",
       "                    k = self.split_clone_by_direction(\n",
       "                        track_hits,\n",
       "                        tol_clone_est,\n",
       "                        hit_by_index,\n",
       "                        tol_intersects,\n",
       "                        k,\n",
       "                        found_segments,\n",
       "                        found_tracks,\n",
       "                        found_clusters,\n",
       "                        found_p_vertices,\n",
       "                        false_tracks,\n",
       "                        false_clusters,\n",
       "                        display=display_clone_splitting\n",
       "                    )\n",
       "\n",
       "            #-----------\n",
       "            # Ghost hit\n",
       "            #-----------\n",
       "            elif len(cluster) == 1:\n",
       "                ghost_clusters.append(cluster)\n",
       "\n",
       "            #-------------------------\n",
       "            # Too small to be a track\n",
       "            #-------------------------\n",
       "            else:\n",
       "                false_clusters.append(cluster)\n",
       "\n",
       "        #--------------------------------------------------------------------------------------------------------------------\n",
       "        # Save in the parameter list ghost clusters, false clusters, found tracks, found segments and found primary vertices\n",
       "        #--------------------------------------------------------------------------------------------------------------------\n",
       "        param[\"found_clusters\"] = found_clusters\n",
       "        param[\"found_tracks\"] = found_tracks\n",
       "        param[\"found_segments\"] = found_segments\n",
       "        param[\"found_p_vertices\"] = found_p_vertices\n",
       "        param[\"ghost_clusters\"] = ghost_clusters\n",
       "        param[\"false_tracks\"] = false_tracks\n",
       "        param[\"false_clusters\"] = false_clusters\n",
       "\n",
       "        #-------------------------\n",
       "        # Display completion time\n",
       "        #-------------------------\n",
       "        t1 = time.time()\n",
       "        text = f\" ✅ find_tracks() completed in {t1 - t0:.2f} seconds \"\n",
       "        line = \"-\" * (len(text) + 1)\n",
       "        print(f\"\\n{line}\\n{text}\\n{line}\")\n",
       "\n",
       "        #-------------------------------------\n",
       "        # Create a list of found ghost_hits\n",
       "        # Use a set for O(1) membership tests\n",
       "        #-------------------------------------\n",
       "        ghost_hit_indices = {int(x[0]) for cluster in ghost_clusters for x in cluster}\n",
       "        found_ghost_hits = [hit_by_index[idx] for idx in ghost_hit_indices]\n",
       "        param[\"found_ghost_hits\"] = found_ghost_hits\n",
       "        \n",
       "        #-------------------------------------------------------------------------------------------------------\n",
       "        # Create an instance of the class Event defined in the module state_event_model.py\n",
       "        # LHCb_VeLo_Toy_Model_1-Bit_HHL/toy_model/state_event_model.py\n",
       "        # https://github.com/AlainChance/LHCb_VeLo_Toy_Model_1-Bit_HHL/blob/main/toy_model/state_event_model.py\n",
       "        #-------------------------------------------------------------------------------------------------------\n",
       "        found_event = Event(\n",
       "            detector_geometry = param[\"detector_geometry\"],\n",
       "            tracks = found_tracks,\n",
       "            hits = list_hits,\n",
       "            segments = found_segments,\n",
       "            modules = param[\"modules\"],\n",
       "            ghost_hits = found_ghost_hits\n",
       "        )\n",
       "        param[\"found_event\"] = found_event\n",
       "\n",
       "        #--------------------------------\n",
       "        # Get a list of primary_vertices\n",
       "        #--------------------------------\n",
       "        primary_vertices = self.analyze_p_vertices(found_p_vertices, tol_vertices)\n",
       "        \n",
       "        #--------------------------------\n",
       "        # Display found primary vertices\n",
       "        #--------------------------------\n",
       "        text = f\" find_tracks()\"\n",
       "        self.display_p_vertices(primary_vertices, text)\n",
       "\n",
       "        #---------------------------------------------------------\n",
       "        # Display number of found tracks, hits and false clusters\n",
       "        #---------------------------------------------------------\n",
       "        text = f\" find_tracks() found {len(found_tracks)} tracks\"\n",
       "\n",
       "        if len(ghost_clusters) > 0:\n",
       "            text += f\" and {len(ghost_clusters)} ghost hits\"\n",
       "        \n",
       "        if len(false_clusters) > 0:\n",
       "            text += f\" and {len(false_clusters)} false clusters\"\n",
       "            \n",
       "        line = \"-\" * (len(text) + 1)\n",
       "        print(f\"\\n{line}\\n{text}\\n{line}\")\n",
       "\n",
       "        #------------------------\n",
       "        # Display found clusters\n",
       "        #------------------------\n",
       "        if display_clusters and len(found_clusters) > 0:\n",
       "            self.display_all_clusters(found_clusters, text=\"clusters found by find_tracks()\")\n",
       "        \n",
       "        #------------------------\n",
       "        # Display false clusters\n",
       "        #------------------------\n",
       "        if display_false_clusters and len(false_clusters) > 0:\n",
       "            self.display_all_clusters(false_clusters, text=\"false clusters found by the function find_tracks()\")\n",
       "\n",
       "        #--------------------------\n",
       "        # Display found ghost hits\n",
       "        #--------------------------\n",
       "        if display_ghost_hits and len(ghost_clusters) > 0:\n",
       "            self.display_all_clusters(ghost_clusters, text=\"ghost hits found by the function find_tracks()\")\n",
       "        \n",
       "        #----------------------\n",
       "        # Display found tracks\n",
       "        #----------------------\n",
       "        if display_tracks and len(found_tracks) > 0:                       \n",
       "            self.display_all_tracks(found_tracks,\n",
       "                                text=f\" All {len(found_tracks)} tracks found by the function find_tracks()\"\n",
       "                               )\n",
       "\n",
       "        #---------------------------\n",
       "        # Plot reconstructed tracks\n",
       "        #---------------------------\n",
       "        if do_plot_tracks:          \n",
       "            self.plot_event(found_event,\n",
       "                            text=\" Plot of tracks found by the function find_tracks() with ghost hits marked with a green 'x'\",\n",
       "                            resolution = resolution\n",
       "                           )\n",
       "        \n",
       "        return\n",
       "```\n",
       "\n",
       "Extract of the output of `find_tracks()` from the Jupyter notebook [Find_tracks/HHL_29_particles_7_layers_find_tracks.ipynb](https://github.com/AlainChance/LHCb_VeLo_Toy_Model_1-Bit_HHL/blob/main/29_particles/7_layers/Find_tracks/HHL_29_particles_7_layers_find_tracks.ipynb).\n",
       "\n",
       "```python\n",
       "--------------------------------------------\n",
       " ✅ find_tracks() completed in 0.00 seconds \n",
       "--------------------------------------------\n",
       "\n",
       "----------------------------------------\n",
       " find_tracks() found 4 primary vertices\n",
       "----------------------------------------\n",
       "(0.000, 0.000, 4.000)\n",
       "(0.000, 0.000, 5.999)\n",
       "(0.000, 0.000, 7.999)\n",
       "(0.000, 0.000, 10.000)\n",
       "\n",
       "------------------------------------------------\n",
       " find_tracks() found 29 tracks and 2 ghost hits\n",
       "------------------------------------------------\n",
       "\n",
       "------------------------------------------------------\n",
       " All 2 ghost hits found by the function find_tracks()\n",
       "------------------------------------------------------\n",
       "\n",
       "   Hit ID       x         y         z       Theta    Module ID\n",
       "     0       -13.05     -0.91     20.00    -3.072       1\n",
       "     0       -13.33     -5.06     40.00    -2.779       2\n",
       "\n",
       "---------------------------------------------------\n",
       " All 29 tracks found by the function find_tracks()\n",
       "---------------------------------------------------\n",
       "\n",
       "Track ID: 0\n",
       "     Hit ID       x         y         z       Theta      Module ID\n",
       "       0         3.24     -0.71     20.00    -0.215          1\n",
       "       1         7.28     -1.59     40.00    -0.215          2\n",
       "       2        11.33     -2.47     60.00    -0.215          3\n",
       "       3        15.37     -3.35     80.00    -0.215          4\n",
       "       4        19.42     -4.23    100.00    -0.215          5\n",
       "       5        23.46     -5.12    120.00    -0.215          6\n",
       "       6        27.51     -6.00    140.00    -0.215          7\n",
       "\n",
       "    Segment ID        Hits           Theta         Module ID     Track ID\n",
       "       0            0      1        -0.215            2              0\n",
       "       1            1      2        -0.215            3              0\n",
       "       2            2      3        -0.215            4              0\n",
       "       3            3      4        -0.215            5              0\n",
       "       4            4      5        -0.215            6              0\n",
       "       5            5      6        -0.215            7              0\n",
       "```\n",
       "\n",
       "---\n",
       "\n",
       "### Function gen_indices\n",
       "The function `gen_indices()` generates ordered active segment indices as illustrated in Figure 2, left panel, of [ALGO-3](https://cds.cern.ch/record/2950969/files/document.pdf) identical to the one returned by the modified function `construct_segments` of the class SimpleHamiltonian.\n",
       "\n",
       "The Jupyter notebook [Test_gen_indices.ipynb](https://github.com/AlainChance/LHCb_VeLo_Toy_Model_1-Bit_HHL/blob/main/Test_gen_indices.ipynb) generates the following list of segment indices for 2 to 8 particles and 3 layers:\n",
       "```python\n",
       "Number of particles   Active segment indices\n",
       "2                     [0, 3, 4, 7]\n",
       "3                     [0, 4, 8, 9, 13, 17]\n",
       "4                     [0, 5, 10, 15, 16, 21, 26, 31]\n",
       "5                     [0, 6, 12, 18, 24, 25, 31, 37, 43, 49]\n",
       "6                     [0, 7, 14, 21, 28, 35, 36, 43, 50, 57, 64, 71]\n",
       "7                     [0, 8, 16, 24, 32, 40, 48, 49, 57, 65, 73, 81, 89, 97]\n",
       "8                     [0, 9, 18, 27, 36, 45, 54, 63, 64, 73, 82, 91, 100, 109, 118, 127]\n",
       "```\n",
       "\n",
       "---\n",
       "\n",
       "(see [Introduction to Qiskit patterns](https://quantum.cloud.ibm.com/docs/en/guides/intro-to-patterns)).\n",
       "\n",
       "### Function get_tracks_smart\n",
       "The function `get_tracks_smart()` performs the following steps:\n",
       "  - Lists active segments in the first three layers from the solution returned by the 1-bit HHL algorithm.\n",
       "  - Uses only active segments that intersect the z‑axis to reconstruct tracks.\n",
       "  - Completes the solution with missed segments that intersect the z-axis.\n",
       "  - Completes the list of active segments with hits in all the outer layers.\n",
       "\n",
       "This is consistent with the IBM Qiskit pattern methodology (*Post-process results*):\n",
       "\n",
       "*“This can involve a range of classical data-processing steps, such as … or post-selection based on inherent properties of the problem …”*\n",
       "\n",
       "(see [Introduction to Qiskit patterns](https://quantum.cloud.ibm.com/docs/en/guides/intro-to-patterns)).\n",
       "\n",
       "Both classical and 1-Bit HHL simulations only use the hits in the first three layers.\n",
       "\n",
       "**Input parameters**\n",
       "  - `ham`: simple Hamiltonian\n",
       "  - `solution`: list of active segments\n",
       "  - `atol`: tolerance\n",
       "\n",
       "**Input from the parameter list**\n",
       "  - `do_print_outer_segs`\n",
       "  - `hits`\n",
       "  - `modules`\n",
       "  - `segment_indices`\n",
       "  - `segment_in_indices`\n",
       "  - `found_tracks`\n",
       "  - `found_segments`\n",
       "  - `tol`\n",
       "\n",
       "**Returns**\n",
       "  - `event`: an instance of the class Event defined in state_event_model.py\n",
       "  - `tracks_processed`\n",
       "  - `good_indices`: list of indices of active segments that intersects the z-axis\n",
       "\n",
       "```python\n",
       "    def get_tracks_smart(self, ham: SimpleHamiltonian, solution: list[int], atol=1e-6):\n",
       "        param = self.param\n",
       "\n",
       "        #-------------------------------------------\n",
       "        # Retrieve parameters from param dictionary\n",
       "        #-------------------------------------------\n",
       "        do_print_outer_segs = param[\"do_print_outer_segs\"]\n",
       "        hits = param[\"hits\"]\n",
       "        modules = param[\"modules\"]\n",
       "        npart = sum(param[\"n_particles\"])\n",
       "        segment_indices = param[\"segment_indices\"]\n",
       "        segment_in_indices = param[\"segment_in_indices\"]\n",
       "        found_tracks = param[\"found_tracks\"]\n",
       "        found_segments = param[\"found_segments\"]\n",
       "        tol_intersects = param[\"tol_intersects\"]\n",
       "\n",
       "        # Initialize the list of found primary vertices\n",
       "        found_p_vertices = []\n",
       "\n",
       "        #--------------------------------------------------------------------------------------------------------------------\n",
       "        # List active segments from the solution returned by either the classical solution or the 1-bit HHL quantum solution\n",
       "        #--------------------------------------------------------------------------------------------------------------------\n",
       "        min_val = np.min(solution)\n",
       "        \n",
       "        active_segments = [\n",
       "            segment for segment, pseudo_state in zip(ham.segments, solution)\n",
       "            if pseudo_state > min_val\n",
       "        ]\n",
       "\n",
       "        #-------------------------------------------\n",
       "        # Filter segments that intersect the z-axis\n",
       "        #-------------------------------------------\n",
       "        filtered_solution = solution.copy()\n",
       "\n",
       "        filtered = False\n",
       "        first = True\n",
       "        for s in active_segments:\n",
       "            intersects = self.segment_intersects_z_axis(s, found_p_vertices, tol=tol_intersects)\n",
       "            if intersects:\n",
       "                filtered_solution[s.segment_id] = 1\n",
       "            else:\n",
       "                filtered_solution[s.segment_id] = 0\n",
       "                filtered = True\n",
       "                if first:\n",
       "                    print(\"\\nRemoved segments that do not intersect the z-axis:\")\n",
       "                    print(f\"\\n   Segment ID         Hits           Theta         Module ID     Track ID\")\n",
       "                    first = False\n",
       "                print(f\"    {s.segment_id:4d}       {s.hits[0].hit_id:6d}   {s.hits[1].hit_id:4d}        {s.theta:6.3f}         {s.module_id:4d}           {s.track_id:4d}\")\n",
       "\n",
       "        if filtered:\n",
       "            print(\"\\nFiltered solution:\")\n",
       "            print(filtered_solution)\n",
       "\n",
       "        # Update list of active segments\n",
       "        active_segments = [segment for segment in ham.segments if filtered_solution[segment.segment_id] == 1]\n",
       "\n",
       "        #------------------------------------------------------------------\n",
       "        # Complete solution with missed segments that intersect the z-axis\n",
       "        #------------------------------------------------------------------\n",
       "        completed = False\n",
       "        first = True\n",
       "        \n",
       "        if sum(filtered_solution) != len(segment_indices):\n",
       "            completed_solution = filtered_solution.copy()\n",
       "\n",
       "            #--------------------------------------------------------\n",
       "            # Look only for segments in the list segment_in_indices\n",
       "            # returned by the modified function construct_segments()\n",
       "            #--------------------------------------------------------\n",
       "            for s in segment_in_indices:\n",
       "                if completed_solution[s.segment_id] == 1:\n",
       "                    continue\n",
       "                intersects = self.segment_intersects_z_axis(s, found_p_vertices, tol=tol_intersects)\n",
       "                if intersects:\n",
       "                    completed_solution[s.segment_id] = 1\n",
       "                    completed = True\n",
       "                    if first:\n",
       "                        print(\"\\nAdded new segments:\")\n",
       "                        print(f\"\\n    Segment ID        Hits           Theta         Module ID     Track ID\")\n",
       "                        first = False\n",
       "                    print(f\"    {s.segment_id:4d}       {s.hits[0].hit_id:6d}   {s.hits[1].hit_id:4d}        {s.theta:6.3f}         {s.module_id:4d}           {s.track_id:4d}\")\n",
       "\n",
       "        if completed:\n",
       "            print(\"\\nCompleted solution:\")\n",
       "            print(completed_solution)\n",
       "\n",
       "            # Update list of active segments\n",
       "            active_segments = [segment for segment in ham.segments if completed_solution[segment.segment_id] == 1]\n",
       "\n",
       "        # Save list of found primary vertices in the parameter list\n",
       "        param[\"found_p_vertices\"] = found_p_vertices\n",
       "\n",
       "        #----------------------\n",
       "        # Get primary vertices\n",
       "        #----------------------\n",
       "        primary_vertices = self.analyze_p_vertices(found_p_vertices, tol_vertices)\n",
       "\n",
       "        #--------------------------\n",
       "        # Display primary vertices\n",
       "        #--------------------------\n",
       "        self.display_p_vertices(found_p_vertices)\n",
       "\n",
       "        #-------------------------------------------------------------------------------------------------------\n",
       "        # Create an instance of the class Event defined in state_event_model.py\n",
       "        # LHCb_VeLo_Toy_Model_1-Bit_HHL/toy_model/state_event_model.py\n",
       "        # https://github.com/AlainChance/LHCb_VeLo_Toy_Model_1-Bit_HHL/blob/main/toy_model/state_event_model.py\n",
       "        #-------------------------------------------------------------------------------------------------------\n",
       "        event = Event(\n",
       "            detector_geometry = param[\"detector_geometry\"],\n",
       "            tracks = found_tracks,\n",
       "            hits = param[\"hits\"],\n",
       "            segments = found_segments,\n",
       "            modules = param[\"modules\"],\n",
       "            ghost_hits = []\n",
       "        )\n",
       "        \n",
       "        #-----------------------------------\n",
       "        # Exit if there is no active segment\n",
       "        #-----------------------------------\n",
       "        if active_segments == []:\n",
       "            return event, [], []\n",
       "\n",
       "        #--------------------------------------\n",
       "        # Compute list of good segment indices\n",
       "        #--------------------------------------\n",
       "        good_indices = [segment.segment_id for segment in active_segments]\n",
       "        \n",
       "        #-------------------------------------------------------------------\n",
       "        # Complete the list of active segments with hits in the modules > 3\n",
       "        # Author: Alain Chancé\n",
       "        #-------------------------------------------------------------------\n",
       "        for module in [module for module in modules if module.module_id > 3]:\n",
       "\n",
       "            if module.module_id == 4 and do_print_outer_segs:\n",
       "                text = \" Added new segments\"\n",
       "                line = \"-\" * (len(text) + 1)\n",
       "                print(f\"\\n{line}\\n{text}\\n{line}\")\n",
       "            \n",
       "            if do_print_outer_segs:\n",
       "                print(f\"\\nModule: {module.module_id}\")\n",
       "                print(f\"\\n   Segment ID         Hits           Theta         Module ID     Track ID\")\n",
       "\n",
       "            for s in [s for s in found_segments if s.module_id == module.module_id]:\n",
       "\n",
       "                # Add new segment to the list of active segments\n",
       "                active_segments.append(s)\n",
       "\n",
       "                if do_print_outer_segs:\n",
       "                    print(f\"    {s.segment_id:4d}       {s.hits[0].hit_id:6d}   {s.hits[1].hit_id:4d}        {s.theta:6.3f}         {s.module_id:4d}           {s.track_id:4d}\")\n",
       "\n",
       "        event.tracks = found_tracks\n",
       "        \n",
       "        return event, found_tracks, good_indices\n",
       "```\n",
       "\n",
       "---\n",
       "\n",
       "### Function plot_event\n",
       "This function is derived from function plot_segments defined in the module `state_event_model.py`:\n",
       "[LHCb_VeLo_Toy_Model_1-Bit_HHL/toy_model/state_event_model.py](https://github.com/AlainChance/LHCb_VeLo_Toy_Model_1-Bit_HHL/blob/main/toy_model/state_event_model.py).\n",
       "\n",
       "**Input parameters**\n",
       "  - `event`: an event of the class Event defined in the module `state_event_model.py`\n",
       "  - `text`: text to be printed, default is None\n",
       "  - `resolution`: increase for finer mesh\n",
       "\n",
       "**Displays**\n",
       "  - A 3D plot of tracks with ghost hits marked with a green 'x'\n",
       "\n",
       "```python\n",
       "    def plot_event(self, event, text=None, resolution=25):\n",
       "\n",
       "        if text is not None:\n",
       "            line = \"-\" * (len(text) + 1)\n",
       "            print(f\"\\n{line}\\n{text}\\n{line}\")\n",
       "        \n",
       "        detector_geometry = event.detector_geometry\n",
       "        tracks = event.tracks\n",
       "        hits = event.hits\n",
       "        ghost_hits = event.ghost_hits\n",
       "        segments = event.segments\n",
       "        \n",
       "        fig = plt.figure()\n",
       "        ax = fig.add_subplot(111, projection='3d')\n",
       "\n",
       "        # Re-map: X-axis <- Z, Y-axis <- Y, Z-axis <- X\n",
       "        X = [h.z for h in hits]\n",
       "        Y = [h.y for h in hits]\n",
       "        Z = [h.x for h in hits]\n",
       "        ax.scatter(X, Y, Z, c='r', marker='o', s=5)\n",
       "            \n",
       "        # Plot lines\n",
       "        for segment in segments:\n",
       "            x = [h.z for h in segment.hits]\n",
       "            y = [h.y for h in segment.hits]\n",
       "            z = [h.x for h in segment.hits]\n",
       "            ax.plot(x, y, z, c='b', linewidth=0.5)\n",
       "\n",
       "        # Draw planes from geometry, but only show regions that are in the bulk\n",
       "        \n",
       "        # print(self.detector_geometry)\n",
       "        for mod_id, lx, ly, zpos in detector_geometry:\n",
       "            xs = np.linspace(-lx, lx, resolution)\n",
       "            ys = np.linspace(-ly, ly, resolution)\n",
       "            X, Y = np.meshgrid(xs, ys)\n",
       "            Z = np.full_like(X, zpos, dtype=float)\n",
       "\n",
       "            for idx in np.ndindex(X.shape):\n",
       "                x_val = X[idx]\n",
       "                y_val = Y[idx]\n",
       "                # If not in the bulk (e.g., inside a void), mask out\n",
       "                if not detector_geometry.point_on_bulk({'x': x_val, 'y': y_val, 'z': zpos}):\n",
       "                    X[idx], Y[idx], Z[idx] = np.nan, np.nan, np.nan\n",
       "\n",
       "            # Plot, using (Z, Y, X) to match the existing axis mappings\n",
       "            ax.plot_surface(Z, Y, X, alpha=0.3, color='gray')\n",
       "\n",
       "        # Scatter ghost_hits with a green 'x'\n",
       "        if ghost_hits != []:\n",
       "            X = [h.z for h in ghost_hits]\n",
       "            Y = [h.y for h in ghost_hits]\n",
       "            Z = [h.x for h in ghost_hits]\n",
       "            ax.scatter(X, Y, Z, c='g', marker='x')\n",
       "        \n",
       "        ax.set_xlabel('Z (horizontal)')\n",
       "        ax.set_ylabel('Y')\n",
       "        ax.set_zlabel('X')\n",
       "        plt.tight_layout()\n",
       "        plt.show()\n",
       "\n",
       "        return\n",
       "```\n",
       "\n",
       "---\n",
       "\n",
       "### Function plot_hits_polar\n",
       "The function `plot_hits_polar()` displays a plot in Radians of hits projected onto the XY plane.\n",
       "\n",
       "**Input parameters**\n",
       "  - `List of hits`\n",
       "  - `text`: text to be printed, default is None\n",
       "\n",
       "**Displays**\n",
       "  - a polar plot.\n",
       "\n",
       "```python\n",
       "def plot_hits_polar(self, hits, text=None):\n",
       "\n",
       "        if text is not None:\n",
       "            line = \"-\" * (len(text) + 1)\n",
       "            print(f\"\\n{line}\\n{text}\\n{line}\")\n",
       "\n",
       "        # Compute polar coordinates\n",
       "        theta = [h.theta for h in hits]           # Angle theta\n",
       "        r = [math.hypot(h.x, h.y) for h in hits]  # Radius\n",
       "\n",
       "        fig, ax = plt.subplots(subplot_kw={'projection': 'polar'})\n",
       "        ax.scatter(theta, r, s=5)                 # Scatter with small dots\n",
       "\n",
       "        # Display tick labels in radians\n",
       "        ax.set_xticks([0, np.pi/2, np.pi, 3*np.pi/2])\n",
       "        ax.set_xticklabels(['0', 'π/2', 'π', '3π/2'])\n",
       "        \n",
       "        ax.set_title(\"Polar Plot of Hits in Radians\")\n",
       "        plt.show()\n",
       "\n",
       "        return\n",
       "```\n",
       "An example of a polar plot follows.\n",
       "\n",
       "[LHCb_VeLo_Toy_Model_1-Bit_HHL/8_particles/6_layers/Noiseless/Polar_Plot_8_p_6_l_noiseless.png](https://github.com/AlainChance/LHCb_VeLo_Toy_Model_1-Bit_HHL/blob/main/8_particles/6_layers/Noiseless/Polar_Plot_8_p_6_l_noiseless.png).\n",
       "\n",
       "![LHCb_VeLo_Toy_Model_1-Bit_HHL/8_particles/6_layers/Noiseless/Polar_Plot_8_p_6_l_noiseless.png](https://github.com/AlainChance/LHCb_VeLo_Toy_Model_1-Bit_HHL/blob/main/8_particles/6_layers/Noiseless/Polar_Plot_8_p_6_l_noiseless.png).\n",
       "\n",
       "---\n",
       "\n",
       "### Function segment_intersects_z_axis\n",
       "This function determines whether a segment intersects the z-axis and if so it updates the list of primary vertices given as input.\n",
       "It is called by the functions `get_tracks_smart()` and `find_tracks()`. The list of found_p_vertices is processed by the function `analyze_p_vertices()`.\n",
       "\n",
       "**Input parameters**\n",
       "  - `Segment`: a segment object as defined in state_event_model.py\n",
       "  - `found_p_vertices`: list of primary vertices or None\n",
       "  - `tol`: tolerance for the intersection\n",
       "\n",
       "**Input from the parameter list**\n",
       "  - `dz`: layer spacing (mm)\n",
       "\n",
       "**Mutates**\n",
       "  - `found_p_vertices`: updated if a new primary vertex has been found\n",
       "\n",
       "**Returns**\n",
       "  - `intersects`: boolean True if the segment intersects the z-axis\n",
       "\n",
       "### Note on the physics of z-axis intersection testing \n",
       "These functions determine whether a reconstructed segment is compatible with originating from the LHCb interaction point by checking if the segment intersects the `z‑axis`. This is physically well‑motivated in the VELO for the following reasons:\n",
       "\n",
       "1. In the VELO, tracks can be approximated as straight lines because the magnetic field is negligible in this region. Real charged‑particle trajectories therefore pass very close to the beamline. A genuine track segment should extrapolate back to the `z‑axis` at a physically reasonable z‑position.\n",
       "\n",
       "2. The intersection is computed analytically by solving `x(t) = 0` and `y(t) = 0` for the segment parameter t. If both solutions agree within a tolerance, the segment is considered to pass through the beamline. This provides a robust geometric criterion that is independent of hit ordering or cluster structure.\n",
       "\n",
       "3. The resulting `z‑coordinate` of the intersection must lie between the origin of the detector (`z = 0`) and the first VELO layer (`z = dz`). Intersections outside this region correspond to unphysical backward extrapolations or to segments that do not originate from a primary vertex.\n",
       "\n",
       "4. Because θ‑based clustering already ensures that hits in a cluster share a common azimuthal direction, any segment formed from two hits in the cluster will have a consistent XY direction. This makes the `z‑axis` intersection test stable even when the internal ordering of hits is arbitrary (e.g., when using a set).\n",
       "\n",
       "5. Unique primary vertices are accumulated by comparing intersection points within a tolerance. This allows the algorithm to identify multiple distinct primary vertices if present, while avoiding duplicates caused by numerical precision.\n",
       "\n",
       "Together, these properties ensure that the `z‑axis` intersection test is both geometrically rigorous and aligned with the physical behavior of tracks in the VELO. It serves as the final validation step for accepting or rejecting candidate tracks derived from θ‑clusters.\n",
       "\n",
       "```python\n",
       "    def segment_intersects_z_axis(self, s: Segment, found_p_vertices, tol=1e-6):\n",
       "        param = self.param\n",
       "\n",
       "        dz = param[\"dz\"]\n",
       "        \n",
       "        p0 = s.p0()\n",
       "        p1 = s.p1()\n",
       "        d = s.to_vect()\n",
       "\n",
       "        intersects, xyz = self.intersects_z_axis(p0[0], p0[1], p0[2], d[0], d[1], d[2], tol=tol)\n",
       "        if not intersects:\n",
       "            return False\n",
       "            \n",
       "        intersects, xyz = self.intersects_z_axis(p1[0], p1[1], p1[2], d[0], d[1], d[2], tol=tol)\n",
       "        if not intersects:\n",
       "            return False\n",
       "\n",
       "        # Reject intersection that is before the origin or beyond the first layer\n",
       "        if xyz[2] <= 0 or xyz[2] >= dz or np.allclose(xyz[2], 0.0, atol=tol) or np.allclose(xyz[2], dz, atol=tol):\n",
       "            return False\n",
       "        \n",
       "        if found_p_vertices is None:\n",
       "            found_p_vertices = [xyz]\n",
       "        else:\n",
       "            found_p_vertices.append(xyz)\n",
       "        \n",
       "        return True\n",
       "        \n",
       "        return True\n",
       "```\n",
       "\n",
       "---\n",
       "\n",
       "### Function setup_Hamiltonian\n",
       "The function `setup_Hamiltonian()` creates an instance of the `SimpleHamiltonian` class:\n",
       "\n",
       "```python\n",
       "ham = SimpleHamiltonian(epsilon=1e-7, alpha=2.0, beta=1.0, theta_d=tol)\n",
       "param[\"ham\"] = ham\n",
       "```\n",
       "\n",
       "It then calls the `construct_segments()` method of the `SimpleHamiltonian class`. Finally, it stores the lists `segment_indices` and `segment_in_indices` in the parameter list:\n",
       "\n",
       "```python\n",
       "ham.construct_segments(event=event_tracks)\n",
       "\n",
       "param[\"segment_indices\"] = ham.segment_indices\n",
       "param[\"segment_in_indices\"] = ham.segment_in_indices\n",
       "```\n",
       "\n",
       "---\n",
       "\n",
       "### Function split_clone_by_direction()\n",
       "This function splits a θ-cluster into physically distinct clone tracks by clustering the 3D direction vectors of consecutive hit segments.\n",
       "\n",
       "**Motivation**\n",
       "\n",
       "A θ-cluster groups hits with similar azimuthal angle φ. When multiple particles share nearly identical φ (common in dense VELO-like geometries), they may be merged into a single cluster. These \"clone clusters\" must be separated into individual tracks.\n",
       "\n",
       "The most stable discriminator between clone tracks is the *direction* of their local segments. For a true straight track, the direction vector between consecutive modules is nearly constant. Clone tracks, even if close in φ, exhibit distinct 3D directions.\n",
       "\n",
       "This method performs clone splitting by:\n",
       "  1. Building Segment objects between consecutive modules.\n",
       "  2. Converting each segment into a normalized direction vector.\n",
       "  3. Measuring cosine similarity relative to a reference segment.\n",
       "  4. Clustering the cosines using the existing 1‑D clustering engine.\n",
       "  5. Mapping segment clusters back to hit clusters.\n",
       "\n",
       "**Parameters**\n",
       "  - `track_hits`: list[Hit]. A list of Hit objects belonging to a θ-cluster. Hits must already be sorted in ascending module_id order.\n",
       "\n",
       "  - `tol_clone_est`: float. The tolerance used to cluster segment direction cosines. Typically derived from the angular spread of θ_seg via the adaptive estimator: `tol_clone_est` = `max(alpha * std(θ_seg), tol_min)`\n",
       "\n",
       "  - `hit_by_index`: dictionary built by the function `find_tracks()`\n",
       "    \n",
       "  - `tol_intersects`\n",
       "    \n",
       "  - `k`: integer\n",
       "    \n",
       "  - `found_segments`: list of found segments\n",
       "    \n",
       "  - `found_tracks`: list of found_tracks\n",
       "    \n",
       "  - `found_clusters`: list of found clusters\n",
       "    \n",
       "  - `found_p_vertices`: list of found primary vertices\n",
       "    \n",
       "  - `false_tracks`: list of false tracks\n",
       "    \n",
       "  - `false_clusters`: list of false clustyers\n",
       "\n",
       "  - `display` : bool, optional (default=False). If True, prints diagnostic information about the segment clusters and the resulting hit clusters.\n",
       "\n",
       "**Returns**\n",
       "  - `k` : integer.\n",
       "\n",
       "**Notes**\n",
       "  - Segment direction vectors are extremely stable in the VELO toy-model, making cosine similarity a robust discriminator.\n",
       "  - The clustering is performed in 1‑D (cosine space), reusing the existing cluster_by_last_column() machinery for consistency and speed.\n",
       "  - Deduplication of hits is performed by object identity (id()), ensuring that Hit objects remain intact and no attributes are lost.\n",
       "  - This method is designed to be called inside the clone-splitting branch of the main find_tracks() reconstruction loop.\n",
       "\n",
       "**Example**\n",
       "```python\n",
       "        k = self.split_clone_by_direction(\n",
       "            track_hits,\n",
       "            tol_clone_est,\n",
       "            hit_by_index,\n",
       "            tol_intersects,\n",
       "            k,\n",
       "            found_segments,\n",
       "            found_tracks,\n",
       "            found_clusters,\n",
       "            found_p_vertices,\n",
       "            false_tracks,\n",
       "            false_clusters,\n",
       "            display=True\n",
       "        )\n",
       "```\n",
       "\n",
       "```python\n",
       "   def split_clone_by_direction(\n",
       "        self,\n",
       "        track_hits,\n",
       "        tol_clone_est,\n",
       "        hit_by_index,\n",
       "        tol_intersects,\n",
       "        k,\n",
       "        found_segments,\n",
       "        found_tracks,\n",
       "        found_clusters,\n",
       "        found_p_vertices,\n",
       "        false_tracks,\n",
       "        false_clusters,\n",
       "        display=False\n",
       "    ):\n",
       "        \"\"\"\n",
       "        Split a θ-cluster into clone tracks by clustering segment directions.\n",
       "        \"\"\"\n",
       "    \n",
       "        #-----------------------------------------\n",
       "        # Build segments in module order\n",
       "        #-----------------------------------------\n",
       "        segments = []\n",
       "        for i in range(len(track_hits) - 1):\n",
       "            if track_hits[i+1].module_id > track_hits[i].module_id:\n",
       "                segments.append(\n",
       "                    Segment(hits=[track_hits[i], track_hits[i+1]], segment_id=i)\n",
       "                )\n",
       "    \n",
       "        if len(segments) == 0:\n",
       "            return k  # nothing to split\n",
       "    \n",
       "        #-----------------------------------------\n",
       "        # Compute direction cosines relative to ref\n",
       "        #-----------------------------------------\n",
       "        ref = segments[0]\n",
       "        cos_values = np.array([ref * s for s in segments])\n",
       "    \n",
       "        #----------------------------------------------------------------------\n",
       "        # Cluster cosines using 1-D clustering function cluster_by_last_column\n",
       "        #----------------------------------------------------------------------\n",
       "        array_cos = np.array([[i, cos] for i, cos in enumerate(cos_values)], dtype=float)\n",
       "        seg_clusters = self.cluster_by_last_column(array_cos, tol=tol_clone_est)\n",
       "    \n",
       "        #-----------------------------------------------------------------\n",
       "        # Optional: avoid exact duplicates, but keep complementary tracks\n",
       "        #-----------------------------------------------------------------\n",
       "        seen_signatures = set()\n",
       "    \n",
       "        #-------------------------------------------------------------\n",
       "        # For each segment cluster → build hit cluster → create track\n",
       "        #-------------------------------------------------------------\n",
       "        first = True\n",
       "        \n",
       "        for sc in seg_clusters:\n",
       "            seg_indices = sc[:, 0].astype(int)\n",
       "    \n",
       "            # Build hits for this segment cluster\n",
       "            hits = []\n",
       "            for idx in seg_indices:\n",
       "                hits.append(segments[idx].hits[0])\n",
       "                hits.append(segments[idx].hits[1])\n",
       "    \n",
       "            # Deduplicate by identity and sort by module_id\n",
       "            unique_hits = {}\n",
       "            for h in hits:\n",
       "                unique_hits[id(h)] = h\n",
       "            hits = sorted(unique_hits.values(), key=lambda h: h.module_id)\n",
       "    \n",
       "            # Check module-ID validity\n",
       "            module_ids = [h.module_id for h in hits]\n",
       "            if len(module_ids) < 2:\n",
       "                continue\n",
       "            if len(module_ids) != len(set(module_ids)):\n",
       "                continue  # reject clusters with duplicate modules\n",
       "    \n",
       "            # Signature using (module_id, index) → keeps complementary tracks distinct\n",
       "            signature = tuple((h.module_id, h.index) for h in hits)\n",
       "            if signature in seen_signatures:\n",
       "                continue\n",
       "            seen_signatures.add(signature)\n",
       "\n",
       "            # Display (optional)\n",
       "            if display:\n",
       "                if first:\n",
       "                    print(\"\\nClusters found by the function split_clone_by_direction()\")\n",
       "                    print(\"\\n    Hit Index     Hit ID          x         y         z       Theta      Module ID\")\n",
       "                first = False\n",
       "                \n",
       "                for h in hits:\n",
       "                    print(f\"    {h.index:6d}        {h.hit_id:6d}       {h.x:6.2f}    {h.y:6.2f}    {h.z:6.2f}    {h.theta:6.3f}       {h.module_id:4d}\")\n",
       "    \n",
       "            # Convert Hit objects → array format expected by create_tracks\n",
       "            subcluster = np.array(\n",
       "                [[h.index, h.hit_id, h.x, h.y, h.z, h.module_id, h.theta] for h in hits],\n",
       "                dtype=float\n",
       "            )\n",
       "\n",
       "            # Create a new track for the new segment cluster\n",
       "            k = self.create_tracks(\n",
       "                subcluster,\n",
       "                hit_by_index,\n",
       "                tol_intersects,\n",
       "                k,\n",
       "                found_segments,\n",
       "                found_tracks,\n",
       "                found_clusters,\n",
       "                found_p_vertices,\n",
       "                false_tracks,\n",
       "                false_clusters\n",
       "            )\n",
       "    \n",
       "        return k\n",
       "```\n",
       "\n",
       "---\n",
       "\n",
       "## Module OneBQF.py, class OneBQF\n",
       "The module [AlainChance/LHCb_VeLo_Toy_Model_1-Bit_HHL/OneBQF.py](https://github.com/AlainChance/LHCb_VeLo_Toy_Model_1-Bit_HHL/blob/main/OneBQF.py) is derived from the module [Xenofon-Chiotopoulos/OneBQF/quantum_algorithms/OneBQF.py](https://github.com/Xenofon-Chiotopoulos/OneBQF/blob/main/quantum_algorithms/OneBQF.py)\n",
       "\n",
       "The register name `ancilla` has been changed to `qr_ancilla` to fix a known bug with qpy in Qiskit v2.2.2 that causes an `IndexError: index out of range` if a register starts with the name ancilla.\n",
       "```python\n",
       "#self.ancilla_qr = QuantumRegister(1, \"ancilla\")\n",
       "self.ancilla_qr = QuantumRegister(1, \"qr_ancilla\")\n",
       "```\n",
       "\n",
       "---\n",
       "\n",
       "## Module simple_hamiltonian.py\n",
       "The module [AlainChance/LHCb_VeLo_Toy_Model_1-Bit_HHL/simple_hamiltonian.py](https://github.com/AlainChance/LHCb_VeLo_Toy_Model_1-Bit_HHL/blob/main/toy_model/simple_hamiltonian.py) is derived from the module [Xenofon-Chiotopoulos/OneBQF/toy_model/simple_hamiltonian.py](https://github.com/Xenofon-Chiotopoulos/OneBQF/blob/main/toy_model/simple_hamiltonian.py).\n",
       "\n",
       "### class SimpleHamiltonian\n",
       "Additional properties: \n",
       "  - `self.segment_indices`\n",
       "  - `self.segment_in_indices`\n",
       "\n",
       "```python\n",
       "class SimpleHamiltonian(Hamiltonian):\n",
       "    \n",
       "    def __init__(self, epsilon, alpha, beta, theta_d = 1e-4):\n",
       "        self.epsilon                                    = epsilon\n",
       "        self.gamma                                      = alpha\n",
       "        self.delta                                      = beta\n",
       "        self.theta_d                                   = theta_d\n",
       "        self.Z                                          = None\n",
       "        self.A                                          = None\n",
       "        self.b                                          = None\n",
       "        self.segments                                   = None\n",
       "        self.segments_grouped                           = None\n",
       "        self.n_segments                                 = None\n",
       "        #---------------------------------------------------\n",
       "        # Added by Alain Chancé\n",
       "        self.segment_indices                            = []\n",
       "        self.segment_in_indices                         = []\n",
       "        #---------------------------------------------------\n",
       "```\n",
       "\n",
       "### Function construct_segments in the module simple_hamiltonian.py\n",
       "The function `construct_segments()` is enhanced to identify segments with matching values of `theta` during their creation and to append them to the list `segment_in_indices`, along with their corresponding segment IDs in the list `segment_indices`. The function `construct_hamiltonian()` uses these lists.\n",
       "\n",
       "```python\n",
       "    def construct_segments(self, event: StateEventGenerator):    \n",
       "        segments_grouped = []\n",
       "        segments = []\n",
       "        n_segments = 0\n",
       "        segment_id = count()\n",
       "\n",
       "        #-------------------------\n",
       "        # Added by Alain Chancé\n",
       "        first = True\n",
       "        #------------------------\n",
       "\n",
       "        for idx in range(len(event.modules)-1):\n",
       "            from_hits = event.modules[idx].hits\n",
       "            to_hits = event.modules[idx+1].hits\n",
       "\n",
       "            segments_group = []\n",
       "            for from_hit, to_hit in product(from_hits, to_hits):\n",
       "                seg = Segment([from_hit, to_hit],next(segment_id))\n",
       "                segments_group.append(seg)\n",
       "                segments.append(seg)\n",
       "                n_segments = n_segments + 1\n",
       "\n",
       "                #------------------------------------------------------------------------------\n",
       "                # Added by Alain Chancé\n",
       "                #\n",
       "                # Identify segments with matching values of `theta` during their creation and\n",
       "                # append them to the list `segment_in_indices`, along with their corresponding\n",
       "                # segment IDs in the list `segment_indices`.\n",
       "                #------------------------------------------------------------------------------\n",
       "                if np.allclose(from_hit.theta, to_hit.theta, atol=self.theta_d):\n",
       "\n",
       "                    if first:\n",
       "                        print(f\"\\nFunction construct_segments() - Adding segments with matching theta to segment_in_indices\")\n",
       "                        print(f\"\\n    Segment ID        Hits           Theta         Module ID     Track ID\")\n",
       "                        first = False\n",
       "                    \n",
       "                    print(f\"    {seg.segment_id:4d}       {seg.hits[0].hit_id:6d}   {seg.hits[1].hit_id:4d}        {seg.theta:6.3f}         {seg.module_id:4d}           {seg.track_id:4d}\")\n",
       "\n",
       "                    self.segment_in_indices.append(seg)\n",
       "                #---------------------------------------\n",
       "        \n",
       "            segments_grouped.append(segments_group)\n",
       "\n",
       "        #-----------------------\n",
       "        # Added by Alain Chancé\n",
       "        #-----------------------\n",
       "        self.segment_indices = [segment.segment_id for segment in self.segment_in_indices]\n",
       "        print(\"\\nconstruct_segments() - list segment_indices\")\n",
       "        print(f\"\\n{self.segment_indices}\")\n",
       "        #----------------------------------------------------------------------------------\n",
       "            \n",
       "        self.segments_grouped = segments_grouped\n",
       "        self.segments = segments\n",
       "        self.n_segments = n_segments\n",
       "\n",
       "        return\n",
       "```\n",
       "\n",
       "An example of output of `construct_segments()` follows:\n",
       "```python\n",
       "------------------------------------------------------------\n",
       " construct_segments() method of the SimpleHamiltonian class\n",
       "------------------------------------------------------------\n",
       "\n",
       "Function construct_segments() - Adding segments with matching theta to segment_in_indices\n",
       "\n",
       "    Segment ID        Hits           Theta         Module ID     Track ID\n",
       "       0            0      1         1.816            2              0\n",
       "       9            6      7        -3.020            2              1\n",
       "      18           12     13        -2.164            2              2\n",
       "      27           18     19         2.392            2              3\n",
       "      36           24     25        -1.423            2              4\n",
       "      45           30     31        -0.574            2              5\n",
       "      54           36     37        -2.023            2              6\n",
       "      63           42     43         1.544            2              7\n",
       "      64            1      2         1.816            3              0\n",
       "      73            7      8        -3.020            3              1\n",
       "      82           13     14        -2.164            3              2\n",
       "      91           19     20         2.392            3              3\n",
       "     100           25     26        -1.423            3              4\n",
       "     109           31     32        -0.574            3              5\n",
       "     118           37     38        -2.023            3              6\n",
       "     127           43     44         1.544            3              7\n",
       "\n",
       "construct_segments() - list segment_indices\n",
       "\n",
       "[0, 9, 18, 27, 36, 45, 54, 63, 64, 73, 82, 91, 100, 109, 118, 127]\n",
       "```\n",
       "\n",
       "### Function construct_hamiltonian\n",
       "The function `construct_hamiltonian()` considers only doublets $S_i$ and $S_j$ of segments in `segment_in_indices` returned by the function `construct_segments()`. This modification significantly improves the performance of the preprocessing step.\n",
       "\n",
       "```python\n",
       "def construct_hamiltonian(self, event: StateEventGenerator, convolution: bool= False):\n",
       "        Segment.id_counter = 0\n",
       "        if self.segments_grouped is None:\n",
       "            self.construct_segments(event)\n",
       "        A = sci.sparse.eye(self.n_segments,format='lil')*(-(self.delta+self.gamma))\n",
       "        b = np.ones(self.n_segments)*self.delta\n",
       "\n",
       "        #-----------------------\n",
       "        # Added by Alain Chancé\n",
       "        #-----------------------\n",
       "        if self.segment_in_indices != []:\n",
       "            #--------------------------------------------------------------------------------------------\n",
       "            # Consider only segments in segment_in_indices returned by the function construct_segments()\n",
       "            #--------------------------------------------------------------------------------------------\n",
       "            for group_idx in range(len(self.segments_grouped) - 1):\n",
       "                for seg_i, seg_j in product(self.segment_in_indices, self.segment_in_indices):\n",
       "                    if seg_i.hits[1] == seg_j.hits[0]:\n",
       "                        A[seg_i.segment_id, seg_j.segment_id] = A[seg_j.segment_id, seg_i.segment_id] =  1\n",
       "        else:\n",
       "            #---------------------------------\n",
       "            # Search in all possible segments\n",
       "            #---------------------------------\n",
       "            for group_idx in range(len(self.segments_grouped) - 1):\n",
       "                for seg_i, seg_j in product(self.segments_grouped[group_idx], self.segments_grouped[group_idx+1]):\n",
       "                    \n",
       "                    # Modified by Alain Chancé\n",
       "                    #if seg_i.hits[1] == seg_j.hits[0]:\n",
       "                        #cosine = (seg_i * seg_j) \n",
       "                        #if convolution:\n",
       "                            #convolved_step = (1 + erf((self.epsilon - abs(np.arccos(cosine))) / (self.theta_d * np.sqrt(2))))\n",
       "                            #A[seg_i.segment_id, seg_j.segment_id] = A[seg_j.segment_id, seg_i.segment_id] =  convolved_step\n",
       "                        #else: \n",
       "                            #if abs(cosine - 1) < self.epsilon:\n",
       "                                #A[seg_i.segment_id, seg_j.segment_id] = A[seg_j.segment_id, seg_i.segment_id] =  1\n",
       "                    \n",
       "                    if seg_i.hits[1] == seg_j.hits[0] and np.allclose(seg_i.theta, seg_j.theta, atol=self.theta_d):\n",
       "                        A[seg_i.segment_id, seg_j.segment_id] = A[seg_j.segment_id, seg_i.segment_id] =  1\n",
       "        \n",
       "        #------------------------------------------------------------------\n",
       "        # Get a new sparse matrix in CSC format for fast column operations\n",
       "        #------------------------------------------------------------------\n",
       "        A = A.tocsc()\n",
       "        \n",
       "        self.A, self.b = -A, b\n",
       "        return -A, b\n",
       "```\n",
       "\n",
       "---\n",
       "\n",
       "## Module state_event_generator.py, class StateEventGenerator\n",
       "\n",
       "The module [AlainChance/LHCb_VeLo_Toy_Model_1-Bit_HHL/toy_model/state_event_generator.py](https://github.com/AlainChance/LHCb_VeLo_Toy_Model_1-Bit_HHL/blob/main/toy_model/state_event_generator.py) is derived from the module [Xenofon-Chiotopoulos/OneBQF/toy_model/state_event_generator.py](https://github.com/Xenofon-Chiotopoulos/OneBQF/blob/main/toy_model/state_event_generator.py).\n",
       "\n",
       "### Function __init__\n",
       "Added property: ghost_hits\n",
       "```python\n",
       "        self.ghost_hits = []\n",
       "```\n",
       "\n",
       "### Function generate_particles()\n",
       "Added sanity check:\n",
       "```python\n",
       "    if event == len(self.primary_vertices):\n",
       "        print(f\"\\nError: the list of particles is larger than the list of primary vertices.\")\n",
       "        return 0\n",
       "            \n",
       "    try:\n",
       "        x, y, z = self.primary_vertices[event]\n",
       "    except Exception as e:\n",
       "        print(f\"StateEventGenerator - Error generating particles: {e}\")\n",
       "        return 0\n",
       "```\n",
       "\n",
       "### Function generate_complete_events()\n",
       "Modified\n",
       "```python\n",
       "    self.true_event = em.Event(self.detector_geometry, self.true_tracks, self.true_hits, self.true_segments, self.true_modules, self.ghost_hits)\n",
       "```\n",
       "\n",
       "### Function make_noisy_event()\n",
       "Added:\n",
       "```python\n",
       "        self.ghost_hits = ghost_hits\n",
       "```\n",
       "\n",
       "```python\n",
       "    self.false_event = em.Event(\n",
       "        self.detector_geometry, self.tracks, self.hits, self.segments, self.modules, self.ghost_hits)\n",
       "```\n",
       "\n",
       "---\n",
       "\n",
       "# References\n",
       "\n",
       "## LHCb Taking a closer look at LHC\n",
       "[LHC-1] [The Large Hadron Collider beauty (LHCb) experiment](https://home.cern/science/experiments/lhcb)\n",
       "\n",
       "[LHC-2] [LHCb Taking a closer look at LHC](https://www.lhc-closer.es/taking_a_closer_look_at_lhc/0.lhcb)\n",
       "\n",
       "[LHC-3] [LHCb @ Syracuse: An overview](https://hep.syr.edu/quark-flavor-physics/lhcb-cern/)\n",
       "\n",
       "[LHC-4] [LHCb Upgrade II, Detector and Physics Prospects, Vincenzo Vagnoni (INFN Bologna, CERN), for the LHCb collaboration, The 2024 International Workshop on Future Tau Charm Facilities, 15 January 2024](https://indico.pnp.ustc.edu.cn/event/91/contributions/6351/attachments/1859/3063/FTCF%2015%20January%202024.pdf)\n",
       "\n",
       "---\n",
       "\n",
       "## Efficient algorithms for track reconstruction\n",
       "[ALGO-1] [Alain Chancé, A Toy Model For Reconstructing Particle Tracks at LHCb at CERN with Quantum Computing, 30 Oct. 2025, LHCb_VeLo_Toy_Model_1-Bit_HHL.pdf](https://github.com/AlainChance/LHCb_VeLo_Toy_Model_1-Bit_HHL/blob/main/LHCb_VeLo_Toy_Model_1-Bit_HHL.pdf)\n",
       "\n",
       "[ALGO-2] [Aaij, R., Adinolfi, M., Aiola, S. et al. A Comparison of CPU and GPU Implementations for the LHCb Experiment Run 3 Trigger. Comput Softw Big Sci 6, 1 (2022)](https://doi.org/10.1007/s41781-021-00070-2)\n",
       "\n",
       "[ALGO-3] [Daniel Campora, Track reconstruction made easy, 2021](https://github.com/dcampora/velopix_tracking)\n",
       "\n",
       "[ALGO-4] [Cámpora Pérez, D. H., Neufeld, N. & Riscos Núñez, A. Search by triplet: An efficient local track reconstruction algorithm\n",
       "for parallel architectures. J. Comput. Sci. 54, 101422, DOI: 10.1016/j.jocs.2021.101422 (2021)](https://arxiv.org/pdf/2207.03936)\n",
       "\n",
       "[ALGO-5] [Aaij, R., Albrecht, J., Belous, M. et al. Allen: A High-Level Trigger on GPUs for LHCb. Comput Softw Big Sci 4, 7 (2020). https://doi.org/10.1007/s41781-020-00039-7](https://doi.org/10.1007/s41781-020-00039-7)\n",
       "\n",
       "[ALGO-6] [The CMS Collaboration, Description and performance of track and primary-vertex reconstruction with the CMS tracker, arXiv:1405.6569v2, physics.ins-det, 28 Oct 2014](https://doi.org/10.48550/arXiv.1405.6569)\n",
       "\n",
       "[ALGO-7] [Primary Vertex Reconstruction at LHCb, LHCb-PUB-2014-044, October 21, 2014](https://cds.cern.ch/record/1756296/files/LHCb-PUB-2014-044.pdf)\n",
       "\n",
       "---\n",
       "\n",
       "## Hough transform\n",
       "[HOUGH-1] [Tomasz Bold1, Stefan Horodenski1, and Piotr Libucha1, Adaptive Hough Transform for Charged Particles Tracking at the LHC, EPJ Web of Conferences 337, 01278 (2025)](https://doi.org/10.1051/epjconf/202533701278)\n",
       "\n",
       "[HOUGH-2] [Straight line Hough transform](https://scikit-image.org/docs/stable/auto_examples/edges/plot_line_hough_transform.html)\n",
       "\n",
       "[HOUGH-3] [Frank Klefenz, Nico Wittrock, Frank Feldhoff, Parallel Quantum Hough Transform, 15 Nov 2023, arXiv:2311.09002 eess.IV](https://doi.org/10.48550/arXiv.2311.09002)\n",
       "\n",
       "[HOUGH-4] [F. Klefenz, K.-H. Noffz, W. Conen, R. Zoz, A. Kugel, and R. Manner. “Track recognition in 4 µs by a systolic trigger processor using a parallel Hough transform”. IEEE Transactions on Nuclear Science 40, 688–691 (1993)](https://ieeexplore.ieee.org/document/256642)\n",
       "\n",
       "---\n",
       "\n",
       "# Quantum computing algorithms for particle tracking\n",
       "\n",
       "## Simulated Bifurcation Algorithm\n",
       "[BIFUR-1] [Simulated Bifurcation for Python](https://github.com/bqth29/simulated-bifurcation-algorithm/tree/main)\n",
       "\n",
       "[BIFUR-2] [Hideki Okawa, Qing-Guo Zeng, Xian-Zhe Tao, Man-Hong Yung, Quantum-Annealing-Inspired Algorithms for Track Reconstruction at High-Energy Colliders, 30 Aug 2024, arXiv:2402.14718 quant-ph](https://doi.org/10.48550/arXiv.2402.14718)\n",
       "\n",
       "[BIFUR-3] [Okawa, Hideki, Quantum Algorithms for Track Reconstruction at High Energy Colliders, Workshop of Tracking in Particle Physics Experiments, May 17-19, 2024](https://indico.ihep.ac.cn/event/21775/contributions/155907/attachments/78247/97329/okawa_QTrack_20240517.pdf)\n",
       "\n",
       "## Quantum search using Grover’s Algorithm\n",
       "[GROVER-1] [Quantum pathways for charged track finding in high-energy collisions, Front. Artif. Intell., 30 May 2024, Sec. Big Data and AI in High Energy Physics, Volume 7 - 2024](https://www.frontiersin.org/journals/artificial-intelligence/articles/10.3389/frai.2024.1339785/full)\n",
       "\n",
       "[GROVER-2] [Alexiades Armenakas, A., Baker, O.K. Implementation and analysis of quantum computing application to Higgs boson reconstruction at the large Hadron Collider. Sci Rep 11, 22850 (2021)](https://doi.org/10.1038/s41598-021-01552-4)\n",
       "\n",
       "## Quantum Machine Learning in High Energy Physics\n",
       "[QML-1] [Gray HM. Quantum pattern recognition algorithms for charged particle tracking. Philos Trans A Math Phys Eng Sci. 2022 Feb 7;380(2216):20210103. doi: 10.1098/rsta.2021.0103. Epub 2021 Dec 20. PMID: 34923843; PMCID: PMC8685607.](https://pmc.ncbi.nlm.nih.gov/articles/PMC8685607/)\n",
       "\n",
       "[QML-2] [Wen Guan et al, Quantum machine learning in high energy physics, 2021 Mach. Learn.: Sci. Technol. 2 011003](https://quantum.web.cern.ch/sites/default/files/2021-07/Quantum%20Machine%20Learning%20in%20High%20Energy%20Physics.pdf)\n",
       "\n",
       "[QML-3] [Felser, T., Trenti, M., Sestini, L. et al. Quantum-inspired machine learning on high-energy physics data. npj Quantum Inf 7, 111 (2021)](https://doi.org/10.1038/s41534-021-00443-w)\n",
       "\n",
       "## TrackHHL: A Quantum Computing Algorithm for Track Reconstruction at the LHCb\n",
       "[TRHHL-1] [Xenofon Chiotopoulos, Davide Nicotra, George Scriven, Kurt Driessens, Marcel Merk, Jochen Schütz, Jacco de Vries, Mark H.M. Winands, TrackHHL: The 1-Bit Quantum Filter for particle trajectory reconstruction, 12 Jan 2026, arXiv:2601.07766](https://doi.org/10.48550/arXiv.2601.07766)\n",
       "\n",
       "[TRHHL-2] [Xenofon Chiotopoulos, TrackHHL: A Quantum Computing Algorithm for Track Reconstruction at the LHCb](https://cds.cern.ch/record/2950969/files/document.pdf)\n",
       "\n",
       "[TRHHL-3] [Xenofon Chiotopoulos, Miriam Lucio Martinez, Davide Nicotra, Jacco A. de Vries, Kurt Driessens, Marcel Merk, and Mark H.M. Winands, TrackHHL: A Quantum Computing Algorithm for Track Reconstruction at the LHCb, EPJ Web of Conferences 337, 01181 (2025)](https://doi.org/10.1051/epjconf/202533701181)\n",
       "\n",
       "[TRHHL-4] [Okawa, Hideki, Quantum Algorithms for Track Reconstruction at High Energy Colliders, Workshop of Tracking in Particle Physics Experiments, May 17-19, 2024](https://indico.ihep.ac.cn/event/21775/contributions/155907/attachments/78247/97329/okawa_QTrack_20240517.pdf)\n",
       "\n",
       "[TRHHL-5] [D. Nicotra et al., arXiv:2308.00619v2, 7 Oct 2023, A quantum algorithm for track reconstruction in the LHCb vertex detector](https://arxiv.org/pdf/2308.00619)\n",
       "\n",
       "## LHCb Velo Toy Model\n",
       "[TOY-1] [OneBQF](https://github.com/Xenofon-Chiotopoulos/OneBQF/tree/main)\n",
       "\n",
       "[TOY-2] [OneBQF.py](https://github.com/Xenofon-Chiotopoulos/OneBQF/blob/main/quantum_algorithms/OneBQF.py)\n",
       "\n",
       "[TOY-3] [LHCb_VeLo_Toy_Model](https://github.com/GeorgeWilliam1999/LHCb_VeLo_Toy_Model/tree/main)\n",
       "\n",
       "[TOY-4] [George_Sandbox.ipynb](https://github.com/GeorgeWilliam1999/LHCb_VeLo_Toy_Model/blob/main/George_Sandbox.ipynb)\n",
       "\n",
       "[TOY-5] [Xenofon Chiotopoulos, TrackHHL: A Quantum Computing Algorithm for Track Reconstruction at the LHCb](https://indico.cern.ch/event/1338689/contributions/6010017/attachments/2951297/5188722/CHEP_ppt.pdf)\n",
       "\n",
       "[TOY-6] [Tracking Toy Model Demo](https://github.com/Xenofon-Chiotopoulos/Tracking_Toy_model/blob/main/example_notebook.ipynb)\n",
       "\n",
       "---\n",
       "\n",
       "# Quantum error mitigation, detection and correction\n",
       "\n",
       "[ERR-1] [Ian Hincks — *Samplomatic and Its Use Cases* (QDC 2025)](https://www.youtube.com/watch?v=mZB3SxQMsiI)\n",
       "\n",
       "[ERR-2] [Andrew Eddins — *Error Mitigation Landscape* (QDC 2025)](https://www.youtube.com/watch?v=ix52wx4_zek)\n",
       "\n",
       "[ERR-3] [Alireza Seif — *Dynamic Circuit and Error Detection* (QDC 2025)](https://www.youtube.com/watch?v=GO7fiYEKIVw)\n",
       "\n",
       "[ERR-4] [Maika Takita — *Dynamic Circuit and Error Detection* (QDC 2025)](https://www.youtube.com/watch?v=rs3nlhRK7So)\n",
       "\n",
       "[ERR-5] [van den Berg, E., Minev, Z. K., Kandala, A. et al.\n",
       "*Probabilistic error cancellation with sparse Pauli–Lindblad models on noisy quantum processors.*\n",
       "Nat. Phys. 19, 1116–1121 (2023). https://doi.org/10.1038/s41567-023-02042-2](https://doi.org/10.1038/s41567-023-02042-2)\n",
       "\n",
       "---\n",
       "\n",
       "# Qiskit\n",
       "[Qiskit_1] [Install Qiskit](https://quantum.cloud.ibm.com/docs/en/guides/install-qiskit#install-qiskit)\n",
       "\n",
       "[Qiskit-2] [Introduction to Qiskit patterns](https://quantum.cloud.ibm.com/docs/en/guides/intro-to-patterns)\n",
       "\n",
       "---\n",
       "\n",
       "# Energetics of quantum computing\n",
       "[EN-1] [informatique quantique état de l’art, perspective et défis, Olivier Ezratty, SFGP, Paris, 5 novembre 2025](https://www.oezratty.net/Files/Conferences/Olivier%20Ezratty%20Informatique%20Quantique%20SFGP%20Nov2025.pdf) \n",
       "\n",
       "[EN-2] [Q2B25 Paris | Olivier Ezratty, Academic, Co Founder, Free Electron, EPITA, Quantum Energy Initiative, \n",
       "QC Ware, September 24-25 2025](https://www.youtube.com/watch?v=JVtm3pbesnA)\n",
       "\n",
       "[EN-3] [Green quantum computing, Capgemini, 8 May 2023](https://www.capgemini.com/insights/expert-perspectives/green-quantum-computing/)\n",
       "\n",
       "---\n",
       "\n",
       "# Quantum computing algorithms\n",
       "\n",
       "## Sample-based quantum diagonalization (SQD)\n",
       "[SQD-1] [Alain Chancé, Demonstrating chemistry simulations with Sample-based Quantum Diagonalization (SQD)](https://github.com/AlainChance/SQD_Alain)\n",
       "\n",
       "[SQD-2] [Sample-based quantum diagonalization (SQD) overview](https://quantum.cloud.ibm.com/docs/en/guides/qiskit-addons-sqd)\n",
       "\n",
       "[SQD_3] [Bounding the subspace dimension in Qiskit addon: sample-based quantum diagonalization (SQD)](https://qiskit.github.io/qiskit-addon-sqd/how_tos/choose_subspace_dimension.html)\n",
       "\n",
       "## Harrow–Hassidim–Lloyd (HHL) Algorithm\n",
       "[HHL-1] [V., Shwetha, Abinaya Selvarajan, Aarthi A., and Sneka R.. \"Quantum Speedup for Linear Systems: An Analysis of the HHL Algorithm Using IBM Qiskit.\" Journal of Electronics and Informatics 6, no. 4 (2024): 317-331](https://irojournals.com/iroei/article/view/6/4/3)\n",
       "\n",
       "[HHL-2] [Solving linear systems of equations using HHL and its Qiskit implementation, Qiskit Tutorial](https://github.com/Qiskit/textbook/blob/main/notebooks/ch-applications/hhl_tutorial.ipynb)\n",
       "\n",
       "## Quantum Phase Estimation (QPE) Algorithm\n",
       "[QPE-1] [Stefano Scali, Josh Kirsopp, Antonio Márquez Romero, Michał Krompiec, Spectral subspace extraction via incoherent quantum phase estimation, 16 Oct 2025, arXiv:2510.14744 quant-ph](https://doi.org/10.48550/arXiv.2510.14744)\n",
       "\n",
       "[QPE-2] [Antoine Lemelin, Christophe Pere, Olivier Landon-Cardinal, Camille Coti, Mid-circuit measurement as an algorithmic primitive, 2 Sep 2025, arXiv:2506.00118 quant-ph](https://doi.org/10.48550/arXiv.2506.00118) \n",
       "\n",
       "[QPE-3] [Phase estimation variants and its implication for quantum/classical architecture by Microsoft, From the need to hybridize algorithmically to the need to integrate QPUs with CPUs, J. Mikael, EDF, E. Vergnaud, Teratec TQCI, Conference on QPU/CPU Integration](https://www.teratec.eu/library/seminaires/2022/TQCI/Microsoft_Hybrid_QC_EDF.pdf)\n",
       "\n",
       "[QPE-4] [quantum-phase-estimation.ipynb, Qiskit Textbook](https://github.com/Qiskit/textbook/blob/main/notebooks/ch-algorithms/quantum-phase-estimation.ipynb)\n",
       "\n",
       "[QPE-5] [qiskit.circuit.library.phase_estimation](https://quantum.cloud.ibm.com/docs/en/api/qiskit/qiskit.circuit.library.phase_estimation)\n",
       "\n",
       "[QPE-6] [Non-variational and Phase Estimation algorithms, Quantinuum's InQuanto 5.1.0](https://docs.quantinuum.com/inquanto/manual/algorithms/non_variational_overview.html)\n",
       "\n",
       "## Quantum complexities of ordered searching, sorting, and element distinctness\n",
       "[HOY-1] [Høyer, P.; Neerbek, J.; Shi, Y. (2001). *Quantum complexities of ordered searching, sorting, and element distinctness*. 28th International Colloquium on Automata, Languages, and Programming. Lecture Notes in Computer Science. Vol. 2076. pp. 62–73. arXiv:quant-ph/0102078. doi:10.1007/3-540-48224-5_29. ISBN 978-3-540-42287-7](https://arxiv.org/abs/quant-ph/0102078)\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display Markdown file from the GitHub repository LHCb_VeLo_Toy_Model_1-Bit_HHL\n",
    "import requests\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/AlainChance/LHCb_VeLo_Toy_Model_1-Bit_HHL/main/README.md\"\n",
    "\n",
    "response = requests.get(url)\n",
    "response.raise_for_status()  # ensures errors are visible\n",
    "\n",
    "display(Markdown(response.text))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
